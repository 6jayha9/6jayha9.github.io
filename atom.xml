<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jayhablog.vercel.app</id>
    <title>Jayha小罗的秘密基地</title>
    <updated>2021-04-07T05:52:16.940Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jayhablog.vercel.app"/>
    <link rel="self" href="https://jayhablog.vercel.app/atom.xml"/>
    <subtitle>欢迎来到Jayha小罗的Blog嘻嘻嘻：）</subtitle>
    <logo>https://jayhablog.vercel.app/images/avatar.png</logo>
    <icon>https://jayhablog.vercel.app/favicon.ico</icon>
    <rights>All rights reserved 2021, Jayha小罗的秘密基地</rights>
    <entry>
        <title type="html"><![CDATA[docker part1]]></title>
        <id>https://jayhablog.vercel.app/docker-part1-ji-chu-pian/</id>
        <link href="https://jayhablog.vercel.app/docker-part1-ji-chu-pian/">
        </link>
        <updated>2021-04-01T05:08:27.000Z</updated>
        <content type="html"><![CDATA[<p>Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中,然后发布到任何流行的Linux机器或Windows 机器上,也可以实现虚拟化,容器是完全使用沙箱机制,相互之间不会有任何接口。<br>
官网为：https://www.docker.com/<br>
本博客旨在本人整理笔记，顺带介绍docker的基础知识。</p>
<p><img src="https://jayhablog.vercel.app/post-images/1617254006024.png" alt="" loading="lazy"><img src="D:%5C%E5%9B%BE%E5%BA%8A%5C576507-docker1.png" alt="" loading="lazy"></p>
<table>
<thead>
<tr>
<th>概念</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Docker 镜像(Images)</td>
<td>Docker 镜像是用于创建 Docker 容器的模板，比如 Ubuntu 系统。</td>
</tr>
<tr>
<td>Docker 容器(Container)</td>
<td>容器是独立运行的一个或一组应用，是镜像运行时的实体。</td>
</tr>
<tr>
<td>Docker 客户端(Client)</td>
<td>Docker 客户端通过命令行或者其他工具使用 Docker SDK (https://docs.docker.com/develop/sdk/) 与 Docker 的守护进程通信。</td>
</tr>
<tr>
<td>Docker 主机(Host)</td>
<td>一个物理或者虚拟的机器用于执行 Docker  守护进程和容器。</td>
</tr>
<tr>
<td>Docker Registry</td>
<td>Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。 Docker Hub(https://hub.docker.com) 提供了庞大的镜像集合供使用。  一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 <strong>latest</strong> 作为默认标签。</td>
</tr>
<tr>
<td>Docker Machine</td>
<td>Docker Machine是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，比如VirtualBox、 Digital Ocean、Microsoft Azure。</td>
</tr>
</tbody>
</table>
<p><strong>Docker是什么工作的?</strong><br>
Docker是一个Client-Server结构的系统，Docker的守护进程运行在主机上。通过<code>Socket</code>从客户端访问! DockerServer接收到 Docker-Client的指令，就会执行这个命令!</p>
<p>docker支持$() 的标记语法 如</p>
<pre><code class="language-shell">docker rm $(docker ps -aq)
</code></pre>
<p>ctrl+p+q 容器不停止退出交互模式</p>
<p>常用命令 查询 https://mp.weixin.qq.com/s/vBsTkAGmwInbLT18qOUZBw</p>
<h2 id="docker镜像加载原理"><strong>Docker镜像加载原理</strong></h2>
<p>docker的镜像实际上由一层一层的文件系统组成，这种展级的文件系统UnionFS.<br>
bootfs(boot file system)主要包含bootloader和kernel,bootloader主要是引导加载kernel,Linux刚启动时会加载bootfs文件系统，在Docker镜像的最底层是bootfs。这一层与我们典型的Linux/Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs,<br>
rootfs (root fle system)，在bootfs之上。包含的就是典型Linux系统中的/dev/proc/bin,/etc 等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。</p>
<blockquote>
<p>平时我们安装进虚拟机的CentOS都是好几个G，为什么Docker这里才200M?</p>
</blockquote>
<p>对于一个精简的Os，rootfs可以很小，只需要包含最基本的命令，工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供rootfs就可以了。由此可见对于不同的linux发行版bootfs基本是一致的rootfs会有差别,因此不同的发行版可以公用 bootfs.</p>
<p><img src="https://jayhablog.vercel.app/post-images/1617253972074.png" alt="" loading="lazy"><img src="D:%5C%E5%9B%BE%E5%BA%8A%5C20200320105107961.png" alt="" loading="lazy"></p>
<h4 id="换一个方法来说"><strong>换一个方法来说</strong></h4>
<p>Docker 镜像由一些松耦合的只读镜像层组成。</p>
<p>Docker 负责堆叠这些镜像层，并且将它们表示为单个统一的对象。</p>
<p>查看镜像分层的方式可以通过 docker image inspect 命令。下面同样以 ubuntu:latest 镜像为例。</p>
<p>所有的 Docker 镜像都起始于一个基础镜像层，当进行修改或增加新的内容时，就会在当前镜像层之上，创建新的镜像层。</p>
<p>举一个简单的例子，假如基于 Ubuntu Linux 16.04 创建一个新的镜像，这就是新镜像的第一层；如果在该镜像中添加python 包，就会在基础镜像层之上创建第二个镜像层；如果继续添加一个安全补丁，就会创建第三个镜像层。</p>
<p>该镜像当前已经包含 3 个镜像层，如下图所示（这只是一个用于演示的很简单的例子）。</p>
<p><img src="https://jayhablog.vercel.app/post-images/1617253896321.gif" alt="" loading="lazy"><img src="D:%5C%E5%9B%BE%E5%BA%8A%5C4-1Z416164115364.gif" alt="" loading="lazy"></p>
<p><strong><code>多个镜像之间可以并且确实会共享镜像层。这样可以有效节省空间并提升性能</code></strong>。</p>
<p>在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合，理解这一点非常重要。下图中举了一个简单的例子，每个镜像层包含 3 个文件，而镜像包含了来自两个镜像层的 6 个文件。</p>
<p><img src="https://jayhablog.vercel.app/post-images/1617253822923.gif" alt="" loading="lazy"><img src="D:%5C%E5%9B%BE%E5%BA%8A%5C4-1Z41616413R94.gif" alt="" loading="lazy"></p>
<p>上图中的镜像层跟之前图中的略有区别，主要目的是便于展示文件。</p>
<p>下图中展示了一个稍微复杂的三层镜像，在外部看来整个镜像只有 6 个文件，这是因为最上层中的文件 7 是文件 5 的一个更新版本。</p>
<p><img src="https://jayhablog.vercel.app/post-images/1617253858775.gif" alt="" loading="lazy"><img src="D:%5C%E5%9B%BE%E5%BA%8A%5C4-1Z416164203H1.gif" alt="" loading="lazy"></p>
<p>这种情况下，上层镜像层中的文件覆盖了底层镜像层中的文件。这样就使得文件的更新版本作为一个新镜像层添加到镜像当中。</p>
<p>Docker 通过存储引擎（新版本采用快照机制）的方式来实现镜像层堆栈，并保证多镜像层对外展示为统一的文件系统。</p>
<p>Linux 上可用的存储引擎有 AUFS、Overlay2、Device Mapper、Btrfs 以及 ZFS。顾名思义，每种存储引擎都基于 Linux 中对应的文件系统或者块设备技术，并且每种存储引擎都有其独有的性能特点。</p>
<p>Docker 在 Windows 上仅支持 windowsfilter 一种存储引擎，该引擎基于 NTFS 文件系统之上实现了分层和 CoW[1]。</p>
<p>下图展示了与系统显示相同的三层镜像。所有镜像层堆叠并合并，对外提供统一的视图。</p>
<figure data-type="image" tabindex="1"><img src="http://c.biancheng.net/uploads/allimg/190416/4-1Z4161642301E.gif" alt="从系统角度看三层镜像" loading="lazy"></figure>
<p>回顾一下之前用于拉取 nigelpoulton/tu-demo 仓库下全部包含标签的 docker image pull 命令（包含 -a 参数）。</p>
<pre><code class="language-bash">$ docker image pull -a nigelpoulton/tu-demo
 
 latest: Pulling from nigelpoulton/tu-demo
 237d5fcd25cf: Pull complete
 a3ed95caeb02: Pull complete
 &lt;Snip&gt;
 Digest: sha256:42e34e546cee61adb100...a0c5b53f324a9e1c1aae451e9
 
 v1: Pulling from nigelpoulton/tu-demo
 237d5fcd25cf: Already exists
 a3ed95caeb02: Already exists
 &lt;Snip&gt;
 Digest: sha256:9ccc0c67e5c5eaae4beb...24c1d5c80f2c9623cbcc9b59a
 
 v2: Pulling from nigelpoulton/tu-demo
 237d5fcd25cf: Already exists
 a3ed95caeb02: Already exists
 &lt;Snip&gt;
 eab5aaac65de: Pull complete
 Digest: sha256:d3c0d8c9d5719d31b79c...fef58a7e038cf0ef2ba5eb74c
 
 Status: Downloaded newer image for nigelpoulton/tu-demo
 
 $ docker image ls
 REPOSITORY TAG IMAGE ID CREATED SIZE
 nigelpoulton/tu-demo v2 6ac...ead 4 months ago 211.6 MB
 nigelpoulton/tu-demo latest 9b9...e29 4 months ago 211.6 MB
 nigelpoulton/tu-demo v1 9b9...e29 4 months ago 211.6 MB
</code></pre>
<p>注意那些以 Already exists 结尾的行。</p>
<p>由这几行可见，Docker 很聪明，可以识别出要拉取的镜像中，哪几层已经在本地存在。</p>
<p>在本例中，Docker 首先尝试拉取标签为 latest 的镜像。然后，当拉取标签为 v1 和 v2 的镜像时，Docker 注意到组成这两个镜像的镜像层，有一部分已经存在了。出现这种情况的原因是前面 3 个镜像相似度很高，所以共享了很多镜像层。</p>
<p>如前所述，Docker 在 Linux 上支持很多存储引擎（Snapshotter）。每个存储引擎都有自己的镜像分层、镜像层共享以及写时复制（CoW）技术的具体实现。</p>
<h1 id="容器和虚拟机">容器和虚拟机</h1>
<p>容器和虚拟机都依赖于宿主机才能运行。宿主机可以是笔记本，是数据中心的物理服务器，也可以是公有云的某个实例。</p>
<p>在下面的示例中，假设宿主机是一台需要运行 4 个业务应用的物理服务器。</p>
<p>在虚拟机模型中，首先要开启物理机并启动 Hypervisor 引导程序。一旦 Hypervisor 启动，就会占有机器上的全部物理资源，如 CPU、RAM、存储和 NIC。</p>
<p>Hypervisor 接下来就会将这些物理资源划分为虚拟资源，并且看起来与真实物理资源完全一致。</p>
<p>然后 Hypervisor 会将这些资源打包进一个叫作虚拟机（VM）的软件结构当中。这样用户就可以使用这些虚拟机，并在其中安装操作系统和应用。</p>
<p>前面提到需要在物理机上运行 4 个应用，所以在 Hypervisor 之上需要创建 4 个虚拟机并安装 4 个操作系统，然后安装 4 个应用。当操作完成后，结构如下图所示。</p>
<figure data-type="image" tabindex="2"><img src="http://c.biancheng.net/uploads/allimg/190417/4-1Z41G01336346.gif" alt="运行4个业务应用的物理服务器" loading="lazy"></figure>
<p>而容器模型则略有不同。</p>
<p>服务器启动之后，所选择的操作系统会启动。在 Docker 世界中可以选择 Linux，或者内核支持内核中的容器原语的新版本 Windows。</p>
<p>与虚拟机模型相同，OS 也占用了全部硬件资源。在 OS 层之上，需要安装容器引擎（如 Docker）。</p>
<p>容器引擎可以获取系统资源，比如进程树、文件系统以及网络栈，接着将资源分割为安全的互相隔离的资源结构，称之为容器。</p>
<p>每个容器看起来就像一个真实的操作系统，在其内部可以运行应用。按照前面的假设，需要在物理机上运行 4 个应用。</p>
<p>因此，需要划分出 4 个容器并在每个容器中运行一个应用，如下图所示。</p>
<figure data-type="image" tabindex="3"><img src="http://c.biancheng.net/uploads/allimg/190417/4-1Z41G01424234.gif" alt="划分4个容器" loading="lazy"></figure>
<p>从更高层面上来讲，Hypervisor 是硬件虚拟化（Hardware Virtualization）——Hypervisor 将硬件物理资源划分为虚拟资源。</p>
<p>容器是操作系统虚拟化（OS Virtualization）——容器将系统资源划分为虚拟资源。</p>
<h1 id="虚拟机的额外开销">虚拟机的额外开销</h1>
<p>基于前文所述内容，接下来会着重探讨 Hypervisor 模型的一个主要问题。</p>
<p>首先我们的目标是在一台物理机上运行 4 个业务相关应用。每种模型示例中都安装了一个操作系统或者 Hypervisor（一种针对虚拟机高度优化后的操作系统）。</p>
<p>虚拟机模型将底层硬件资源划分到虚拟机当中。每个虚拟机都是包含了虚拟 CPU、虚拟 RAM、虚拟磁盘等资源的一种软件结构。</p>
<p>因此，每个虚拟机都需要有自己的操作系统来声明、初始化并管理这些虚拟资源。</p>
<p>但是，操作系统本身是有其额外开销的。例如，每个操作系统都消耗一点 CPU、一点 RAM、一点存储空间等。</p>
<p>每个操作系统都需要独立的许可证，并且都需要打补丁升级，每个操作系统也都面临被攻击的风险。</p>
<p>通常将这种现象称作 OS Tax 或者 VM Tax，每个操作系统都占用一定的资源。</p>
<p>容器模型具有在宿主机操作系统中运行的单个内核。在一台主机上运行数十个甚至数百个容器都是可能的——容器共享一个操作系统/内核。</p>
<p>这意味着只有一个操作系统消耗 CPU、RAM 和存储资源，只有一个操作系统需要授权，只有一个操作系统需要升级和打补丁。同时，只有一个操作系统面临被攻击的风险。简言之，就是只有一份 OS 损耗。</p>
<p>在上述单台机器上只需要运行 4 个业务应用的场景中，也许问题尚不明显。但当需要运行成百上千应用的时候，就会引起质的变化。</p>
<p>另一个值得考虑的事情是启动时间。因为容器并不是完整的操作系统，所以其启动要远比虚拟机快。</p>
<p>切记，在容器内部并不需要内核，也就没有定位、解压以及初始化的过程——更不用提在内核启动过程中对硬件的遍历和初始化了。</p>
<p>这些在容器启动的过程中统统都不需要！唯一需要的是位于下层操作系统的共享内核是启动了的！最终结果就是，容器可以在 1s 内启动。唯一对容器启动时间有影响的就是容器内应用启动所花费的时间。</p>
<p>这就是容器模型要比虚拟机模型简洁并且高效的原因了。使用容器可以在更少的资源上运行更多的应用，启动更快，并且支付更少的授权和管理费用，同时面对未知攻击的风险也更小。</p>
<h1 id="docker数据卷数据挂载">docker数据卷（数据挂载）</h1>
<p>docker的镜像是由多个只读的文件系统叠加在一起形成的。当我们在我启动一个容器的时候，docker会加载这些只读层并在这些只读层的上面(栈顶)增加一个读写层。这时如果修改正在运行的容器中已有的文件，那么这个文件将会从只读层复制到读写层。该文件的只读版本还在，只是被上面读写层的该文件的副本隐藏。当删除docker,或者重新启动时，之前的更改将会消失。在Docker中，只读层及在顶部的读写层的组合被称为Union File System（联合文件系统）。<code>简单来说，没有数据卷的时候，删除容器=删除容器内所有数据。</code></p>
<p>为了很好的实现数据保存和数据共享，Docker提出了Volume这个概念，简单的说就是绕过默认的联合文件系统，而以正常的文件或者目录的形式存在于宿主机上。又被称作数据卷。是<code>软连接，数据只有一份，双向同步</code>。</p>
<p>好处就是，<code>比如把本机nginx配置和docker内配置相互挂载，以后修改本机nginx配置后</code>，再打开docker nginx就方便很多了</p>
<h3 id="使用数据卷">使用数据卷</h3>
<blockquote>
<p>方式一：使用命令挂载 -v</p>
</blockquote>
<pre><code class="language-bash">docker run -it -v 宿主机目录:容器内目录
</code></pre>
<p>可以在docker inspect中的monts属性查看挂载情况</p>
<blockquote>
<p>方式二： 使用--mount</p>
</blockquote>
<pre><code class="language-text">docker run --name xxxx -p 8888:8888 --mount   
type:volume,source=/src/xxx,target=/xxx /my:/docker -it imagename /bin/bash 
</code></pre>
<p>type选项，其可以是bind，volume，或 tmpfs。本主题讨论卷，因此类型始终是 volume</p>
<p>注意：使用-v参数时如果本地目录不存在Docker会自动为你创建一个文件夹。使用<code>--mount</code>参数时如果本地目录不存在，Docker会报错。Docker挂载主机目录的默认权限是读写，用户也可以通过增加readonly指定为只读。</p>
<ul>
<li>如果挂载一个空的数据卷到容器中的一个非空目录中，那么这个目录下的文件会被复制到数据卷中。(我的测试：使用 -v 参数并没有这个效果，需要使<code>--mount</code>参数，如果不符请指正)</li>
<li>如果挂载一个非空的数据卷到容器中的一个目录中，那么容器中的目录中会显示数据卷中的数据。如果原来容器中目录非空，那么这些原始数据会被隐藏掉。</li>
</ul>
<p>匿名挂载：docker volume ls命令后 是无序字符串的就是匿名挂载。</p>
<p>具名挂载：配置的时候 变成-v 名字:容器目录 之后本机挂载位置可以通过inspect命令查看  <code>推荐</code></p>
<blockquote>
<p>拓展：在-v 卷名（或者宿主机路径）:容器路径:rw(这个是权限 可以选ro[read only]或者rw[read＆write])</p>
<p>ro即是只能从容器外部改变（即容器内部不可写）</p>
</blockquote>
<hr>
<h1 id="docker网络">docker网络</h1>
<p>没有计网只是的 可以跳过本章节了</p>
<h3 id="docker0">docker0</h3>
<p>输入ip addr 查看网络状况时 很容易找到docker0的描述</p>
<pre><code class="language-bash">3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP 
    link/ether 02:42:ee:b5:9d:73 brd ff:ff:ff:ff:ff:ff
    inet 172.18.0.1/16 brd 172.18.255.255 scope global docker0
       valid_lft forever preferred_lft forever
</code></pre>
<p>docker0即是物理网卡直连NAT为docker生成的虚拟网卡</p>
<p>进入容器内部（我选择进入了centos8的容器） 用ip addr查看</p>
<pre><code class="language-bash">16: eth0@if17: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group 
#16: eth0@if17 是docker0分配的
default 
    link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.18.0.2/16 brd 172.18.255.255 scope global eth0
       valid_lft forever preferred_lft forever
#宿主机一定能ping通内部容器因为172.18.0.2可以发现他就是宿主机docker0给容器分配的网段，是同一网段内的
</code></pre>
<blockquote>
<p>原理</p>
</blockquote>
<p>docker0相当于docker生成的网卡</p>
<p>上面的情况使用的是桥接模式，使用的是evth-pair技术。当启动容器后，在宿主机内ip addr</p>
<p>就会发现出现了</p>
<pre><code class="language-shell">17: veth2844acd@if16: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP 
    link/ether f2:45:bc:90:59:53 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</code></pre>
<p>一个容器 多<code>一对</code>网卡，即容器内的网卡对容器外的网卡。</p>
<p>evth-pair就是一对虚拟设备接口，一段连接协议。</p>
<p>所以evth-pair充当桥梁桥接宿主机和容器机，链接各种虚拟网络设备</p>
<p><mark>---容器间虽然相互隔离，但可以通过docker0转发，所以互相之间ping ip 可以ping通<code>docker0就相当于路由器</code>，docker0给容器分配默认的可用ip---</mark></p>
<p>这个特性有其缺陷，编写微服务的时候常常需要写ip地址调用，当docker遇到不可预测的问题宕机重启后，ip地址变了，写的服务层代码往往会失效。到后面会讲怎么解决。</p>
<h5 id="link">link</h5>
<p>启动容器时，设置 --link属性 后面+被接受容器名，即可实现两个容器间互通(当然 用)，比如</p>
<pre><code class="language-bash">docker run -it -P --name jayha_centos --link jayha_ubuntu7070 centos
</code></pre>
<p>输入docker network 命令 可查看docker的网络id号 通过id号即可用inspect查询目前网络各种情况。我们就会发现</p>
<p><code>link实现原理其实就是把link链接的容器，写死ip在本容器的host文件中，添加了一个映射。</code></p>
<p>所以，link已经是个被不看好的技术，也是个不实用的技术，了解即可。</p>
<hr>
<p><code>由此，我们为了拓展网络自由度，可以自己做网络。</code></p>
<h3 id="扩展docker网络">扩展docker网络</h3>
<p>💛docker网络模式有：bridge（默认），none（不配置网络），host（与宿主机共享网络），container（容器网络连通，局限极大，基本不用）</p>
<p>而拓展docker用的就是bridge</p>
<p>创建网络方式为：</p>
<pre><code class="language-bash">docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet
#                     连接方式设置为桥接    设置子网                网关                网络名
</code></pre>
<p>之后在启动容器时， 设置--net属性时候， 即可用自己创建的网络，这样的话 直接ping容器名字都可以ping通了。</p>
<p>好处就是，<code>不同的集群使用不同的网络，可以保证集群的安全健康。</code></p>
<p>容器与不同的网络之间也是可以打通的 可以使用</p>
<pre><code class="language-bash">docker network connect [参数] [网络] [容器]
</code></pre>
<p>来打通</p>
<hr>
<h1 id="dockerfile">dockerFile</h1>
<p>即是<code>用来构建docker image</code>的构建文件或者可以说是命令脚本，相当于编写docker images的源代码。</p>
<figure data-type="image" tabindex="4"><img src="D:%5C%E5%9B%BE%E5%BA%8A%5CdockerFile%E7%9A%84%E6%8C%87%E4%BB%A4%E5%9C%A8%E5%B9%B2%E4%BB%80%E4%B9%88.png" alt="" loading="lazy"></figure>
<p><strong>FROM：指定基础镜像，必须为第一个命令</strong> ：docker hub上九成九都是从scratch开始的（了解即可 我们不用从这个开始写</p>
<pre><code>格式：
　　FROM &lt;image&gt;
　　FROM &lt;image&gt;:&lt;tag&gt;
　　FROM &lt;image&gt;@&lt;digest&gt;示例：　　FROM mysql:5.6注：　　tag或digest是可选的，如果不使用这两个值时，会使用latest版本的基础镜像
</code></pre>
<p><strong>MAINTAINER: 维护者信息</strong></p>
<pre><code>格式：
    MAINTAINER &lt;name&gt;
示例：
    MAINTAINER Jasper Xu
    MAINTAINER sorex@163.com
    MAINTAINER Jasper Xu &lt;sorex@163.com&gt;
</code></pre>
<p><strong>RUN：构建镜像时执行的命令</strong></p>
<pre><code>RUN用于在镜像容器中执行命令，其有以下两种命令执行方式：
shell执行
格式：
    RUN &lt;command&gt;
exec执行
格式：
    RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]
示例：
    RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]
    RUN apk update
    RUN [&quot;/etc/execfile&quot;, &quot;arg1&quot;, &quot;arg1&quot;]
注：　　RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定--no-cache参数，如：docker build --no-cache
</code></pre>
<p><strong>ADD：将本地文件添加到容器中，tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，类似wget</strong></p>
<pre><code>格式：
    ADD &lt;src&gt;... &lt;dest&gt;
    ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] 用于支持包含空格的路径
示例：
    ADD hom* /mydir/          # 添加所有以&quot;hom&quot;开头的文件
    ADD hom?.txt /mydir/      # ? 替代一个单字符,例如：&quot;home.txt&quot;
    ADD test relativeDir/     # 添加 &quot;test&quot; 到 `WORKDIR`/relativeDir/
    ADD test /absoluteDir/    # 添加 &quot;test&quot; 到 /absoluteDir/
</code></pre>
<p><strong>COPY：功能类似ADD，但是是不会自动解压文件，也不能访问网络资源</strong></p>
<p><strong>CMD：构建容器后调用，也就是在容器启动时才进行调用。</strong></p>
<pre><code>格式：
    CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (执行可执行文件，优先)
    CMD [&quot;param1&quot;,&quot;param2&quot;] (设置了ENTRYPOINT，则直接调用ENTRYPOINT添加参数)
    CMD command param1 param2 (执行shell内部命令)
示例：
    CMD echo &quot;This is a test.&quot; | wc -
    CMD [&quot;/usr/bin/wc&quot;,&quot;--help&quot;]注： 　　CMD不同于RUN，CMD用于指定在容器启动时所要执行的命令，而RUN用于指定镜像构建时所要执行的命令。
</code></pre>
<p><strong>ENTRYPOINT：配置容器，使其可执行化。配合CMD可省去&quot;application&quot;，只使用参数。</strong></p>
<pre><code>格式：
    ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (可执行文件, 优先)
    ENTRYPOINT command param1 param2 (shell内部命令)
示例：
    FROM ubuntu
    ENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]
    CMD [&quot;-c&quot;]注：　　　ENTRYPOINT与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT，而docker run命令中指定的任何参数，都会被当做参数再次传递给ENTRYPOINT。Dockerfile中只允许有一个ENTRYPOINT命令，多指定时会覆盖前面的设置，而只执行最后的ENTRYPOINT指令。
</code></pre>
<p><strong>LABEL：用于为镜像添加元数据</strong></p>
<pre><code>格式：
    LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...
示例：
　　LABEL version=&quot;1.0&quot; description=&quot;这是一个Web服务器&quot; by=&quot;IT笔录&quot;
注：
　　使用LABEL指定元数据时，一条LABEL指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔。推荐将所有的元数据通过一条LABEL指令指定，以免生成过多的中间镜像。
</code></pre>
<p><strong>ENV：设置环境变量</strong></p>
<pre><code>格式：
    ENV &lt;key&gt; &lt;value&gt;  #&lt;key&gt;之后的所有内容均会被视为其&lt;value&gt;的组成部分，因此，一次只能设置一个变量
    ENV &lt;key&gt;=&lt;value&gt; ...  #可以设置多个变量，每个变量为一个&quot;&lt;key&gt;=&lt;value&gt;&quot;的键值对，如果&lt;key&gt;中包含空格，可以使用\来进行转义，也可以通过&quot;&quot;来进行标示；另外，反斜线也可以用于续行
示例：
    ENV myName John Doe
    ENV myDog Rex The Dog
    ENV myCat=fluffy
</code></pre>
<p><strong>EXPOSE：指定于外界交互的端口</strong></p>
<pre><code>格式：
    EXPOSE &lt;port&gt; [&lt;port&gt;...]
示例：
    EXPOSE 80 443
    EXPOSE 8080    EXPOSE 11211/tcp 11211/udp注：　　EXPOSE并不会让容器的端口访问到主机。要使其可访问，需要在docker run运行容器时通过-p来发布这些端口，或通过-P参数来发布EXPOSE导出的所有端口
</code></pre>
<p><strong>VOLUME：用于指定持久化目录</strong></p>
<pre><code>格式：
    VOLUME [&quot;/path/to/dir&quot;]
示例：
    VOLUME [&quot;/data&quot;]
    VOLUME [&quot;/var/www&quot;, &quot;/var/log/apache2&quot;, &quot;/etc/apache2&quot;注：　　一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能：
1 卷可以容器间共享和重用
2 容器并不一定要和其它容器共享卷
3 修改卷后会立即生效
4 对卷的修改不会对镜像产生影响
5 卷会一直存在，直到没有任何容器在使用它
</code></pre>
<p><strong>WORKDIR：工作目录，类似于cd命令</strong></p>
<pre><code>格式：
    WORKDIR /path/to/workdir
示例：
    WORKDIR /a  (这时工作目录为/a)
    WORKDIR b  (这时工作目录为/a/b)
    WORKDIR c  (这时工作目录为/a/b/c)注：　　通过WORKDIR设置工作目录后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT、ADD、COPY等命令都会在该目录下执行。在使用docker run运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。
</code></pre>
<p>**USER:**<strong>指定运行容器时的用户名或 UID，后续的 RUN 也会使用指定用户。使用USER指定用户时，可以使用用户名、UID或GID，或是两者的组合。当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户</strong></p>
<pre><code class="language-bash">格式:
　　USER user
　　USER user:group
　　USER uid
　　USER uid:gid
　　USER user:gid
　　USER uid:group

 示例：
    　　USER www
</code></pre>
<p>注：</p>
<p>使用USER指定用户后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT都将使用该用户。镜像构建完成后，通过<code>docker run</code>运行容器时，可以通过-u参数来覆盖所指定的用户。</p>
<p><strong>ARG：用于指定传递给构建运行时的变量</strong></p>
<pre><code>格式：
    ARG &lt;name&gt;[=&lt;default value&gt;]
示例：
    ARG site
    ARG build_user=www
</code></pre>
<p><strong>ONBUILD：用于设置镜像触发器</strong></p>
<pre><code>格式：　　ONBUILD [INSTRUCTION]
示例：
　　ONBUILD ADD . /app/src
　　ONBUILD RUN /usr/local/bin/python-build --dir /app/src
注：　　当所构建的镜像被用做其它镜像的基础镜像，该镜像中的触发器将会被钥触发
</code></pre>
<p><strong>以下是一个小例子：</strong></p>
<pre><code># This my first nginx Dockerfile
# Version 1.0

# Base images 基础镜像
FROM centos

#MAINTAINER 维护者信息
MAINTAINER tianfeiyu 

#ENV 设置环境变量
ENV PATH /usr/local/nginx/sbin:$PATH

#ADD  文件放在当前目录下，拷过去会自动解压
ADD nginx-1.8.0.tar.gz /usr/local/  
ADD epel-release-latest-7.noarch.rpm /usr/local/  

#RUN 执行以下命令 
RUN rpm -ivh /usr/local/epel-release-latest-7.noarch.rpm
RUN yum install -y wget lftp gcc gcc-c++ make openssl-devel pcre-devel pcre &amp;&amp; yum clean all
RUN useradd -s /sbin/nologin -M www

#WORKDIR 相当于cd
WORKDIR /usr/local/nginx-1.8.0 

RUN ./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-pcre &amp;&amp; make &amp;&amp; make install

RUN echo &quot;daemon off;&quot; &gt;&gt; /etc/nginx.conf

#EXPOSE 映射端口
EXPOSE 80

#CMD 运行以下命令
CMD [&quot;nginx&quot;]
</code></pre>
<p><strong><code>可以！推送到阿里云的镜像仓库！</code></strong></p>
<p><s>吐槽：极其类似github 我怀疑不管docker官方还是阿里云代码都借鉴了很多linus写的东西，至少是思想</s></p>
<figure data-type="image" tabindex="5"><img src="https://jayhablog.vercel.app/post-images/1617773530086.png" alt="Jayha的，别乱用" loading="lazy"></figure>
<hr>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[更优雅的写接口（转）]]></title>
        <id>https://jayhablog.vercel.app/geng-you-ya-de-xie-jie-kou-zhuan/</id>
        <link href="https://jayhablog.vercel.app/geng-you-ya-de-xie-jie-kou-zhuan/">
        </link>
        <updated>2020-11-20T08:27:04.000Z</updated>
        <content type="html"><![CDATA[<p>作者：RudeCrab<br>
来源：juejin.im/post/6844904101940117511<br>
前言</p>
<p>一个后端接口大致分为四个部分组成：接口地址（url）、接口请求方式（get、post等）、请求数据（request）、响应数据（response）。如何构建这几个部分每个公司要求都不同，没有什么“一定是最好的”标准，但一个优秀的后端接口和一个糟糕的后端接口对比起来差异还是蛮大的，其中最重要的关键点就是看是否规范! 本文就一步一步演示如何构建起一个优秀的后端接口体系，体系构建好了自然就有了规范，同时再构建新的后端接口也会十分轻松。<br>
所需依赖包</p>
<p>这里用的是SpringBoot配置项目，本文讲解的重点是后端接口，所以只需要导入一个spring-boot-starter-web包就可以了：</p>
<!--web依赖包，web应用必备-->
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-web</artifactId>
</dependency>
本文还用了swagger来生成API文档，lombok来简化类，不过这两者不是必须的，可用可不用。
参数校验
<p>一个接口一般对参数（请求数据）都会进行安全校验，参数校验的重要性自然不必多说，那么如何对参数进行校验就有讲究了。<br>
业务层校验<br>
首先我们来看一下最常见的做法，就是在业务层进行参数校验：<br>
public String addUser(User user) {<br>
if (user == null || user.getId() == null || user.getAccount() == null || user.getPassword() == null || user.getEmail() == null) {<br>
return &quot;对象或者对象字段不能为空&quot;;<br>
}<br>
if (StringUtils.isEmpty(user.getAccount()) || StringUtils.isEmpty(user.getPassword()) || StringUtils.isEmpty(user.getEmail())) {<br>
return &quot;不能输入空字符串&quot;;<br>
}<br>
if (user.getAccount().length() &lt; 6 || user.getAccount().length() &gt; 11) {<br>
return &quot;账号长度必须是6-11个字符&quot;;<br>
}<br>
if (user.getPassword().length() &lt; 6 || user.getPassword().length() &gt; 16) {<br>
return &quot;密码长度必须是6-16个字符&quot;;<br>
}<br>
if (!Pattern.matches(&quot;<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>+@[a-zA-Z0-9_-]+(\.[a-zA-Z0-9_-]+)+$&quot;, user.getEmail())) {<br>
return &quot;邮箱格式不正确&quot;;<br>
}<br>
// 参数校验完毕后这里就写上业务逻辑<br>
return &quot;success&quot;;<br>
}<br>
这样做当然是没有什么错的，而且格式排版整齐也一目了然，不过这样太繁琐了，这还没有进行业务操作呢光是一个参数校验就已经这么多行代码，实在不够优雅。我们来改进一下，使用Spring Validator和Hibernate Validator这两套Validator来进行方便的参数校验！这两套Validator依赖包已经包含在前面所说的web依赖包里了，所以可以直接使用。<br>
Validator + BindResult进行校验<br>
Validator可以非常方便的制定校验规则，并自动帮你完成校验。首先在入参里需要校验的字段加上注解,每个注解对应不同的校验规则，并可制定校验失败后的信息：<br>
@Data<br>
public class User {<br>
@NotNull(message = &quot;用户id不能为空&quot;)<br>
private Long id;</p>
<pre><code>@NotNull(message = &quot;用户账号不能为空&quot;)
@Size(min = 6, max = 11, message = &quot;账号长度必须是6-11个字符&quot;)
private String account;

@NotNull(message = &quot;用户密码不能为空&quot;)
@Size(min = 6, max = 11, message = &quot;密码长度必须是6-16个字符&quot;)
private String password;

@NotNull(message = &quot;用户邮箱不能为空&quot;)
@Email(message = &quot;邮箱格式不正确&quot;)
private String email;
</code></pre>
<p>}<br>
校验规则和错误提示信息配置完毕后，接下来只需要在接口需要校验的参数上加上@Valid注解，并添加BindResult参数即可方便完成验证：<br>
@RestController<br>
@RequestMapping(&quot;user&quot;)<br>
public class UserController {<br>
@Autowired<br>
private UserService userService;</p>
<pre><code>@PostMapping(&quot;/addUser&quot;)
public String addUser(@RequestBody @Valid User user, BindingResult bindingResult) {
    // 如果有参数校验失败，会将错误信息封装成对象组装在BindingResult里
    for (ObjectError error : bindingResult.getAllErrors()) {
        return error.getDefaultMessage();
    }
    return userService.addUser(user);
}
</code></pre>
<p>}<br>
这样当请求数据传递到接口的时候Validator就自动完成校验了，校验的结果就会封装到BindingResult中去，如果有错误信息我们就直接返回给前端，业务逻辑代码也根本没有执行下去。此时，业务层里的校验代码就已经不需要了：<br>
public String addUser(User user) {<br>
// 直接编写业务逻辑<br>
return &quot;success&quot;;<br>
}<br>
现在可以看一下参数校验效果。我们故意给这个接口传递一个不符合校验规则的参数，先传递一个错误数据给接口，故意将password这个字段不满足校验条件：<br>
{<br>
&quot;account&quot;: &quot;12345678&quot;,<br>
&quot;email&quot;: &quot;123@qq.com&quot;,<br>
&quot;id&quot;: 0,<br>
&quot;password&quot;: &quot;123&quot;<br>
}<br>
再来看一下接口的响应数据：</p>
<p>img<br>
这样是不是方便很多？不难看出使用Validator校验有如下几个好处：<br>
简化代码，之前业务层那么一大段校验代码都被省略掉了。<br>
使用方便，那么多校验规则可以轻而易举的实现，比如邮箱格式验证，之前自己手写正则表达式要写那么一长串，还容易出错，用Validator直接一个注解搞定。（还有更多校验规则注解，可以自行去了解哦）<br>
减少耦合度，使用Validator能够让业务层只关注业务逻辑，从基本的参数校验逻辑中脱离出来。<br>
使用Validator+ BindingResult已经是非常方便实用的参数校验方式了，在实际开发中也有很多项目就是这么做的，不过这样还是不太方便，因为你每写一个接口都要添加一个BindingResult参数，然后再提取错误信息返回给前端。这样有点麻烦，并且重复代码很多（尽管可以将这个重复代码封装成方法）。我们能否去掉BindingResult这一步呢？当然是可以的！<br>
Validator + 自动抛出异常<br>
我们完全可以将BindingResult这一步给去掉：<br>
@PostMapping(&quot;/addUser&quot;)<br>
public String addUser(@RequestBody @Valid User user) {<br>
return userService.addUser(user);<br>
}<br>
去掉之后会发生什么事情呢？直接来试验一下，还是按照之前一样故意传递一个不符合校验规则的参数给接口。此时我们观察控制台可以发现接口已经引发MethodArgumentNotValidException异常了：</p>
<p>img<br>
其实这样就已经达到我们想要的效果了，参数校验不通过自然就不执行接下来的业务逻辑，去掉BindingResult后会自动引发异常，异常发生了自然而然就不会执行业务逻辑。也就是说，我们完全没必要添加相关BindingResult相关操作嘛。不过事情还没有完，异常是引发了，可我们并没有编写返回错误信息的代码呀，那参数校验失败了会响应什么数据给前端呢？我们来看一下刚才异常发生后接口响应的数据：</p>
<p>img<br>
没错，是直接将整个错误对象相关信息都响应给前端了！这样就很难受，不过解决这个问题也很简单，就是我们接下来要讲的全局异常处理！<br>
全局异常处理</p>
<p>参数校验失败会自动引发异常，我们当然不可能再去手动捕捉异常进行处理，不然还不如用之前BindingResult方式呢。又不想手动捕捉这个异常，又要对这个异常进行处理，那正好使用SpringBoot全局异常处理来达到一劳永逸的效果！<br>
基本使用<br>
首先，我们需要新建一个类，在这个类上加上@ControllerAdvice或@RestControllerAdvice注解，这个类就配置成全局处理类了。（这个根据你的Controller层用的是@Controller还是@RestController来决定） 然后在类中新建方法，在方法上加上@ExceptionHandler注解并指定你想处理的异常类型，接着在方法内编写对该异常的操作逻辑，就完成了对该异常的全局处理！我们现在就来演示一下对参数校验失败抛出的MethodArgumentNotValidException全局处理：<br>
@RestControllerAdvice<br>
public class ExceptionControllerAdvice {</p>
<pre><code>@ExceptionHandler(MethodArgumentNotValidException.class)
public String MethodArgumentNotValidExceptionHandler(MethodArgumentNotValidException e) {
 // 从异常对象中拿到ObjectError对象
    ObjectError objectError = e.getBindingResult().getAllErrors().get(0);
    // 然后提取错误提示信息进行返回
    return objectError.getDefaultMessage();
}
</code></pre>
<p>}<br>
我们再来看下这次校验失败后的响应数据：</p>
<p>img<br>
没错，这次返回的就是我们制定的错误提示信息！我们通过全局异常处理优雅的实现了我们想要的功能！以后我们再想写接口参数校验，就只需要在入参的成员变量上加上Validator校验规则注解，然后在参数上加上@Valid注解即可完成校验，校验失败会自动返回错误提示信息，无需任何其他代码！<br>
自定义异常<br>
全局处理当然不会只能处理一种异常，用途也不仅仅是对一个参数校验方式进行优化。在实际开发中，如何对异常处理其实是一个很麻烦的事情。传统处理异常一般有以下烦恼：<br>
是捕获异常(try...catch)还是抛出异常(throws)<br>
是在controller层做处理还是在service层处理又或是在dao层做处理<br>
处理异常的方式是啥也不做，还是返回特定数据，如果返回又返回什么数据<br>
不是所有异常我们都能预先进行捕捉，如果发生了没有捕捉到的异常该怎么办？<br>
以上这些问题都可以用全局异常处理来解决，全局异常处理也叫统一异常处理，全局和统一处理代表什么？代表规范！ 规范有了，很多问题就会迎刃而解！全局异常处理的基本使用方式大家都已经知道了，我们接下来更进一步的规范项目中的异常处理方式：自定义异常。在很多情况下，我们需要手动抛出异常，比如在业务层当有些条件并不符合业务逻辑，我这时候就可以手动抛出异常从而触发事务回滚。那手动抛出异常最简单的方式就是throw new RuntimeException(&quot;异常信息&quot;)了，不过使用自定义会更好一些：<br>
自定义异常可以携带更多的信息，不像这样只能携带一个字符串。<br>
项目开发中经常是很多人负责不同的模块，使用自定义异常可以统一了对外异常展示的方式。<br>
自定义异常语义更加清晰明了，一看就知道是项目中手动抛出的异常。<br>
我们现在就来开始写一个自定义异常：<br>
@Getter //只要getter方法，无需setter<br>
public class APIException extends RuntimeException {<br>
private int code;<br>
private String msg;</p>
<pre><code>public APIException() {
    this(1001, &quot;接口错误&quot;);
}

public APIException(String msg) {
    this(1001, msg);
}

public APIException(int code, String msg) {
    super(msg);
    this.code = code;
    this.msg = msg;
}
</code></pre>
<p>}<br>
在刚才的全局异常处理类中记得添加对我们自定义异常的处理：<br>
@ExceptionHandler(APIException.class)<br>
public String APIExceptionHandler(APIException e) {<br>
return e.getMsg();<br>
}<br>
这样就对异常的处理就比较规范了，当然还可以添加对Exception的处理，这样无论发生什么异常我们都能屏蔽掉然后响应数据给前端，不过建议最后项目上线时这样做，能够屏蔽掉错误信息暴露给前端，在开发中为了方便调试还是不要这样做。现在全局异常处理和自定义异常已经弄好了，不知道大家有没有发现一个问题，就是当我们抛出自定义异常的时候全局异常处理只响应了异常中的错误信息msg给前端，并没有将错误代码code返回。这就要引申出我们接下来要讲的东西了：数据统一响应<br>
数据统一响应</p>
<p>现在我们规范好了参数校验方式和异常处理方式，然而还没有规范响应数据！比如我要获取一个分页信息数据，获取成功了呢自然就返回的数据列表，获取失败了后台就会响应异常信息，即一个字符串，就是说前端开发者压根就不知道后端响应过来的数据会是啥样的！所以，统一响应数据是前后端规范中必须要做的！<br>
自定义统一响应体<br>
统一数据响应第一步肯定要做的就是我们自己自定义一个响应体类，无论后台是运行正常还是发生异常，响应给前端的数据格式是不变的！那么如何定义响应体呢？可以参考我们自定义异常类，也来一个响应信息代码code和响应信息说明msg：<br>
@Getter<br>
public class ResultVO<T> {<br>
/**<br>
* 状态码，比如1000代表响应成功<br>
<em>/<br>
private int code;<br>
/</em>*<br>
* 响应信息，用来说明响应情况<br>
<em>/<br>
private String msg;<br>
/</em>*<br>
* 响应的具体数据<br>
*/<br>
private T data;</p>
<pre><code>public ResultVO(T data) {
    this(1000, &quot;success&quot;, data);
}

public ResultVO(int code, String msg, T data) {
    this.code = code;
    this.msg = msg;
    this.data = data;
}
</code></pre>
<p>}<br>
然后我们修改一下全局异常处理那的返回值：<br>
@ExceptionHandler(APIException.class)<br>
public ResultVO<String> APIExceptionHandler(APIException e) {<br>
// 注意哦，这里返回类型是自定义响应体<br>
return new ResultVO&lt;&gt;(e.getCode(), &quot;响应失败&quot;, e.getMsg());<br>
}</p>
<p>@ExceptionHandler(MethodArgumentNotValidException.class)<br>
public ResultVO<String> MethodArgumentNotValidExceptionHandler(MethodArgumentNotValidException e) {<br>
ObjectError objectError = e.getBindingResult().getAllErrors().get(0);<br>
// 注意哦，这里返回类型是自定义响应体<br>
return new ResultVO&lt;&gt;(1001, &quot;参数校验失败&quot;, objectError.getDefaultMessage());<br>
}<br>
我们再来看一下此时如果发生异常了会响应什么数据给前端：</p>
<p>img<br>
OK，这个异常信息响应就非常好了，状态码和响应说明还有错误提示数据都返给了前端，并且是所有异常都会返回相同的格式！异常这里搞定了，别忘了我们到接口那也要修改返回类型，我们新增一个接口好来看看效果：<br>
@GetMapping(&quot;/getUser&quot;)<br>
public ResultVO<User> getUser() {<br>
User user = new User();<br>
user.setId(1L);<br>
user.setAccount(&quot;12345678&quot;);<br>
user.setPassword(&quot;12345678&quot;);<br>
user.setEmail(&quot;123@qq.com&quot;);</p>
<pre><code>return new ResultVO&lt;&gt;(user);
</code></pre>
<p>}<br>
看一下如果响应正确返回的是什么效果：</p>
<p>img<br>
这样无论是正确响应还是发生异常，响应数据的格式都是统一的，十分规范！<br>
数据格式是规范了，不过响应码code和响应信息msg还没有规范呀！大家发现没有，无论是正确响应，还是异常响应，响应码和响应信息是想怎么设置就怎么设置，要是10个开发人员对同一个类型的响应写10个不同的响应码，那这个统一响应体的格式规范就毫无意义！所以，必须要将响应码和响应信息给规范起来。<br>
响应码枚举<br>
要规范响应体中的响应码和响应信息用枚举简直再恰当不过了，我们现在就来创建一个响应码枚举类：<br>
@Getter<br>
public enum ResultCode {</p>
<pre><code>SUCCESS(1000, &quot;操作成功&quot;),

FAILED(1001, &quot;响应失败&quot;),

VALIDATE_FAILED(1002, &quot;参数校验失败&quot;),

ERROR(5000, &quot;未知错误&quot;);

private int code;
private String msg;

ResultCode(int code, String msg) {
    this.code = code;
    this.msg = msg;
}
</code></pre>
<p>}<br>
然后修改响应体的构造方法，让其只准接受响应码枚举来设置响应码和响应信息：<br>
public ResultVO(T data) {<br>
this(ResultCode.SUCCESS, data);<br>
}</p>
<p>public ResultVO(ResultCode resultCode, T data) {<br>
this.code = resultCode.getCode();<br>
this.msg = resultCode.getMsg();<br>
this.data = data;<br>
}<br>
然后同时修改全局异常处理的响应码设置方式：<br>
@ExceptionHandler(APIException.class)<br>
public ResultVO<String> APIExceptionHandler(APIException e) {<br>
// 注意哦，这里传递的响应码枚举<br>
return new ResultVO&lt;&gt;(ResultCode.FAILED, e.getMsg());<br>
}</p>
<p>@ExceptionHandler(MethodArgumentNotValidException.class)<br>
public ResultVO<String> MethodArgumentNotValidExceptionHandler(MethodArgumentNotValidException e) {<br>
ObjectError objectError = e.getBindingResult().getAllErrors().get(0);<br>
// 注意哦，这里传递的响应码枚举<br>
return new ResultVO&lt;&gt;(ResultCode.VALIDATE_FAILED, objectError.getDefaultMessage());<br>
}<br>
这样响应码和响应信息只能是枚举规定的那几个，就真正做到了响应数据格式、响应码和响应信息规范化、统一化！<br>
全局处理响应数据<br>
接口返回统一响应体 + 异常也返回统一响应体，其实这样已经很好了，但还是有可以优化的地方。要知道一个项目下来定义的接口搞个几百个太正常不过了，要是每一个接口返回数据时都要用响应体来包装一下好像有点麻烦，有没有办法省去这个包装过程呢？当然是有滴，还是要用到全局处理。<br>
首先，先创建一个类加上注解使其成为全局处理类。然后继承ResponseBodyAdvice接口重写其中的方法，即可对我们的controller进行增强操作，具体看代码和注释：<br>
@RestControllerAdvice(basePackages = {&quot;com.rudecrab.demo.controller&quot;}) // 注意哦，这里要加上需要扫描的包<br>
public class ResponseControllerAdvice implements ResponseBodyAdvice<Object> {<br>
@Override<br>
public boolean supports(MethodParameter returnType, Class<? extends HttpMessageConverter<?>&gt; aClass) {<br>
// 如果接口返回的类型本身就是ResultVO那就没有必要进行额外的操作，返回false<br>
return !returnType.getParameterType().equals(ResultVO.class);<br>
}</p>
<pre><code>@Override
public Object beforeBodyWrite(Object data, MethodParameter returnType, MediaType mediaType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; aClass, ServerHttpRequest request, ServerHttpResponse response) {
    // String类型不能直接包装，所以要进行些特别的处理
    if (returnType.getGenericParameterType().equals(String.class)) {
        ObjectMapper objectMapper = new ObjectMapper();
        try {
            // 将数据包装在ResultVO里后，再转换为json字符串响应给前端
            return objectMapper.writeValueAsString(new ResultVO&lt;&gt;(data));
        } catch (JsonProcessingException e) {
            throw new APIException(&quot;返回String类型错误&quot;);
        }
    }
    // 将原本的数据包装在ResultVO里
    return new ResultVO&lt;&gt;(data);
}
</code></pre>
<p>}<br>
重写的这两个方法是用来在controller将数据进行返回前进行增强操作，supports方法要返回为true才会执行beforeBodyWrite方法，所以如果有些情况不需要进行增强操作可以在supports方法里进行判断。对返回数据进行真正的操作还是在beforeBodyWrite方法中，我们可以直接在该方法里包装数据，这样就不需要每个接口都进行数据包装了，省去了很多麻烦。<br>
我们可以现在去掉接口的数据包装来看下效果：<br>
@GetMapping(&quot;/getUser&quot;)<br>
public User getUser() {<br>
User user = new User();<br>
user.setId(1L);<br>
user.setAccount(&quot;12345678&quot;);<br>
user.setPassword(&quot;12345678&quot;);<br>
user.setEmail(&quot;123@qq.com&quot;);<br>
// 注意哦，这里是直接返回的User类型，并没有用ResultVO进行包装<br>
return user;<br>
}<br>
然后我们来看下响应数据：</p>
<p>img<br>
成功对数据进行了包装！<br>
注意：beforeBodyWrite方法里包装数据无法对String类型的数据直接进行强转，所以要进行特殊处理，这里不讲过多的细节，有兴趣可以自行深入了解。<br>
总结</p>
<p>自此整个后端接口基本体系就构建完毕了<br>
通过Validator + 自动抛出异常来完成了方便的参数校验<br>
通过全局异常处理 + 自定义异常完成了异常操作的规范<br>
通过数据统一响应完成了响应数据的规范<br>
多个方面组装非常优雅的完成了后端接口的协调，让开发人员有更多的经历注重业务逻辑代码，轻松构建后端接口<br>
再次强调，项目体系该怎么构建、后端接口该怎么写都没有一个绝对统一的标准，不是说一定要按照本文的来才是最好的，你怎样都可以，本文每一个环节你都可以按照自己的想法来进行编码，我只是提供了一个思路！<br>
项目源码地址</p>
<p>https://github.com/RudeCrab/rude-java/tree/master/project-practice/validation-and-exception-handler</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>a-zA-Z0-9_- <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springboot整合apchepoi 实现excel的导入导出]]></title>
        <id>https://jayhablog.vercel.app/springboot-zheng-he-apchepoi-shi-xian-excel-de-dao-ru-dao-chu/</id>
        <link href="https://jayhablog.vercel.app/springboot-zheng-he-apchepoi-shi-xian-excel-de-dao-ru-dao-chu/">
        </link>
        <updated>2020-11-20T08:17:31.000Z</updated>
        <content type="html"><![CDATA[<p>转自ruoyi开发文档</p>
<h2 id="导入导出">导入导出</h2>
<p>在实际开发中经常需要使用导入导出功能来加快数据的操作。在项目中可以使用注解来完成此项功能。 在需要被导入导出的实体类属性添加<code>@Excel</code>注解  该注解编写在转载者在桌面的utils包内（以改良ruoyi包下的excelUtil 支持date、localdate、localdatetime转换。如有需要可以联系本网站管理员）</p>
<p>目前支持参数如下：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>sort</td>
<td>int</td>
<td>Integer.MAX_VALUE</td>
<td>导出时在excel中排序</td>
</tr>
<tr>
<td>name</td>
<td>String</td>
<td>空</td>
<td>导出到Excel中的名字</td>
</tr>
<tr>
<td>dateFormat</td>
<td>String</td>
<td>空</td>
<td>日期格式, 如: yyyy-MM-dd</td>
</tr>
<tr>
<td>dictType</td>
<td>String</td>
<td>空</td>
<td>如果是字典类型，请设置字典的type值 (如: sys_user_sex)</td>
</tr>
<tr>
<td>readConverterExp</td>
<td>String</td>
<td>空</td>
<td>读取内容转表达式 (如: 0=男,1=女,2=未知)</td>
</tr>
<tr>
<td>separator</td>
<td>String</td>
<td>,</td>
<td>分隔符，读取字符串组内容</td>
</tr>
<tr>
<td>scale</td>
<td>int</td>
<td>-1</td>
<td>BigDecimal 精度 默认:-1(默认不开启BigDecimal格式化)</td>
</tr>
<tr>
<td>roundingMode</td>
<td>int</td>
<td>BigDecimal.ROUND_HALF_EVEN</td>
<td>BigDecimal 舍入规则 默认:BigDecimal.ROUND_HALF_EVEN</td>
</tr>
<tr>
<td>columnType</td>
<td>Enum</td>
<td>Type.STRING</td>
<td>导出类型（0数字 1字符串）</td>
</tr>
<tr>
<td>height</td>
<td>String</td>
<td>14</td>
<td>导出时在excel中每个列的高度 单位为字符</td>
</tr>
<tr>
<td>width</td>
<td>String</td>
<td>16</td>
<td>导出时在excel中每个列的宽 单位为字符</td>
</tr>
<tr>
<td>suffix</td>
<td>String</td>
<td>空</td>
<td>文字后缀,如% 90 变成90%</td>
</tr>
<tr>
<td>defaultValue</td>
<td>String</td>
<td>空</td>
<td>当值为空时,字段的默认值</td>
</tr>
<tr>
<td>prompt</td>
<td>String</td>
<td>空</td>
<td>提示信息</td>
</tr>
<tr>
<td>combo</td>
<td>String</td>
<td>Null</td>
<td>设置只能选择不能输入的列内容</td>
</tr>
<tr>
<td>targetAttr</td>
<td>String</td>
<td>空</td>
<td>另一个类中的属性名称,支持多级获取,以小数点隔开</td>
</tr>
<tr>
<td>isStatistics</td>
<td>boolean</td>
<td>false</td>
<td>是否自动统计数据,在最后追加一行统计数据总和</td>
</tr>
<tr>
<td>type</td>
<td>Enum</td>
<td>Type.ALL</td>
<td>字段类型（0：导出导入；1：仅导出；2：仅导入）</td>
</tr>
</tbody>
</table>
<h3 id="导出实现流程">导出实现流程</h3>
<p>1、前端调用封装好的方法$.table.init，传入后台<code>exportUrl</code></p>
<pre><code class="language-javascript">var options = {
	exportUrl: prefix + &quot;/export&quot;,
	columns: [{
		field: 'id',
		title: '主键'
	},
	{
		field: 'name',
		title: '名称'
	}]
};
$.table.init(options);
</code></pre>
<p>2、添加导出按钮事件</p>
<pre><code class="language-html">&lt;a class=&quot;btn btn-warning&quot; onclick=&quot;$.table.exportExcel()&quot;&gt;
	&lt;i class=&quot;fa fa-download&quot;&gt;&lt;/i&gt; 导出
&lt;/a&gt;
</code></pre>
<p>3、在实体变量上添加@Excel注解</p>
<pre><code class="language-java">@Excel(name = &quot;用户序号&quot;, prompt = &quot;用户编号&quot;)
private Long userId;

@Excel(name = &quot;用户名称&quot;)
private String userName;
	
@Excel(name = &quot;用户性别&quot;, readConverterExp = &quot;0=男,1=女,2=未知&quot;)
private String sex;

@Excel(name = &quot;最后登陆时间&quot;, width = 30, dateFormat = &quot;yyyy-MM-dd HH:mm:ss&quot;)
private Date loginDate;
</code></pre>
<p>4、在Controller添加导出方法</p>
<pre><code class="language-java">@PostMapping(&quot;/export&quot;)
@ResponseBody
public AjaxResult export(User user)
{
	List&lt;User&gt; list = userService.selectUserList(user);
	ExcelUtil&lt;User&gt; util = new ExcelUtil&lt;User&gt;(User.class);
	return util.exportExcel(list, &quot;用户数据&quot;);
}
</code></pre>
<h3 id="导入实现流程">导入实现流程</h3>
<p>1、前端调用封装好的方法$.table.init，传入后台importUrl。</p>
<pre><code class="language-javascript">var options = {
	importUrl: prefix + &quot;/importData&quot;,
	columns: [{
		field: 'id',
		title: '主键'
	},
	{
		field: 'name',
		title: '名称'
	}]
};
$.table.init(options);
</code></pre>
<p>2、添加导入按钮事件</p>
<pre><code class="language-html">&lt;a class=&quot;btn btn-info&quot; onclick=&quot;$.table.importExcel()&quot;&gt;
	&lt;i class=&quot;fa fa-upload&quot;&gt;&lt;/i&gt; 导入
&lt;/a&gt;
</code></pre>
<p>3、添加导入前端代码，form默认id为importForm，也可指定importExcel(id)</p>
<pre><code class="language-html">&lt;!-- 导入区域 --&gt;
&lt;script id=&quot;importTpl&quot; type=&quot;text/template&quot;&gt;
&lt;form enctype=&quot;multipart/form-data&quot; class=&quot;mt20 mb10&quot;&gt;
	&lt;div class=&quot;col-xs-offset-1&quot;&gt;
		&lt;input type=&quot;file&quot; id=&quot;file&quot; name=&quot;file&quot;/&gt;
		&lt;div class=&quot;mt10 pt5&quot;&gt;
			&lt;input type=&quot;checkbox&quot; id=&quot;updateSupport&quot; name=&quot;updateSupport&quot; title=&quot;如果登录账户已经存在，更新这条数据。&quot;&gt; 是否更新已经存在的用户数据
			 &amp;nbsp;	&lt;a onclick=&quot;$.table.importTemplate()&quot; class=&quot;btn btn-default btn-xs&quot;&gt;&lt;i class=&quot;fa fa-file-excel-o&quot;&gt;&lt;/i&gt; 下载模板&lt;/a&gt;
		&lt;/div&gt;
		&lt;font color=&quot;red&quot; class=&quot;pull-left mt10&quot;&gt;
			提示：仅允许导入“xls”或“xlsx”格式文件！
		&lt;/font&gt;
	&lt;/div&gt;
&lt;/form&gt;
&lt;/script&gt;
</code></pre>
<p>4、在实体变量上添加@Excel注解，默认为导出导入，也可以单独设置仅导入Type.IMPORT</p>
<pre><code class="language-java">@Excel(name = &quot;用户序号&quot;)
private Long id;

@Excel(name = &quot;部门编号&quot;, type = Type.IMPORT)
private Long deptId;

@Excel(name = &quot;用户名称&quot;)
private String userName;

/** 导出部门多个对象 */
@Excels({
	@Excel(name = &quot;部门名称&quot;, targetAttr = &quot;deptName&quot;, type = Type.EXPORT),
	@Excel(name = &quot;部门负责人&quot;, targetAttr = &quot;leader&quot;, type = Type.EXPORT)
})
private SysDept dept;

/** 导出部门单个对象 */
@Excel(name = &quot;部门名称&quot;, targetAttr = &quot;deptName&quot;, type = Type.EXPORT)
private SysDept dept;
</code></pre>
<p>5、在Controller添加导入方法，updateSupport属性为是否存在则覆盖（可选）</p>
<pre><code class="language-java">@PostMapping(&quot;/importData&quot;)
@ResponseBody
public AjaxResult importData(MultipartFile file, boolean updateSupport) throws Exception
{
	ExcelUtil&lt;SysUser&gt; util = new ExcelUtil&lt;SysUser&gt;(SysUser.class);
	List&lt;SysUser&gt; userList = util.importExcel(file.getInputStream());
	String operName = ShiroUtils.getSysUser().getLoginName();
	String message = userService.importUser(userList, updateSupport, operName);
	return AjaxResult.success(message);
}
</code></pre>
<p>提示</p>
<p>也可以直接到main运行此方法测试。</p>
<pre><code class="language-java">InputStream is = new FileInputStream(new File(&quot;D:\\test.xlsx&quot;));
ExcelUtil&lt;Entity&gt; util = new ExcelUtil&lt;Entity&gt;(Entity.class);
List&lt;Entity&gt; userList = util.importExcel(is);
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springboot全局异常处理]]></title>
        <id>https://jayhablog.vercel.app/springboot-quan-ju-yi-chang-chu-li/</id>
        <link href="https://jayhablog.vercel.app/springboot-quan-ju-yi-chang-chu-li/">
        </link>
        <updated>2020-11-20T08:16:53.000Z</updated>
        <content type="html"><![CDATA[<p>转自ruoyi开发文档</p>
<h2 id="异常处理">异常处理</h2>
<p>通常一个web框架中，有大量需要处理的异常。比如业务异常，权限不足等等。前端通过弹出提示信息的方式告诉用户出了什么错误。 通常情况下我们用try.....catch.... 对异常进行捕捉处理，但是在实际项目中对业务模块进行异常捕捉，会造成代码重复和繁杂， 我们希望代码中只有业务相关的操作，所有的异常我们单独设立一个类来处理它。全局异常就是对框架所有异常进行统一管理。 我们在可能发生异常的方法里throw抛给控制器。然后由全局异常处理器对异常进行统一处理。 如此，我们的<code>Controller</code>中的方法就可以很简洁了。</p>
<p>所谓全局异常处理器就是使用<code>@ControllerAdvice</code>注解。示例如下：</p>
<p>1、统一返回实体定义</p>
<pre><code class="language-java">package com.ruoyi.common.core.domain;

import java.util.HashMap;

/**
 * 操作消息提醒
 * 
 * @author ruoyi
 */
public class AjaxResult extends HashMap&lt;String, Object&gt;
{
    private static final long serialVersionUID = 1L;

    /**
     * 返回错误消息
     * 
     * @param code 错误码
     * @param msg 内容
     * @return 错误消息
     */
    public static AjaxResult error(String msg)
    {
        AjaxResult json = new AjaxResult();
        json.put(&quot;msg&quot;, msg);
        json.put(&quot;code&quot;, 500);
        return json;
    }

    /**
     * 返回成功消息
     * 
     * @param msg 内容
     * @return 成功消息
     */
    public static AjaxResult success(String msg)
    {
        AjaxResult json = new AjaxResult();
        json.put(&quot;msg&quot;, msg);
        json.put(&quot;code&quot;, 0);
        return json;
    }
}
</code></pre>
<p>2、定义登录异常定义</p>
<pre><code class="language-java">package com.ruoyi.common.exception;

/**
 * 登录异常
 * 
 * @author ruoyi
 */
public class LoginException extends RuntimeException
{
    private static final long serialVersionUID = 1L;

    protected final String message;

    public LoginException(String message)
    {
        this.message = message;
    }

    @Override
    public String getMessage()
    {
        return message;
    }
}
</code></pre>
<p>3、基于@ControllerAdvice注解的Controller层的全局异常统一处理</p>
<pre><code class="language-java">package com.ruoyi.framework.web.exception;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.web.bind.annotation.ExceptionHandler;
import org.springframework.web.bind.annotation.RestControllerAdvice;
import com.ruoyi.common.core.domain.AjaxResult;
import com.ruoyi.common.exception.LoginException;

/**
 * 全局异常处理器
 * 
 * @author ruoyi
 */
@RestControllerAdvice
public class GlobalExceptionHandler
{
    private static final Logger log = LoggerFactory.getLogger(GlobalExceptionHandler.class);
	
	/**
     * 登录异常
     */
    @ExceptionHandler(LoginException.class)
    public AjaxResult loginException(LoginException e)
    {
        log.error(e.getMessage(), e);
        return AjaxResult.error(e.getMessage());
    }
}
</code></pre>
<p>4、测试访问请求</p>
<pre><code class="language-java">@Controller
public class SysIndexController 
{
    /**
     * 首页方法
     */
    @GetMapping(&quot;/index&quot;)
    public String index(ModelMap mmap)
    {
        /**
         * 模拟用户未登录，抛出业务逻辑异常
         */
        SysUser user = ShiroUtils.getSysUser();
        if (StringUtils.isNull(user))
		{
            throw new LoginException(&quot;用户未登录，无法访问请求。&quot;);
        }
		mmap.put(&quot;user&quot;, user);
        return &quot;index&quot;;
    }
}
</code></pre>
<p>根据上面代码含义，当我们未登录访问/index时就会发生LoginException业务逻辑异常，按照我们之前的全局异常配置以及统一返回实体实例化，访问后会出现AjaxResult格式JSON数据， 下面我们运行项目访问查看效果。<br>
界面输出内容如下所示：</p>
<pre><code class="language-json">{
    &quot;msg&quot;: &quot;用户未登录，无法访问请求。&quot;,
    &quot;code&quot;: 500
}
</code></pre>
<p><code>对于一些特殊情况，如接口需要返回json，页面请求返回html可以使用如下方法</code>：</p>
<pre><code class="language-java">@ExceptionHandler(LoginException.class)
public Object loginException(HttpServletRequest request, LoginException e)
{
	log.error(e.getMessage(), e);

	if (ServletUtils.isAjaxRequest(request))
	{
		return AjaxResult.error(e.getMessage());
	}
	else
	{
		return new ModelAndView(&quot;/error/500&quot;);
	}
}
</code></pre>
<p>若依系统的全局异常处理器<code>GlobalExceptionHandler</code><br>
注意：如果全部异常处理返回<code>json</code>，那么可以使用<code>@RestControllerAdvice</code>代替<code>@ControllerAdvice</code>，这样在方法上就可以不需要添加<code>@ResponseBody</code>。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[算法归纳]]></title>
        <id>https://jayhablog.vercel.app/kuai-man-zhi-zhen/</id>
        <link href="https://jayhablog.vercel.app/kuai-man-zhi-zhen/">
        </link>
        <updated>2020-10-22T12:29:04.000Z</updated>
        <content type="html"><![CDATA[<h2 id="快慢指针">快慢指针</h2>
<h4 id="floyd判圈算法龟兔赛跑算法">floyd判圈算法（龟兔赛跑算法）</h4>
<blockquote>
<p>遇到场合：判断链表是否循环</p>
</blockquote>
<h6 id="算法描述">算法描述：</h6>
<p>假想「乌龟」和「兔子」在链表上移动，「兔子」跑得快，「乌龟」跑得慢。当「乌龟」和「兔子」从链表上的同一个节点开始移动时，如果该链表中没有环，那么「兔子」将一直处于「乌龟」的前方；如果该链表中有环，那么「兔子」会先于「乌龟」进入环，并且一直在环内移动。等到「乌龟」进入环时，由于「兔子」的速度快，它一定会在某个时刻与乌龟相遇，即套了「乌龟」若干圈。</p>
<p>即有两个指针，他们速度不同 如 A指针=A指针.next B指针=B指针.next.next 那么他们肯定会相遇</p>
<pre><code class="language-java">public boolean hasCycle(ListNode head){
        if (head == null || head.next == null) {
            return false;//只有两个时候不用判断
        }
        ListNode A= head;//慢指针（乌龟指针）
        ListNode B =head.next;//快指针（兔子指针）
        while(A != B){
        if (B == null|| B.next==null){
            return  false;
        }
            A= A.next;
            B=B.next.next;
        }
        return  true;
</code></pre>
<p>时间复杂度O（N）</p>
<p>空间复杂度O（1）</p>
<hr>
<h2 id="贪心算法">贪心算法</h2>
<p>划分字母区间</p>
<p>题目</p>
<blockquote>
<blockquote>
<p>字符串 S 由小写字母组成。我们要把这个字符串划分为尽可能多的片段，同一个字母只会出现在其中的一个片段。返回一个表示每个字符串片段的长度的列表。</p>
<p>示例 1：</p>
<p>输入：S = &quot;ababcbacadefegdehijhklij&quot;<br>
输出：[9,7,8]<br>
解释：<br>
划分结果为 &quot;ababcbaca&quot;, &quot;defegde&quot;, &quot;hijhklij&quot;。<br>
每个字母最多出现在一个片段中。<br>
像 &quot;ababcbacadefegde&quot;, &quot;hijhklij&quot; 的划分是错误的，因为划分的片段数较少。</p>
<p>来源：力扣（LeetCode）<br>
链接：https://leetcode-cn.com/problems/partition-labels<br>
著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p>
</blockquote>
</blockquote>
<p>该题使用贪心算法，具体思路为，先把字符串中出现的char，将他们最后出现的下标保存在一个长度为26（因为有26个字母）的数组内</p>
<pre><code class="language-java">for (int i = 0; i &lt; 所给定字符串.length; i++) {
            last[S.charAt(i) - 'a'] = i;
        }
</code></pre>
<p>然后设置两个指针start和end，初始时为0，然后</p>
<pre><code class="language-java">end = Math.max(end, last[S.charAt(i) - 'a']);
</code></pre>
<p>end不断更新为i字符在该字符串的最后位置，如果在i！=end时候有字符还有更后的最后位置，那么end就会更新为该字符的最后位置。</p>
<p>如果i==end时候，就代表获取了这个字符区间长度（因为前面的字符都不会在剩余的字符串中出现，可以切的尽量多）。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis作为nosql的使用（详细）与集成到springboot缓存]]></title>
        <id>https://jayhablog.vercel.app/redis-zuo-wei-nosql-de-shi-yong-xiang-xi-yu-ji-cheng-dao-springboot-huan-cun/</id>
        <link href="https://jayhablog.vercel.app/redis-zuo-wei-nosql-de-shi-yong-xiang-xi-yu-ji-cheng-dao-springboot-huan-cun/">
        </link>
        <updated>2020-10-22T12:27:01.000Z</updated>
        <content type="html"><![CDATA[<p>声明 由于本文部分借鉴菜鸟教程redis教程 https://www.runoob.com/redis/redis-geo.html</p>
<p>侵删。</p>
<h2 id="redis概述">redis概述</h2>
<p>redis是典型的noSQL数据库，以 <mark>key-value键值对</mark> 的方式存储数据，默认端口为6379</p>
<p>可以用来作<strong>数据库、缓存、消息中间件</strong></p>
<p>特点-&gt;</p>
<ul>
<li>基于内存实现</li>
<li>以单线程方式实现</li>
<li>默认有16个数据库</li>
</ul>
<p>redis可以设置成常开状态</p>
<p>首先 在shell界面启动进入redis命令为</p>
<pre><code class="language-bash">redis-cli
</code></pre>
<p>在redis界面可以使用</p>
<pre><code class="language-bash">dbsize #查看数据库大小
select [value] #使用第几个数据库
keys * #查看所有的key
FLUSHDB #清空此数据库
exist [key] #该key是否存在
move [key] #把这个键值对移到另一个库
EXPIRE [KEY] [TIME] #设置key过期的时间
ttl [key] #查看key剩余时间
type [key] #查看该key的value是什么类型
del [key] #删除某个键值对
</code></pre>
<hr>
<p>…………………………………………………………………………………………………………………………………………………</p>
<hr>
<h2 id="redis五大类型">redis五大类型</h2>
<blockquote>
<p>String类型</p>
</blockquote>
<pre><code class="language-bash">incr [key] #让他自增1
decr [key] #让他自减1
INCRBY [KEY] [NUM] #自增NUM个值 DECRBY同理
GETRANGE [KEY] [从哪开始] [从哪结束] #相当于substr
append [key] [string] #相当于java的append
SETRANGE [KEY] [STRING] #相当于substr＆replace
setex #设置过期时间
setnx #如果该key不存在才赋值
mset #一次设置多个键值对
mget #一次获取多个值
msetnx #看上面就知道什么意思了 只是这是个原子性操作（即只有成功或失败 没有一部分成功一部分失败）
getset #获取完这个值后再set这个值
set key value #存放键值对
</code></pre>
<p>因为json字符串也是String 存对象常用json字符串</p>
<p>或者以 <mark><em>[实体类]:[对象名]:[属性] [值]</em></mark> 多个属性 一个对象名 这种方式存储一个对象</p>
<hr>
<blockquote>
<p>List类型</p>
</blockquote>
<p>把list看作一个链表</p>
<p>L代表从左边 R代表从右边</p>
<p>有-》</p>
<pre><code class="language-bash">LPUSH [key] [value...] #创建链表/从左边插入数据 Rpush即从右边
Lrange [key] [start] [end] #序号开始 从左边开始遍历 Rrange即从右边
LPOP [key] [n] #从左边移出去n个值
Lindex #通过下标获取值 （从0开始 上面的从1开始）
Lrem #移除
#这些命令也可以组合
Lset #替换某个下标的值
Linsert #在某一个具体的值前面或者后面插入一个新的值
</code></pre>
<hr>
<blockquote>
<p>Set 类型</p>
</blockquote>
<table>
<thead>
<tr>
<th>1</th>
<th style="text-align:center">SADD key member1 [member2]向集合添加一个或多个成员</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/sets-scard.html">SCARD key</a>  获取集合的成员数</td>
</tr>
<tr>
<td>3</td>
<td style="text-align:center">[SDIFF key1 <a href="https://www.runoob.com/redis/sets-sdiff.html">key2]</a>  返回第一个集合与其他集合之间的差异。</td>
</tr>
<tr>
<td>4</td>
<td style="text-align:center">[SDIFFSTORE destination key1 <a href="https://www.runoob.com/redis/sets-sdiffstore.html">key2]</a>  返回给定所有集合的差集并存储在 destination 中</td>
</tr>
<tr>
<td>5</td>
<td style="text-align:center">[SINTER key1 <a href="https://www.runoob.com/redis/sets-sinter.html">key2]</a>  返回给定所有集合的交集</td>
</tr>
<tr>
<td>6</td>
<td style="text-align:center">[SINTERSTORE destination key1 <a href="https://www.runoob.com/redis/sets-sinterstore.html">key2]</a>  返回给定所有集合的交集并存储在 destination 中</td>
</tr>
<tr>
<td>7</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/sets-sismember.html">SISMEMBER key member</a>  判断 member 元素是否是集合 key 的成员</td>
</tr>
<tr>
<td>8</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/sets-smembers.html">SMEMBERS key</a>  返回集合中的所有成员</td>
</tr>
<tr>
<td>9</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/sets-smove.html">SMOVE source destination member</a>  将 member 元素从 source 集合移动到 destination 集合</td>
</tr>
<tr>
<td>10</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/sets-spop.html">SPOP key</a>  移除并返回集合中的一个随机元素</td>
</tr>
<tr>
<td>11</td>
<td style="text-align:center">[SRANDMEMBER key <a href="https://www.runoob.com/redis/sets-srandmember.html">count]</a>  返回集合中一个或多个随机数</td>
</tr>
<tr>
<td>12</td>
<td style="text-align:center">[SREM key member1 <a href="https://www.runoob.com/redis/sets-srem.html">member2]</a>  移除集合中一个或多个成员</td>
</tr>
<tr>
<td>13</td>
<td style="text-align:center">[SUNION key1 <a href="https://www.runoob.com/redis/sets-sunion.html">key2]</a>  返回所有给定集合的并集</td>
</tr>
<tr>
<td>14</td>
<td style="text-align:center">[SUNIONSTORE destination key1 <a href="https://www.runoob.com/redis/sets-sunionstore.html">key2]</a>  所有给定集合的并集存储在 destination 集合中</td>
</tr>
<tr>
<td>15</td>
<td style="text-align:center">[SSCAN key cursor <a href="https://www.runoob.com/redis/sets-sscan.html">MATCH pattern] [COUNT count]</a>  迭代集合中的元素</td>
</tr>
</tbody>
</table>
<hr>
<blockquote>
<p>Hash类型</p>
</blockquote>
<p>Redis hash 是一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。</p>
<table>
<thead>
<tr>
<th>1</th>
<th style="text-align:center">[HDEL key field1 <a href="https://www.runoob.com/redis/hashes-hdel.html">field2]</a>  删除一个或多个哈希表字段</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td style="text-align:center">hset key [filed value...] 创建hash</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hexists.html">HEXISTS key field</a>  查看哈希表 key 中，指定的字段是否存在。</td>
</tr>
<tr>
<td>3</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hget.html">HGET key field</a>  获取存储在哈希表中指定字段的值。</td>
</tr>
<tr>
<td>4</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hgetall.html">HGETALL key</a>  获取在哈希表中指定 key 的所有字段和值</td>
</tr>
<tr>
<td>5</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hincrby.html">HINCRBY key field increment</a>  为哈希表 key 中的指定字段的整数值加上增量 increment 。</td>
</tr>
<tr>
<td>6</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hincrbyfloat.html">HINCRBYFLOAT key field increment</a>  为哈希表 key 中的指定字段的浮点数值加上增量 increment 。</td>
</tr>
<tr>
<td>7</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hkeys.html">HKEYS key</a>  获取所有哈希表中的字段</td>
</tr>
<tr>
<td>8</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hlen.html">HLEN key</a>  获取哈希表中字段的数量</td>
</tr>
<tr>
<td>9</td>
<td style="text-align:center">[HMGET key field1 <a href="https://www.runoob.com/redis/hashes-hmget.html">field2]</a>  获取所有给定字段的值</td>
</tr>
<tr>
<td>10</td>
<td style="text-align:center">[HMSET key field1 value1 <a href="https://www.runoob.com/redis/hashes-hmset.html">field2 value2 ]</a>  同时将多个 field-value (域-值)对设置到哈希表 key 中。</td>
</tr>
<tr>
<td>11</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hset.html">HSET key field value</a>  将哈希表 key 中的字段 field 的值设为 value 。</td>
</tr>
<tr>
<td>12</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hsetnx.html">HSETNX key field value</a>  只有在字段 field 不存在时，设置哈希表字段的值。</td>
</tr>
<tr>
<td>13</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hvals.html">HVALS key</a>  获取哈希表中所有值。</td>
</tr>
<tr>
<td>14</td>
<td style="text-align:center">[HSCAN key cursor <a href="https://www.runoob.com/redis/hashes-hscan.html">MATCH pattern] [COUNT count]</a>  迭代哈希表中的键值</td>
</tr>
</tbody>
</table>
<blockquote>
<p>有序集合zset</p>
</blockquote>
<p>Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员。</p>
<p>不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。</p>
<p>有序集合的成员是唯一的,但分数(score)却可以重复。</p>
<p>集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。</p>
<table>
<thead>
<tr>
<th>1</th>
<th>[ZADD key score1 member1 <a href="https://www.runoob.com/redis/sorted-sets-zadd.html">score2 member2]</a>  向有序集合添加一个或多个成员，或者更新已存在成员的分数</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zcard.html">ZCARD key</a>  获取有序集合的成员数</td>
</tr>
<tr>
<td>3</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zcount.html">ZCOUNT key min max</a>  计算在有序集合中指定区间分数的成员数</td>
</tr>
<tr>
<td>4</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zincrby.html">ZINCRBY key increment member</a>  有序集合中对指定成员的分数加上增量 increment</td>
</tr>
<tr>
<td>5</td>
<td>[ZINTERSTORE destination numkeys key <a href="https://www.runoob.com/redis/sorted-sets-zinterstore.html">key ...]</a>  计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 destination 中</td>
</tr>
<tr>
<td>6</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zlexcount.html">ZLEXCOUNT key min max</a>  在有序集合中计算指定字典区间内成员数量</td>
</tr>
<tr>
<td>7</td>
<td>[ZRANGE key start stop <a href="https://www.runoob.com/redis/sorted-sets-zrange.html">WITHSCORES]</a>  通过索引区间返回有序集合指定区间内的成员</td>
</tr>
<tr>
<td>8</td>
<td>[ZRANGEBYLEX key min max <a href="https://www.runoob.com/redis/sorted-sets-zrangebylex.html">LIMIT offset count]</a>  通过字典区间返回有序集合的成员</td>
</tr>
<tr>
<td>9</td>
<td>[ZRANGEBYSCORE key min max <a href="https://www.runoob.com/redis/sorted-sets-zrangebyscore.html">WITHSCORES] [LIMIT]</a>  通过分数返回有序集合指定区间内的成员</td>
</tr>
<tr>
<td>10</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zrank.html">ZRANK key member</a>  返回有序集合中指定成员的索引</td>
</tr>
<tr>
<td>11</td>
<td>[ZREM key member <a href="https://www.runoob.com/redis/sorted-sets-zrem.html">member ...]</a>  移除有序集合中的一个或多个成员</td>
</tr>
<tr>
<td>12</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zremrangebylex.html">ZREMRANGEBYLEX key min max</a>  移除有序集合中给定的字典区间的所有成员</td>
</tr>
<tr>
<td>13</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zremrangebyrank.html">ZREMRANGEBYRANK key start stop</a>  移除有序集合中给定的排名区间的所有成员</td>
</tr>
<tr>
<td>14</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zremrangebyscore.html">ZREMRANGEBYSCORE key min max</a>  移除有序集合中给定的分数区间的所有成员</td>
</tr>
<tr>
<td>15</td>
<td>[ZREVRANGE key start stop <a href="https://www.runoob.com/redis/sorted-sets-zrevrange.html">WITHSCORES]</a>  返回有序集中指定区间内的成员，通过索引，分数从高到低</td>
</tr>
<tr>
<td>16</td>
<td>[ZREVRANGEBYSCORE key max min <a href="https://www.runoob.com/redis/sorted-sets-zrevrangebyscore.html">WITHSCORES]</a>  返回有序集中指定分数区间内的成员，分数从高到低排序</td>
</tr>
<tr>
<td>17</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zrevrank.html">ZREVRANK key member</a>  返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序</td>
</tr>
<tr>
<td>18</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zscore.html">ZSCORE key member</a>  返回有序集中，成员的分数值</td>
</tr>
<tr>
<td>19</td>
<td>[ZUNIONSTORE destination numkeys key <a href="https://www.runoob.com/redis/sorted-sets-zunionstore.html">key ...]</a>  计算给定的一个或多个有序集的并集，并存储在新的 key 中</td>
</tr>
<tr>
<td>20</td>
<td>[ZSCAN key cursor <a href="https://www.runoob.com/redis/sorted-sets-zscan.html">MATCH pattern] [COUNT count]</a>  迭代有序集合中的元素（包括元素成员和元素分值）</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="另外的类型">另外的类型</h2>
<blockquote>
<p>geospatial 地理位置</p>
</blockquote>
<pre><code class="language-bash">geoadd [国家]:city/town/... [区域名] [经纬度坐标] #添加一个城市/镇/街信息 [国家]:[什么区域]是key [区域名]是member 
</code></pre>
<p>但一般不用自己添加 使用java程序下载数据集一次性导入</p>
<pre><code class="language-bash">geopos [key] [member] #获取指定的经纬度
 GEODIST key member1 member2 [unit] #获取两者之间的距离 [unit]可以是km m dm ft（英尺） mi（英里）
 georadius #已给定经纬度为中心，找出某一个半径内的元素
 geohash #将经纬度坐标转换成hash字符串
 
</code></pre>
<p>其底层是zset 可以使用zset指令操作geospatial</p>
<hr>
<blockquote>
<p>HyperLogLog基数</p>
</blockquote>
<p>该元素是基数统计的算法</p>
<p>网页的UV（即一个人访问一个网站多次，还是算作一个人访问）</p>
<p>传统方式，set方式保存用户id，统计set元素数量作为判断。</p>
<p>HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。(12kb)</p>
<p>但有错误率(0.81％)</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>命令及描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>[PFADD key element <a href="https://www.runoob.com/redis/hyperloglog-pfadd.html">element ...]</a>  添加指定元素到 HyperLogLog 中。</td>
</tr>
<tr>
<td>2</td>
<td>[PFCOUNT key <a href="https://www.runoob.com/redis/hyperloglog-pfcount.html">key ...]</a>  返回给定 HyperLogLog 的基数估算值。</td>
</tr>
<tr>
<td>3</td>
<td>[PFMERGE destkey sourcekey <a href="https://www.runoob.com/redis/hyperloglog-pfmerge.html">sourcekey ...]</a>  将多个 HyperLogLog 合并为一个 HyperLogLog</td>
</tr>
</tbody>
</table>
<hr>
<p>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</p>
<hr>
<blockquote>
<p>事务</p>
</blockquote>
<p>redis事务不能保证原子性 使用multi命令开启 exec执行，一条语句错误不影响其他语句的执行</p>
<h2 id="springboot集成redis">springboot集成redis</h2>
<p>springboot2.x后 对redis的 底层放弃了jedis改采用lettuce</p>
<p>jedis：采用的是直连的server，多个线程操作的情况下，没有锁会不安全。</p>
<p>lettuce：底层采用netty，是NIO，实例可在多线程共享，多线程情况下也安全。</p>
<p>spring使用redisTemplate的方式操作redis，需要注意的是redisTemplate没有过多的设置，所以redis<strong>对象需要序列化</strong>，implements Serializable的方式固然可以存取值。但这只是在jdk中序列化，直接在redis仓库中查看会乱码，所以我们采用部分转化成String，部分转化成json的方式进行储存对象。（下面代码为固定模板，直接套用即可）</p>
<pre><code class="language-java">import com.fasterxml.jackson.annotation.JsonAutoDetect;
import com.fasterxml.jackson.annotation.PropertyAccessor;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.StringRedisSerializer;

import javax.xml.transform.Templates;
@Configuration
public class redisConfig {
    /**
     * 自定义redisTemplate 使之序列化到redis仓库不乱码
     * @param redisConnectionFactory
     * @return
     */
    @Bean
    @SuppressWarnings(&quot;all&quot;)
    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;String, Object&gt;();
        template.setConnectionFactory(factory);
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
        ObjectMapper om = new ObjectMapper();
        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
        jackson2JsonRedisSerializer.setObjectMapper(om);
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();

        // key采用String的序列化方式
        template.setKeySerializer(stringRedisSerializer);
        // hash的key也采用String的序列化方式
        template.setHashKeySerializer(stringRedisSerializer);
        // value序列化方式采用jackson
        template.setValueSerializer(jackson2JsonRedisSerializer);
        // hash的value序列化方式采用jackson
        template.setHashValueSerializer(jackson2JsonRedisSerializer);
        template.afterPropertiesSet();

        return template;

    }
}
</code></pre>
<p>之后</p>
<p>在application.yaml里配置有关redis的属性</p>
<pre><code class="language-yaml">spring:
  redis:
    host: 8.129.58.219
    password: djiowandijd
    client-name: redisClient
    lettuce:
      pool:
        max-active: 8
</code></pre>
<p>再之后，就可以用redistemplate封装的各种方法，操作各种类型的数据了，例如</p>
<pre><code class="language-java">Customer testCustomer = new Customer(1, &quot;imgLocaltion&quot;, 1, &quot;testAccount&quot;, &quot;testPassword&quot;, 200d, &quot;testName&quot;, &quot;testPhone&quot;, 2);
        redisTemplate.opsForValue().set(&quot;jayhaKey1&quot;,testCustomer);
        System.out.println(redisTemplate.opsForValue().get(&quot;jayhaKey1&quot;));
</code></pre>
<h2 id="springboot缓存抽象重点">springboot缓存抽象<mark>重点</mark></h2>
<p>spring定义了cache和cachemanager接口来统一不同的注解技术，并支持使用Jcache（JSR107</p>
<p>)注解简化开发</p>
<pre><code class="language-java">@Cacheable //主要针对方法配置，将结果进行缓存 主要用于查询的方法上
@CacheEvict //清空缓存 主要用于delete
@CachePut //保证方法被调用，又缓存 主要用于update
@EnableCaching //开启缓存注解支持
</code></pre>
<p>三个注解都有”value“属性， value属性相同时即是同一个缓存</p>
<h3 id="cacheable">Cacheable</h3>
<p>将方法的运行结果进行缓存;以后再要相同的数据,直接从缓存中获取,不用调用方法:<br>
CacheManager管理多个Cache组件的,对缓存的真正CRUD操作在Cache组件中,每一个缓存组件有自己唯一一个名字;</p>
<p>cacheable几个属性:<br>
cacheNames/value:指定缓存组件的名字;可以是多个</p>
<p>key:缓存数据使用的key;可以用它来指定。默认是使用方法参数的值 1-方法的返回值</p>
<p>编写SPEL; #id;参数id的值<br>
例如#root.method.name获取方法名  #root.args[0]获取参数 #result 结果 #result.id 结果对象的id<br>
keyGenerator: key的生成器;可以自己指定key的生成器的组件id key/keyGenerator: 二选一</p>
<p>cacheManager:指定缓存管理器;或者cacheResol ver指定获取解析器<br>
condition:指定符合条件的情况下才缓存:<br>
unless:否定缓存;当unless指定的条件为true,方法的返回值就不会被缓存;可以获取到结果进行判断<br>
unless = &quot;#result == null&quot;<br>
sync:是否使用异步模式</p>
<h3 id="cacheput">CachePut</h3>
<p>主要放在更新的方法上</p>
<p>在cachePut注解中，可以key指定为“#result.id(主键)”达到更新数据库同时更新缓存的目的</p>
<h3 id="cacheevict">CacheEvict</h3>
<p>主要用于删除的方法上，直接删除这个数据的缓存。</p>
<h3 id="caching">Caching</h3>
<p>上面三个注解的组合注解，适用于较为复杂的缓存</p>
<h3 id="cacheconfig">CacheConfig</h3>
<p>放在service类上 抽取缓存公共配置</p>
<p>比如cacheName等于其他注解的value 该类下所有cache的value都会变成这个</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis面试题]]></title>
        <id>https://jayhablog.vercel.app/redis-mian-shi-ti/</id>
        <link href="https://jayhablog.vercel.app/redis-mian-shi-ti/">
        </link>
        <updated>2020-10-22T12:23:36.000Z</updated>
        <content type="html"><![CDATA[<p>搬运自https://blog.csdn.net/Butterfly_resting/article/details/89668661</p>
<p>本文的面试题如下：<br>
Redis 持久化机制<br>
缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级等问题<br>
热点数据和冷数据是什么<br>
Memcache与Redis的区别都有哪些？<br>
单线程的redis为什么这么快<br>
redis的数据类型，以及每种数据类型的使用场景，Redis 内部结构<br>
redis的过期策略以及内存淘汰机制【～】<br>
Redis 为什么是单线程的，优点<br>
如何解决redis的并发竞争key问题<br>
Redis 集群方案应该怎么做？都有哪些方案？<br>
有没有尝试进行多机redis 的部署？如何保证数据一致的？<br>
对于大量的请求怎么样处理<br>
Redis 常见性能问题和解决方案？<br>
讲解下Redis线程模型<br>
为什么Redis的操作是原子性的，怎么保证原子性的？<br>
Redis事务<br>
Redis实现分布式锁</p>
<hr>
<h2 id="redis-持久化机制">Redis 持久化机制</h2>
<p>Redis是一个支持持久化的内存数据库，通过持久化机制把内存中的数据同步到硬盘文件来保证数据持久化。当Redis重启后通过把硬盘文件重新加载到内存，就能达到恢复数据的目的。<br>
实现：单独创建fork()一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，内存释放。</p>
<p><strong>RDB</strong>是Redis默认的持久化方式。按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即Snapshot快照存储，对应产生的数据文件为dump.rdb，通过配置文件中的save参数来定义快照的周期。（ 快照可以是其所表示的数据的一个副本，也可以是数据的一个复制品。）<br>
<strong>AOF</strong>：Redis会将每一个收到的写命令都通过Write函数追加到文件最后，类似于MySQL的binlog。当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。<br>
当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。</p>
<h2 id="缓存雪崩-缓存穿透-缓存预热-缓存更新-缓存降级等问题">缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级等问题</h2>
<p><strong>缓存雪崩</strong>我们可以简单的理解为：由于原有缓存失效，新缓存未到期间<br>
(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。<br>
<strong>解决办法</strong>：<br>
大多数系统设计者考虑用加锁（ 最多的解决方案）或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。还有一个简单方案就时讲缓存失效时间分散开。</p>
<p>二、<strong>缓存穿透</strong><br>
缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。<br>
<strong>解决办法;</strong><br>
最常见的则是采用<strong>布隆过滤器</strong>，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。<br>
另外也有一个更为<strong>简单粗暴的方法</strong>，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。<br>
5TB的硬盘上放满了数据，请写一个算法将这些数据进行排重。如果这些数据是一些32bit大小的数据该如何解决？如果是64bit的呢？</p>
<p>对于空间的利用到达了一种极致，那就是Bitmap和布隆过滤器(Bloom Filter)。<br>
Bitmap： 典型的就是哈希表<br>
缺点是，Bitmap对于每个元素只能记录1bit信息，如果还想完成额外的功能，恐怕只能靠牺牲更多的空间、时间来完成了。</p>
<p><strong>布隆过滤器（推荐）</strong><br>
就是引入了k(k&gt;1)k(k&gt;1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。<br>
它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。<br>
Bloom-Filter算法的<strong>核心思想</strong>就是利用多个不同的Hash函数来解决“冲突”。<br>
Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是Bloom-Filter的基本思想。<br>
Bloom-Filter一般用于在大数据量的集合中判定某元素是否存在。<br>
<strong>受提醒补充：缓存穿透与缓存击穿的区别</strong><br>
<strong>缓存击穿</strong>：是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据。<br>
解决方案;在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key。<br>
增：给一个我公司处理的案例：背景双机拿token，token在存一份到redis，保证系统在token过期时都只有一个线程去获取token;线上环境有两台机器，故使用分布式锁实现。</p>
<p>三、<strong>缓存预热</strong><br>
缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！<br>
解决思路：<br>
1、直接写个缓存刷新页面，上线时手工操作下；<br>
2、数据量不大，可以在项目启动的时候自动进行加载；<br>
3、定时刷新缓存；</p>
<p>四、<strong>缓存更新</strong><br>
除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：<br>
（1）定时去清理过期的缓存；<br>
（2）当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。<br>
两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。<br>
五、<strong>缓存降级</strong><br>
当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。<br>
降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。<br>
以参考日志级别设置预案：<br>
（1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；<br>
（2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；<br>
（3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；<br>
（4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</p>
<p>服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。</p>
<h2 id="热点数据和冷数据是什么">热点数据和冷数据是什么</h2>
<p>热点数据，缓存才有价值<br>
对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况考虑使用缓存<br>
对于上面两个例子，寿星列表、导航信息都存在一个特点，就是信息修改频率不高，读取通常非常高的场景。<br>
对于热点数据，比如我们的某IM产品，生日祝福模块，当天的寿星列表，缓存以后可能读取数十万次。再举个例子，某导航产品，我们将导航信息，缓存以后可能读取数百万次。<br>
**数据更新前至少读取两次，**缓存才有意义。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。<br>
那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享数等是非常典型的热点数据，但是又不断变化，此时就需要将数据同步保存到Redis缓存，减少数据库压力。</p>
<h2 id="memcache与redis的区别都有哪些">Memcache与Redis的区别都有哪些？</h2>
<p>1)、存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，redis可以持久化其数据<br>
2)、数据支持类型 memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 ，提供list，set，zset，hash等数据结构的存储<br>
3)、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。<br>
4). value 值大小不同：Redis 最大可以达到 512M；memcache 只有 1mb。<br>
5）redis的速度比memcached快很多<br>
6）Redis支持数据的备份，即master-slave模式的数据备份。</p>
<h2 id="单线程的redis为什么这么快">单线程的redis为什么这么快</h2>
<p>(一)纯内存操作<br>
(二)单线程操作，避免了频繁的上下文切换<br>
(三)采用了非阻塞I/O多路复用机制</p>
<h2 id="redis的数据类型以及每种数据类型的使用场景">redis的数据类型，以及每种数据类型的使用场景</h2>
<p>回答：一共五种<br>
(一)String<br>
这个其实没啥好说的，最常规的set/get操作，value可以是String也可以是数字。一般做一些复杂的计数功能的缓存。<br>
(二)hash<br>
这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。博主在做单点登录的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。<br>
(三)list<br>
使用List的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。本人还用一个场景，很合适—取行情信息。就也是个生产者和消费者的场景。LIST可以很好的完成排队，先进先出的原则。<br>
(四)set<br>
因为set堆放的是一堆不重复值的集合。所以可以做全局去重的功能。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。<br>
另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。<br>
(五)sorted set<br>
sorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作。</p>
<h2 id="redis-内部结构">Redis 内部结构</h2>
<ul>
<li>dict 本质上是为了解决算法中的查找问题（Searching）是一个用于维护key和value映射关系的数据结构，与很多语言中的Map或dictionary类似。 本质上是为了解决算法中的查找问题（Searching）</li>
<li>sds sds就等同于char * 它可以存储任意二进制数据，不能像C语言字符串那样以字符’\0’来标识字符串的结 束，因此它必然有个长度字段。</li>
<li>skiplist （跳跃表） 跳表是一种实现起来很简单，单层多指针的链表，它查找效率很高，堪比优化过的二叉平衡树，且比平衡树的实现，</li>
<li>quicklist</li>
<li>ziplist 压缩表 ziplist是一个编码后的列表，是由一系列特殊编码的连续内存块组成的顺序型数据结构，</li>
</ul>
<h2 id="redis的过期策略以及内存淘汰机制">redis的过期策略以及内存淘汰机制</h2>
<p>redis采用的是<strong>定期删除+惰性删除策略</strong>。<br>
为什么不用定时删除策略?<br>
定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.<br>
<strong>定期删除+惰性删除是如何工作的呢?</strong><br>
定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。<br>
于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。<br>
采用定期删除+惰性删除就没其他问题了么?<br>
不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。<br>
在redis.conf中有一行配置</p>
<pre><code>maxmemory-policy volatile-lru
1
</code></pre>
<p>该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)<br>
<strong>volatile-lru</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰<br>
<strong>volatile-ttl</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰<br>
<strong>volatile-random</strong>：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰<br>
<strong>allkeys-lru</strong>：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰<br>
<strong>allkeys-random</strong>：从数据集（server.db[i].dict）中任意选择数据淘汰<br>
<strong>no-enviction</strong>（驱逐）：禁止驱逐数据，新写入操作会报错<br>
ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。</p>
<h2 id="redis-为什么是单线程的">Redis 为什么是单线程的</h2>
<p>官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）Redis利用队列技术将并发访问变为串行访问<br>
1）绝大部分请求是纯粹的内存操作（非常快速）2）采用单线程,避免了不必要的上下文切换和竞争条件<br>
3）非阻塞IO优点：<br>
1.速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)<br>
\2. 支持丰富数据类型，支持string，list，set，sorted set，hash<br>
3.支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行<br>
\4. 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除如何解决redis的并发竞争key问题</p>
<p>同时有多个子系统去set一个key。这个时候要注意什么呢？  不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，redis的事务机制，十分鸡肋。<br>
(1)如果对这个key操作，不要求顺序： 准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可<br>
(2)如果对这个key操作，要求顺序： 分布式锁+时间戳。 假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。<br>
(3) 利用队列，将set方法变成串行访问也可以redis遇到高并发，如果保证读写key的一致性<br>
对redis的操作都是具有原子性的,是线程安全的操作,你不用考虑并发问题,redis内部已经帮你处理好并发的问题了。</p>
<h2 id="redis-集群方案应该怎么做都有哪些方案">Redis 集群方案应该怎么做？都有哪些方案？</h2>
<p>1.twemproxy，大概概念是，它类似于一个代理方式， 使用时在本需要连接 redis 的地方改为连接 twemproxy， 它会以一个代理的身份接收请求并使用一致性 hash 算法，将请求转接到具体 redis，将结果再返回 twemproxy。<br>
缺点： twemproxy 自身单端口实例的压力，使用一致性 hash 后，对 redis 节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。</p>
<p>2.codis，目前用的最多的集群方案，基本和 twemproxy 一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新 hash 节点</p>
<p>3.redis cluster3.0 自带的集群，特点在于他的分布式算法不是一致性 hash，而是 hash 槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。</p>
<h2 id="有没有尝试进行多机redis-的部署如何保证数据一致的">有没有尝试进行多机redis 的部署？如何保证数据一致的？</h2>
<p>主从复制，读写分离<br>
一类是主数据库（master）一类是从数据库（slave），主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库，而从数据库一般是只读的，并接收主数据库同步过来的数据，一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库。</p>
<h2 id="对于大量的请求怎么样处理">对于大量的请求怎么样处理</h2>
<p>redis是一个单线程程序，也就说同一时刻它只能处理一个客户端请求；<br>
redis是通过IO多路复用（select，epoll, kqueue，依据不同的平台，采取不同的实现）来处理多个客户端请求的</p>
<h2 id="redis-常见性能问题和解决方案">Redis 常见性能问题和解决方案？</h2>
<p>(1) Master 最好不要做任何持久化工作，如 RDB 内存快照和 AOF 日志文件<br>
(2) 如果数据比较重要，某个 Slave 开启 AOF 备份数据，策略设置为每秒同步一次<br>
(3) 为了主从复制的速度和连接的稳定性， Master 和 Slave 最好在同一个局域网内<br>
(4) 尽量避免在压力很大的主库上增加从库<br>
(5) 主从复制不要用图状结构，用单向链表结构更为稳定，即： Master &lt;- Slave1 &lt;- Slave2 &lt;-<br>
Slave3…</p>
<h2 id="讲解下redis线程模型">讲解下Redis线程模型</h2>
<p>文件事件处理器包括分别是<strong>套接字、 I/O 多路复用程序、 文件事件分派器（dispatcher）、 以及事件处理器</strong>。使用 I/O 多路复用程序来同时监听多个套接字，  并根据套接字目前执行的任务来为套接字关联不同的事件处理器。当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。<br>
I/O 多路复用程序负责监听多个套接字， 并向文件事件分派器传送那些产生了事件的套接字。<br>
<strong>工作原理：</strong><br>
1)I/O 多路复用程序负责监听多个套接字， 并向文件事件分派器传送那些产生了事件的套接字。<br>
尽管多个文件事件可能会并发地出现， 但 I/O 多路复用程序总是会将所有产生事件的套接字都入队到一个队列里面， 然后通过这个队列，  以有序（sequentially）、同步（synchronously）、每次一个套接字的方式向文件事件分派器传送套接字：  当上一个套接字产生的事件被处理完毕之后（该套接字为事件所关联的事件处理器执行完毕）， I/O  多路复用程序才会继续向文件事件分派器传送下一个套接字。如果一个套接字又可读又可写的话， 那么服务器将先读套接字， 后写套接字.<br>
<img src="https://img-blog.csdnimg.cn/20190429094050254.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0J1dHRlcmZseV9yZXN0aW5n,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h2 id="为什么redis的操作是原子性的怎么保证原子性的">为什么Redis的操作是原子性的，怎么保证原子性的？</h2>
<p>对于Redis而言，命令的原子性指的是：一个操作的不可以再分，操作要么执行，要么不执行。<br>
Redis的操作之所以是原子性的，是因为Redis是单线程的。<br>
Redis本身提供的所有API都是原子操作，Redis中的事务其实是要保证批量操作的原子性。<br>
多个命令在并发中也是原子性的吗？<br>
不一定， 将get和set改成单命令操作，incr 。使用Redis的事务，或者使用Redis+Lua==的方式实现.</p>
<h2 id="redis事务">Redis事务</h2>
<p>Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的<br>
Redis会将一个事务中的所有命令序列化，然后按顺序执行。<br>
1.redis 不支持回滚“Redis 在事务失败时不进行回滚，而是继续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。<br>
2.如果在一个事务中的<strong>命令</strong>出现错误，那么<strong>所有的命令</strong>都不会执行；<br>
3.如果在一个事务中出现<strong>运行错误</strong>，那么<strong>正确的命令</strong>会被执行。<br>
注：redis的discard只是结束本次事务,正确命令造成的影响仍然存在.</p>
<p>1）MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。<br>
2）EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。<br>
3）通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。<br>
4）WATCH 命令可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。</p>
<h2 id="redis实现分布式锁">Redis实现分布式锁</h2>
<p>Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系Redis中可以使用SETNX命令实现分布式锁。<br>
将 key 的值设为 value ，当且仅当 key 不存在。 若给定的 key 已经存在，则 SETNX 不做任何动作<br>
<img src="https://img-blog.csdnimg.cn/20190429094250409.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0J1dHRlcmZseV9yZXN0aW5n,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
解锁：使用 del key 命令就能释放锁<br>
解决死锁：<br>
1）通过Redis中expire()给锁设定最大持有时间，如果超过，则Redis来帮我们释放锁。<br>
2） 使用 setnx key “当前系统时间+锁持有的时间”和getset key “当前系统时间+锁持有的时间”组合的命令就可以实现</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[spring-security安全认证框架Part1（非OAuth2部分）]]></title>
        <id>https://jayhablog.vercel.app/spring-security-an-quan-ren-zheng-kuang-jia-1/</id>
        <link href="https://jayhablog.vercel.app/spring-security-an-quan-ren-zheng-kuang-jia-1/">
        </link>
        <updated>2020-09-13T11:09:48.000Z</updated>
        <content type="html"><![CDATA[<hr>
<p>spring-security是通过servlet的filter链方式实现的一种认证，授权<br>
<img src="https://jayhablog.vercel.app/post-images/1599995513270.png" alt="" loading="lazy"><br>
快速入门（在内存中使用）；</p>
<p>在内存中的使用非常简单</p>
<p>阅读代码即可</p>
<pre><code class="language-java">@Configuration
@EnableWebSecurity
public class securityConfig extends WebSecurityConfigurerAdapter {

    @Bean
    public PasswordEncoder passwordEncoder() {
        // BCryptPasswordEncoder：Spring Security 提供的加密工具，可快速实现加密加盐
        return new BCryptPasswordEncoder();
    }
    @Bean
    public UserDetailsService userDetailsService(){
        InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager();
        return  manager;
    }
    /**
     * 该方法是授权相关方法
     * @param http
     * @throws Exception
     */
    @Override
    protected void configure(HttpSecurity http) throws Exception {
        //首页所有人可以访问&quot;/&quot;
        http.authorizeRequests()
                .antMatchers(&quot;/&quot;).permitAll()
                .antMatchers(&quot;/index.html&quot;).permitAll()
                .antMatchers(&quot;/index&quot;).permitAll()
                .antMatchers(&quot;/home&quot;).permitAll()
                .antMatchers(&quot;/welcome&quot;).permitAll()
                .antMatchers(&quot;/level1/**&quot;).hasRole(&quot;vip1&quot;)
                .antMatchers(&quot;/level2/**&quot;).hasRole(&quot;vip2&quot;)
                .antMatchers(&quot;/level3/**&quot;).hasRole(&quot;vip3&quot;)
        .and().formLogin()//开启自定义页面
                .loginPage(&quot;/userlogin&quot;).loginProcessingUrl(&quot;/welcome&quot;).usernameParameter(&quot;username&quot;).passwordParameter(&quot;password&quot;).
                failureHandler((req, resp, exception) -&gt; {
                    resp.setContentType(&quot;application/json;charset=utf-8&quot;);
                            PrintWriter out = resp.getWriter();
                            out.write(&quot;登录失败...&quot;);
                    out.flush();
                })
                .permitAll()
                .and()
                .httpBasic()
                .and()
                // 关闭CSRF跨域
                .csrf().disable();
        ;
        //没有权限跳到登录页
        /*http.formLogin();*/
        //关闭csrf功能
        //http.csrf().disable();
        //开启注销 成功跳到“/”
        http.logout().logoutSuccessUrl(&quot;/&quot;);
    }

    /**
     * 该方法是认证相关方法
     * @param auth
     * @throws Exception
     */
    /*@Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        //从内存中读
        //使用BCrypt加密

        auth.inMemoryAuthentication().passwordEncoder(passwordEncoder())
                .withUser(&quot;jayha&quot;).password(passwordEncoder().encode(&quot;123456&quot;)).roles(&quot;vip3&quot;,&quot;vip2&quot;)
                .and()
                .withUser(&quot;nanha&quot;).password(passwordEncoder().encode(&quot;123456&quot;)).roles(&quot;vip1&quot;);

    }*/

    @Override
    public void configure(WebSecurity web) throws Exception {
        // 设置拦截忽略url - 会直接过滤该url - 将不会经过Spring Security过滤器链
        web.ignoring().antMatchers(&quot;/getUserInfo&quot;);
        // 设置拦截忽略文件夹，可以对静态资源放行
        web.ignoring().antMatchers(&quot;/css/**&quot;, &quot;/js/**&quot;);

    }
}
</code></pre>
<hr>
<hr>
<p>BCryptPasswordEncoder</p>
<p>是spring提供的一种特殊加密方式，建议数据库以次类方式存储，有静态方法hashpw(实际密码，盐分值[也可由Bcrypt自动生成])</p>
<pre><code class="language-java">void testBcrypto(){
        String s1 = BCrypt.hashpw(&quot;sir159357&quot;, BCrypt.gensalt());
        String s2 = BCrypt.hashpw(&quot;sir159357&quot;, BCrypt.gensalt());

        System.out.println(s1);
        System.out.println(s2);
    }
</code></pre>
<p>结果</p>
<pre><code class="language-tex">s1:$2a$10$WH2U/RLezICmMu8cAN2kQ.vWb46UOEtYbHgMeri8bc4JHGtKVGSKy

s2:$2a$10$aLTNf4pFC3OwyEM/r.9aeepuid9efVaLlvdqpNEDO01vPX.17kc0O
</code></pre>
<p>所以配置一个名为passwordEncoder的bean 该bean返回的值 就是security的编码方式</p>
<pre><code class="language-java">@Bean
    public PasswordEncoder passwordEncoder() {
        // BCryptPasswordEncoder：Spring Security 提供的加密工具，可快速实现加密加盐
        return new BCryptPasswordEncoder();
    }
</code></pre>
<p>接下来 我们就可以从内存过渡到数据库了</p>
<p>回到springsecurity流程图 我们可以发现认证是由一个叫做UserDetailsService的接口进行实现的。我们可以实现这个接口并把ta加入到IOC容器中</p>
<pre><code class="language-java">@Service
public class userdetailService implements UserDetailsService {

    @Autowired
    ItestuserDAO itestuserDAO;

    @Override
    public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException {
        testuser one = itestuserDAO.findOneByAccount(s);
        if(one == null){
            return null;//不用自己抛出异常 返回NULL spring=security会自动整理
        }else{
            UserDetails details = User.withUsername(one.getAccount()).password(one.getPassword()).authorities(&quot;vip1&quot;).build();//withusername方法即把username加入 password同理，authorities则是将用户进行授权操作
            return details;
        }
    }
}
</code></pre>
<p>注意的是这里给用户授权的是auth 而在SecurityConfig里面是授权的role 二者是不同授权理念的具体实现，现在一般是role（角色）包含auth（权限）这种操作  要注意更改</p>
<p><s>俺最初没理解好这两个东西的概念在这疯狂踩坑</s></p>
<pre><code class="language-java">@Override
    protected void configure(HttpSecurity http) throws Exception {
        //首页所有人可以访问&quot;/&quot;
        http.authorizeRequests()
                .antMatchers(&quot;/&quot;).permitAll()
                .antMatchers(&quot;/index.html&quot;).permitAll()
                .antMatchers(&quot;/index&quot;).permitAll()
                .antMatchers(&quot;/home&quot;).permitAll()
                .antMatchers(&quot;/welcome&quot;).permitAll()
                .antMatchers(&quot;/level1/**&quot;).hasAuthority(&quot;vip1&quot;)
                .antMatchers(&quot;/level2/**&quot;).hasAuthority(&quot;vip2&quot;)
                .antMatchers(&quot;/level3/**&quot;).hasAuthority(&quot;vip3&quot;)
                .and()
                .formLogin()//开启自定义页面
                .loginPage(&quot;/userlogin&quot;)
                .loginProcessingUrl(&quot;/welcome&quot;)
                .usernameParameter(&quot;username&quot;)
                .passwordParameter(&quot;password&quot;)

                .failureHandler((req, resp, exception) -&gt; {
                    resp.setContentType(&quot;application/json;charset=utf-8&quot;);
                            PrintWriter out = resp.getWriter();
                            out.write(&quot;登录失败...&quot;);
                    out.flush();
                }).permitAll()
                .and()
                .httpBasic()
                .and()
                // 关闭CSRF跨域
                .csrf().disable().cors();
        ;
        http.logout().logoutSuccessUrl(&quot;/&quot;);
    }
</code></pre>
<h5 id="用户登录后获取用户信息">用户登录后获取用户信息</h5>
<p>可以使用</p>
<pre><code class="language-java">Authentication authentication =SecurityContextHolder.getContext().getAuthentication();
        Object principal = authentication.getPrincipal();
</code></pre>
<p>principal就是UserDetail对象 可以强转后使用它的各种方法 比如获取姓名：</p>
<pre><code class="language-java"> @GetMapping(&quot;/getName&quot;)
    public String getUserAccount(){
        String account= null;
        Authentication authentication = SecurityContextHolder.getContext().getAuthentication();
        Object principal = authentication.getPrincipal();
        if(principal == null){
            account = &quot;匿名&quot;;
        }
        if(principal instanceof UserDetails){
            UserDetails u = (UserDetails)principal;
            account = u.getUsername();
        }
        return account;
    }
</code></pre>
<p>数据库的建立 除了用户类外 还要有角色表 与用户表是多对多关系 还要有权限表 和角色表也是多对多关系由于这个sql比较复杂 建议用mybatis</p>
<p>由于我们之后使用token来保持会话，所以 我们可以将session保持会话方式禁用</p>
<p><s>建议在学了token之后再关</s></p>
<pre><code class="language-java">protected void configure(HttpSecurity http) throws Exception {http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);}
</code></pre>
<hr>
<h4 id="方法授权">方法授权</h4>
<p>在配置类上（加了configuration注解的类）使用</p>
<pre><code class="language-java">@EnableGlobalMethodSecurity(securedEnabled = true )
</code></pre>
<p>开启方法授权 secured注解API支持</p>
<pre><code class="language-java">@Secured(&quot;IS_AUTHENTICATED_ANONYMOUSLY&quot;)//允许匿名访问的方法（即任何人都可以访问）
@Secured(&quot;ROLE_xx&quot;)//只有xx角色的可以访问

</code></pre>
<p>但不建议使用这个</p>
<p>建议使用prepost注解</p>
<pre><code class="language-java">@EnableGlobalMethodSecurity(securedEnabled = true,prePostEnabled = true)
</code></pre>
<pre><code class="language-java">@PreAuthorize(&quot;isAnonymous()&quot;) 匿名可以访问
@PreAuthorize(&quot;hasAuthority('vip1','vip2')&quot;)有vip1和vip2的可以访问
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springboot集成定时，异步，邮件任务]]></title>
        <id>https://jayhablog.vercel.app/springboot-ji-cheng-ding-shi-yi-bu-you-jian-ren-wu/</id>
        <link href="https://jayhablog.vercel.app/springboot-ji-cheng-ding-shi-yi-bu-you-jian-ren-wu/">
        </link>
        <updated>2020-09-11T06:35:16.000Z</updated>
        <content type="html"><![CDATA[<h2 id="异步">异步</h2>
<hr>
<p>springboot主类下用@EnableAsync 开启异步</p>
<p>在需要用异步的方法上使用@Async注解，该任务会自动进入一个新进程，自动异步</p>
<h2 id="邮件">邮件</h2>
<hr>
<p>jar</p>
<pre><code class="language-xml">&lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-mail --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;
&lt;/dependency&gt;

</code></pre>
<p>yaml配置信息</p>
<pre><code class="language-yaml">spring:
   mail:
     username: your_mail@xx.com
     password: your_password
     host: smtp.163.com  #example
     protocol: smtps   #example
</code></pre>
<p>springboot自动装JavaMailSenderImpl的实体类</p>
<pre><code class="language-java">//源码
@Bean
    JavaMailSenderImpl mailSender(Session session) {
        JavaMailSenderImpl sender = new JavaMailSenderImpl();
        sender.setDefaultEncoding(this.properties.getDefaultEncoding().name());
        sender.setSession(session);
        return sender;
    }
</code></pre>
<p>按照配置文件的属性进行创建，可以直接注入</p>
<pre><code class="language-java"> @Autowired
    private JavaMailSenderImpl mailSender;
</code></pre>
<p>之后直接用mailsender所提供的各种send进行发送就行 示例：</p>
<pre><code class="language-java">@Test
    void contextLoads()  {
        SimpleMailMessage mailMessage = new SimpleMailMessage();
        mailMessage.setSubject(&quot;早上好&quot;);
        mailMessage.setText(&quot;goodMoring&quot;);
        mailMessage.setTo(&quot;send_mail@qq.com&quot;);
        mailMessage.setFrom(&quot;your_mail@163.com&quot;);
        mailSender.send(mailMessage);
    }
</code></pre>
<p>若要发送复杂邮件 则可以取消simpleMailMessage类 用</p>
<pre><code class="language-java">MimeMessage mimeMessage = mailSender.createMimeMessage();
</code></pre>
<p>复杂类对象</p>
<pre><code class="language-java">        MimeMessageHelper helper = new MimeMessageHelper(mimeMessage, true);

        helper.setSubject(&quot;早上好&quot;);
        helper.setText(&quot;&lt;a herf='www.baidu.com' &gt;今天 7:30来开会&lt;/a&gt;&quot;,true);

        //发送附件
        helper.addAttachment(&quot;1.jpg&quot;,new File(&quot;C:\\Users\\19029\\Desktop\\杂七杂八~\\1.jpg&quot;));

        helper.setTo(&quot;1902980268@qq.com&quot;);
        helper.setFrom(&quot;15999971548@163.com&quot;);
        mailSender.send(mimeMessage);
</code></pre>
<h2 id="定时">定时</h2>
<hr>
<p>项目开发中经常需要执行一些定时任务，比如需要在每天凌晨的时候，分析一次前一天的日志信息，Spring为我们提供了异步执行任务调度的方式，提供了两个接口。</p>
<ul>
<li>TaskExecutor接口</li>
<li>TaskScheduler接口</li>
</ul>
<p>两个注解：</p>
<ul>
<li>@EnableScheduling// 主main方法上 表示开启定时任务</li>
<li>@Scheduled//写cron表达式 表示什么时候</li>
</ul>
<figure data-type="image" tabindex="1"><img src="C:%5CUsers%5C19029%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200911141657793.png" alt="image-20200911141657793" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[swagger初步实践]]></title>
        <id>https://jayhablog.vercel.app/swagger-chu-bu-shi-jian/</id>
        <link href="https://jayhablog.vercel.app/swagger-chu-bu-shi-jian/">
        </link>
        <updated>2020-09-10T08:04:11.000Z</updated>
        <content type="html"><![CDATA[<h3 id="swagger">swagger</h3>
<hr>
<p>swagger jar</p>
<pre><code class="language-xml">&lt;!--swagger--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.springfox&lt;/groupId&gt;
            &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;
            &lt;version&gt;2.9.2&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!--http://localhost:8080/swagger-ui.html--&gt;
        &lt;!--&lt;dependency&gt;
            &lt;groupId&gt;io.springfox&lt;/groupId&gt;
            &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt;
            &lt;version&gt;2.9.2&lt;/version&gt;
        &lt;/dependency&gt;--&gt;
        &lt;!--http://localhost:8080/document.html--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.zyplayer&lt;/groupId&gt;
            &lt;artifactId&gt;swagger-mg-ui&lt;/artifactId&gt;
            &lt;version&gt;1.0.6&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>
<p><em>swagger的springboot内类配置</em></p>
<pre><code class="language-java">package cn.gdoujayha.springbootApplication.config;

import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.env.Environment;
import org.springframework.core.env.Profiles;
import springfox.documentation.builders.PathSelectors;
import springfox.documentation.builders.RequestHandlerSelectors;
import springfox.documentation.service.ApiInfo;
import springfox.documentation.service.Contact;
import springfox.documentation.spi.DocumentationType;
import springfox.documentation.spring.web.plugins.Docket;
import springfox.documentation.swagger2.annotations.EnableSwagger2;

import java.util.ArrayList;
import java.util.Properties;


@Configuration
@EnableSwagger2
public class SwaggerConfig {

    /**
     * 联系方式（作者名字，联系url，email）
     */
    private static final Contact CONTACT = new Contact(&quot;jayha&quot;,&quot;https://jayhablog.vercel.app&quot;,&quot;1902980268@qq.com&quot;) ;

    /*
        配置swagger的docket bean实例
         */
    @Bean
    /*@ConditionalOnProperty(prefix = &quot;profiles&quot;,havingValue = &quot;dev&quot;)*/
    public Docket docket(Environment environment){


        Profiles profiles = Profiles.of(&quot;dev&quot;,&quot;test&quot;);
        boolean flag = environment.acceptsProfiles(profiles);//“仅在dev和test环境下生效”


       return  new Docket(DocumentationType.SWAGGER_2)
                .groupName(&quot;jayha&quot;)//设置分组名 可以设置多个分组（多人协同的时候，可以一人一个或多个组）
                .enable(flag)
                .apiInfo(apiInfo())
                .select()
                /**
                 * apis：配置所需要扫描的地方
                 * requestHandlerSelectors有方式
                 * .basePackage配置扫描包
                 * .any扫描所有地方
                 * .none全不扫描
                 * .withClassAnnotation()只扫描类上有加了传入注解class的的那个注解的类（传入注解的class）
                 */
                .apis(RequestHandlerSelectors.basePackage(&quot;cn.gdoujayha.springbootApplication.controller&quot;))//配置扫描包
                /**
                 * paths配置过滤的路径
                 * 使用pathselector下的东西
                 * 下有：
                 * any全部
                 * none全否
                 * regex：正则
                 * ant（一般用这个）路径
                 */
                //.paths(PathSelectors.ant(&quot;/springbootApplication/controller/reginController/**&quot;))
                .build()
                ;
    }

    /**
     * apiinfo的配置
     * @return
     */
    private ApiInfo apiInfo(){
        return new ApiInfo(&quot;Jayha‘文档&quot;,
                &quot;关于''项目的swagger文档&quot;,
                &quot;0.1&quot;,
                &quot;urn:tos&quot;,
                CONTACT,
                &quot;Apache 2.0&quot;,
                &quot;http://www.apache.org/licenses/LICENSE-2.0&quot;,
                new ArrayList());
    }
}

</code></pre>
<blockquote>
<h3 id="常用注解">常用注解</h3>
</blockquote>
<p>Swagger的所有注解定义在io.swagger.annotations包下</p>
<p>下面列一些经常用到的，未列举出来的可以另行查阅说明：</p>
<table>
<thead>
<tr>
<th>Swagger注解</th>
<th style="text-align:center">简单说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>@Api(tags = &quot;xxx模块说明&quot;)</td>
<td style="text-align:center">作用在模块类上</td>
</tr>
<tr>
<td>@ApiOperation(&quot;xxx接口说明&quot;)</td>
<td style="text-align:center">作用在接口方法上</td>
</tr>
<tr>
<td>@ApiModel(&quot;xxxPOJO说明&quot;)</td>
<td style="text-align:center">作用在模型类上：如VO、BO</td>
</tr>
<tr>
<td>@ApiModelProperty(value = &quot;xxx属性说明&quot;,hidden = true)</td>
<td style="text-align:center">作用在类方法和属性上，hidden设置为true可以隐藏该属性</td>
</tr>
<tr>
<td>@ApiParam(&quot;xxx参数说明&quot;)</td>
<td style="text-align:center">作用在参数、方法和字段上，类似@ApiModelProperty</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
</feed>