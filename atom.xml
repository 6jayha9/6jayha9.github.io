<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jayhablog.vercel.app</id>
    <title>Jayha真的卷不动了</title>
    <updated>2021-06-06T11:43:10.590Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jayhablog.vercel.app"/>
    <link rel="self" href="https://jayhablog.vercel.app/atom.xml"/>
    <subtitle>欢迎来到Jayha小罗的Blog嘻嘻嘻：）</subtitle>
    <logo>https://jayhablog.vercel.app/images/avatar.png</logo>
    <icon>https://jayhablog.vercel.app/favicon.ico</icon>
    <rights>All rights reserved 2021, Jayha真的卷不动了</rights>
    <entry>
        <title type="html"><![CDATA[我理解的M-WAY树＆B树＆B+树]]></title>
        <id>https://jayhablog.vercel.app/wo-li-jie-de-m-way-shu-andb-shu-andbshu/</id>
        <link href="https://jayhablog.vercel.app/wo-li-jie-de-m-way-shu-andb-shu-andbshu/">
        </link>
        <updated>2021-06-02T13:06:56.000Z</updated>
        <content type="html"><![CDATA[<p>来自于https://www.bilibili.com/video/BV1UC4y1p7zm?from=search&amp;seid=10138161092795701955 的归纳整理 感谢这位印度老师的课程。</p>
<p>M-way树、B树、B+树其实是一种数据结构的不同变形，最终形态的B+树往往用于数据库索引的存储。</p>
<h3 id="为什么要建索引">为什么要建索引</h3>
<p>操作系统的一些小常识必须先了解：磁盘由轨道和扇区切分成一个个“块”（blocks，通常大小为512字节，在不同的磁盘里大小也不一样），数据在磁盘内不能直接操作，所以DBMS必须经过ram读入并处理才能写回磁盘。读取多个block，这对磁盘I／O是一种消耗（因为每读取一个block都会消耗磁盘I/O,磁盘每次读取都是以block为单位的），所以为了降低磁盘损耗，我们把关键字和关键字对应行的地址建立成一个“索引”，由于索引大小远远小于行的大小，一个block可以存的索引数比行数多，遍历索引就比遍历行快，I/O损耗也小。</p>
<p>以聚簇索引为例，索引由一个建索引所依据的字段（通常是主键）和指向其所在行的指针组成（也需要占据一定的块）这样就可以只遍历索引表所在的block，遍历的block数量就会大大减小。</p>
<hr>
<h3 id="m-way树">M-way树</h3>
<p>然而当库表数据大到一定程度的时候，搜索效率还是会下降，我们就需要建一个稀疏index表，选举之前的index表的部分节点到稀疏index表中，并将选举出来的点作为分割点，将原先的表进行分割，稀疏的index表中，索引和指向之前的表分裂出来的子表的指针交错，同样的思想，可以不只建一层稀疏索引，可以建多层，取决于数据库数据量大小，但稀疏index表最少都要有两行数据，因为一行没有意义。</p>
<p>大概长这样</p>
<p><img src="https://jayhablog.vercel.app/post-images/1622721680082.jpg" alt="" loading="lazy"><img src="https://cdnir.com/i/2021/06/02/xflnds.jpg" alt="" loading="lazy"></p>
<p>key就是关键字。</p>
<p>把这个东西横过来，就长得很像树啦，我们称之为M-way树（其实真正的M-way树除了key和指向之前的表分裂出来的子表的指针外 还有一个recordpoint即指向数据库中真正数据地址的指针，也就是key和recordpoint形成了索引）。</p>
<p><img src="https://jayhablog.vercel.app/post-images/1622721696270.jpg" alt="" loading="lazy"><img src="https://cdnir.com/i/2021/06/02/xizh5j.jpg" alt="" loading="lazy"></p>
<p>这里能读懂也就基本能了解B树的思想了，因为B树就是M-way树加了限制条件的一种数据结构</p>
<hr>
<h3 id="b树">B树</h3>
<p>M-way树最大的问题是，不能自维护插入和删除数据的时候，所以希望它进行自我管理，这就是B树的实现目的。</p>
<p><img src="https://jayhablog.vercel.app/post-images/1622721701553.png" alt="" loading="lazy"><img src="https://cdnir.com/i/2021/06/02/xca4er.png" alt="" loading="lazy"></p>
<p>通常我们说m阶的B树（阶即是一个结点最多可以拥有多少个子节点），它必须满足如下条件：</p>
<ul>
<li>每个节点最多只有m个子节点。</li>
<li>每个非叶子节点（除了根）具有至少⌈ m/2⌉子节点。</li>
<li>如果根不是叶节点，则根至少有两个子节点。</li>
<li>具有<em>k</em>个子节点的非叶节点包含<em>k</em> -1个键。（k为关键字个数）</li>
<li>所有叶子都出现在同一水平，没有任何信息（高度一致）。</li>
</ul>
<p><em>对于B树的自维护性，也就是插入删除操作，我的水平讲起来还是有点头疼，这边介绍一下https://www.cnblogs.com/lianzhilei/p/11250589.html 这位大佬写的内容，感谢大佬，之后有时间我会自己重写一遍</em></p>
<p>在现代操作系统中，磁盘IO是非常高昂的操作，所以操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存cache中（因为读取相邻数据的概率较高），称之为局部预读性，所以访问一个数据，相邻数据也会很快访问到，若我们将读取一个节点视为一个IO的话，那么B树读取IO的次数和其时间复杂度都为对数级，大大减小I/O次数，搜索效率大大提升。</p>
<hr>
<h3 id="b树-2">B+树</h3>
<p>B+树是针对B树进行了优化。</p>
<p>具体的优化为，首先是叶子节点存储所有的关键字和关键字对应行的地址，其上的所有非叶子节点仅保存指向叶子节点的索引（仅含有其子树根结点中最大（或最小）关键字），并且所有叶子节点因为在同一高度，B+树也可以轻松的将其串联起来，形成一个链表。</p>
<p>那么这些优化有什么好处呢？首先非叶子节点全部只存关键字，所有非叶子节点的大小就更小了，一个block就可以容纳更多的非叶子节点，遍历速度就更快了，I/O消耗也就更小了。</p>
<p>其次是由于局部预读性，本来B树预读的数据，其附近的关键字和和其绝对值相差往往较大（一个节点中两个相邻的key和recordpoint的绝对值是他们之间的指针指向的子树所有值的总和），指向子节点的指针又没有预读的需要，在范围查找中，二次搜索命中预读的概率较低，而B+树读取的是叶子节点，叶子节点无指向子节点的索引，相邻关键字的绝对值又比较小，预读命中概率就大了。</p>
<p>其次是B+树查询更为稳定，因为一定要查询到叶子节点才能得到地址。</p>
<p>最后是所有叶子节点使用链表方式进行串联，查找到叶子节点后可以直接对叶子节点进行遍历，便于范围查找。</p>
<p><img src="https://jayhablog.vercel.app/post-images/1622721710014.png" alt="" loading="lazy"><img src="https://cdnir.com/i/2021/06/03/shhx53.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springsecurity改写过滤链实现小程序登录]]></title>
        <id>https://jayhablog.vercel.app/springsecurity-gai-xie-guo-lu-lian-shi-xian-xiao-cheng-xu-deng-lu/</id>
        <link href="https://jayhablog.vercel.app/springsecurity-gai-xie-guo-lu-lian-shi-xian-xiao-cheng-xu-deng-lu/">
        </link>
        <updated>2021-05-06T13:27:36.000Z</updated>
        <content type="html"><![CDATA[<h3 id="前期准备工作">前期准备工作：</h3>
<p>前端调用一个wx.login()接口，成功后返回参数code</p>
<p>前端调用一个wx.getUserinfo()接口，返回很多参数，重要的参数为rawData和signature</p>
<p>这几个参数的作用分别是</p>
<blockquote>
<p>code：与appid、appsecret一起作为参数，调用微信官方接口https://api.weixin.qq.com/sns/jscode2session?appid=%s&amp;secret=%s&amp;js_code=%s&amp;grant_type=authorization_code    会返回openid、session_key、errorcode、errmsg等参数信息。</p>
<p>openid：自定义登录态所用。</p>
</blockquote>
<blockquote>
<p>rawData：不包含敏感数据的原始数据字符串,用于签名校验。</p>
<p>signature：用于签名校验数据完整性。具体做法是将rawData和session_key拼接，在后台使用SHA1算法解密后与调用微信接口返回的signature作比对校验数据完整性。</p>
</blockquote>
<hr>
<h3 id="复习下springsecurity过滤链">复习下springsecurity过滤链</h3>
<figure data-type="image" tabindex="1"><img src="https://jayhablog.vercel.app/post-images/1599995513270.png" alt="这张图贯穿整篇文章" loading="lazy"></figure>
<p><code>这张图贯穿整篇文章！</code></p>
<hr>
<p>springsecurity过滤链第一层是UsernamePasswordAuthenticationFilter，小程序微信登录不需要username和password，我们舍弃它，重写。调出源码来，可以发现它是继承了一个AbstractAuthenticationProcessingFilter类，所以我们自己写的过滤器也要继承这个类。该类最重要的是 Authentication attemptAuthentication(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse)方法，所以将它重写。</p>
<p>我们看一看UsernamePasswordAuthenticationFilter是怎么重写这个方法的：</p>
<pre><code class="language-java">public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException {
    if (this.postOnly &amp;&amp; !request.getMethod().equals(&quot;POST&quot;)) {
        throw new AuthenticationServiceException(&quot;Authentication method not supported: &quot; + request.getMethod());
    } else {
        String username = this.obtainUsername(request);
        String password = this.obtainPassword(request);
        if (username == null) {
            username = &quot;&quot;;
        }

        if (password == null) {
            password = &quot;&quot;;
        }

        username = username.trim();
        UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(username, password);
        this.setDetails(request, authRequest);
        return this.getAuthenticationManager().authenticate(authRequest);
    }
}
</code></pre>
<p>可以发现是将username，password封装制作成token，之后再调用this.getAuthenticationManager().authenticate()封装这个token传给下一层过滤链。那我们就按照他的思路写我们用openid、seesion_key、rawData、signature代替username和password作用，那我们就将这四个封装成一个token，再像UsernamePasswordAuthenticationFilter传给下一层就好，那么现在唯一的问题是springsecurity没有对应的token提供，所以我们得自己写：</p>
<p><em>重写token、加入openid、sessionKey、rawData、signature参数进行校验，查看常用的token，发现都继承AbstractAuthenticationToken这个抽象类，我们直接也继承它，加属性再配置对应的构造器和get/set就好了。我为了图方便，还将重写了getCredentials、getPrincipal()方法，方便之后使用，不重写也行只是为了方便。</em></p>
<pre><code class="language-java">public Object getCredentials() {
    return this.openid;
}

public Object getPrincipal() {
    return this.sessionKey;
}
</code></pre>
<p>然后我们就可以用httpServeletRequest、获取前端传过来的三个参数，再用其中的code参数结合自己的appid和appsecret、得到openid和session_key，再将其封装起来就好啦。这一个过滤链就解决。</p>
<hr>
<p>下一层的过滤器是AuthenticationManager，该层是真正执行认证逻辑的，我们也需要重写。我打算在这层顺便把没注册的用户给注册了，方便前端一键实现注册/登录。</p>
<p>首先实现AuthenticationManager接口，会提示我们重写Authentication authenticate(Authentication authentication)方法。</p>
<p>首先该方法的参数token就是上一层过滤器传过来的token，我们需要将它强转成我们自己的token，这样就可以获取到openid来查询数据库有没有该用户。</p>
<p>有该用户即认证成功，直接丢给下一层过滤器就好。</p>
<p>没有的话，就执行注册程序，当然，在注册前我们要首先使用SHA1算法和session_key，对rawdata进行解密，进行签名校验，保证数据完整性和保证不被恶意注册。</p>
<p>rawData使用JSON转换，可以得到很多用户的信息，读者可以自己去试一试，因为占地方就不一一列举了。然后加入openid、session_key方便之后的校验，就可以存入数据库啦之后给下一层过滤器啦~</p>
<p>下一层过滤器就不用我们自己写啦~~~~。</p>
<p>btw记得登陆成功的handler要颁发token就好（颁发的token需要携带openid属性）。</p>
<hr>
<p>接下来我们要实现jwt鉴权。认证登录状态。这个比较简单，我几笔带过了。</p>
<p>和平时写的一样继承OncePerRequestFilter抽象类。重写doFilterInternal方法。在该方法中从请求头获取token，从token中获取openid，获取不到或者返回错误就是有问题，抛出异常，返回错误日志给前端就行了。当然，如果security context为空也要报错给前端。</p>
<hr>
<p>好了 最后总配置一下security就好了</p>
<pre><code class="language-java">@EnableWebSecurity
public class WebSecurityConfig extends WebSecurityConfigurerAdapter {

    @Override
    protected void configure(HttpSecurity http) throws Exception {
        http.csrf()
                .disable()//关闭csrf保护
                .sessionManagement()
                // 不创建Session, 使用jwt来管理用户的登录状态
                .sessionCreationPolicy(SessionCreationPolicy.STATELESS)
                .and()
                .authorizeRequests()
                // /error 异常端点不需要用户认证
                .antMatchers(&quot;/error/**&quot;).permitAll()
                // 其余的全部需要用户认证
                .anyRequest().authenticated()
                .and()
                .exceptionHandling()
                .authenticationEntryPoint(new CustomAuthenticationEntryPoint())
                .accessDeniedHandler(new CustomAccessDeniedHandler());
            // 使用自己写的第一层过滤器替换默认的认证过滤器UsernamePasswordAuthenticationFilter
        http.addFilterAt(wxAppletAuthenticationFilter(), UsernamePasswordAuthenticationFilter.class)
                // 在自己写的第一层过滤器前面添加用于验证jwt，识别用户是否登录的过滤器
                .addFilterBefore(jwtAuthenticationTokenFilter(), WxAppletAuthenticationFilter.class);
    }

    @Autowired
    private WxAppletAuthenticationManager wxAppletAuthenticationManager;

    @Bean
    public WxAppletAuthenticationFilter wxAppletAuthenticationFilter(){
        WxAppletAuthenticationFilter wxAppletAuthenticationFilter = new WxAppletAuthenticationFilter(&quot;/login&quot;);
        wxAppletAuthenticationFilter.setAuthenticationManager(wxAppletAuthenticationManager);
       //将自己写的第二层过滤器加入过滤链中，并将登录接口设置为/login
        wxAppletAuthenticationFilter.setAuthenticationSuccessHandler(customAuthenticationSuccessHandler());//登陆成功的handler加入springsecurity流程
        return wxAppletAuthenticationFilter;
    }

    @Bean
    public CustomAuthenticationSuccessHandler customAuthenticationSuccessHandler(){
        return new CustomAuthenticationSuccessHandler();
        //未登录时的处理端点, 一般是抛出AuthenticationException时会进入
    }

    @Bean
    public JwtAuthenticationTokenFilter jwtAuthenticationTokenFilter() {
        return new JwtAuthenticationTokenFilter();
        //访问接口无权限时的处理端点, 一般是抛出AccessDeniedException异常时会进入
    }

}

</code></pre>
<p>附录：</p>
<p>JwtTokenUtils</p>
<pre><code class="language-java">package com.tanwb.util;

import cn.hutool.core.date.DateTime;
import com.google.common.collect.Maps;
import io.jsonwebtoken.Claims;
import io.jsonwebtoken.Jwts;
import io.jsonwebtoken.SignatureAlgorithm;
import io.jsonwebtoken.security.Keys;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Component;

import javax.crypto.SecretKey;
import java.util.Date;
import java.util.Map;
import java.util.function.Function;

/**
 * jwt工具类
 * @author tanwubo
 */
@Component
public class JwtTokenUtils {

    @Value(&quot;${jwt.expiration}&quot;)
    private Long expiration;

    public SecretKey key;

    public JwtTokenUtils() {
        key = Keys.secretKeyFor(SignatureAlgorithm.HS256);
    }

    public String getUsernameFromToken(String token) {
        return getClaimFromToken(token, Claims::getSubject);
    }

    public &lt;T&gt; T getClaimFromToken(String token, Function&lt;Claims, T&gt; claimsResolver) {
        final Claims claims = getAllClaimsFromToken(token);
        return claimsResolver.apply(claims);
    }

    private Claims getAllClaimsFromToken(String token) {
        return Jwts.parser()
                .setSigningKey(this.key)
                .parseClaimsJws(token)
                .getBody();
    }

    public String generateToken(String openid) {
        Map&lt;String, Object&gt; claims = Maps.newHashMap();
        return doGenerateToken(claims, openid);
    }

    private String doGenerateToken(Map&lt;String, Object&gt; claims, String subject) {
        final Date createdDate = DateTime.now();
        final Date expirationDate = calculateExpirationDate(createdDate);

        return Jwts.builder()
                .setClaims(claims)
                .setSubject(subject)
                .setIssuedAt(createdDate)
                .setExpiration(expirationDate)
                .signWith(this.key)
                .compact();
    }

    private Date calculateExpirationDate(Date createdDate) {
        return new Date(createdDate.getTime() + expiration * 1000);
    }

}

</code></pre>
<p>WxLoginResultDTO</p>
<pre><code class="language-java">@Data
public class WxLoginResultDTO {
    private String openid;
    private String session_key;
    private String errcode;
    private String errmsg;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hystrix小结]]></title>
        <id>https://jayhablog.vercel.app/hystrix-xiao-jie/</id>
        <link href="https://jayhablog.vercel.app/hystrix-xiao-jie/">
        </link>
        <updated>2021-04-24T14:16:27.000Z</updated>
        <content type="html"><![CDATA[<h1 id="hystrix是什么-能干什么">hystrix是什么 能干什么？</h1>
<p>先贴官方文档</p>
<blockquote>
<h6 id="introduction">Introduction</h6>
<p>Hystrix is a latency and fault tolerance library designed to isolate  points of access to remote systems, services and 3rd party libraries,  stop cascading failure and enable resilience in complex distributed  systems where failure is inevitable.</p>
<h6 id="full-documentation">Full Documentation</h6>
<p>See the <a href="https://github.com/Netflix/Hystrix/wiki/">Wiki</a> for full documentation, examples, operational details and other information.</p>
<p>See the <a href="http://netflix.github.com/Hystrix/javadoc">Javadoc</a> for the API.</p>
<h6 id="communication">Communication</h6>
<ul>
<li>Google Group: <a href="http://groups.google.com/d/forum/hystrixoss">HystrixOSS</a></li>
<li>Twitter: <a href="http://twitter.com/HystrixOSS">@HystrixOSS</a></li>
<li><a href="https://github.com/Netflix/Hystrix/issues">GitHub Issues</a></li>
</ul>
<h6 id="what-does-it-do">What does it do?</h6>
<ol>
<li>Latency and Fault Tolerance</li>
</ol>
<p>Stop cascading failures. Fallbacks and graceful degradation. Fail fast and rapid recovery.</p>
<p>Thread and semaphore isolation with circuit breakers.</p>
<ol start="2">
<li>Realtime Operations</li>
</ol>
<p>Realtime monitoring and configuration changes. Watch service and  property changes take effect immediately as they spread across a fleet.</p>
<p>Be alerted, make decisions, affect change and see results in seconds.</p>
<p>Concurrency</p>
<p>Parallel execution. Concurrency aware request caching. Automated batching through request collapsing.</p>
</blockquote>
<h4 id="学hystrix前先了解什么是服务雪崩">学hystrix前，先了解什么是<code>服务雪崩</code>：</h4>
<p>多个微服务互相调用的时候，会组成一条长长的调用链（所谓的“扇出”），当某一个服务挂掉之后， 调用其的上端消费者服务就会积压越来越多的用户请求，当上端消费者服务占用越来越多的资源，“挤得不能在挤”后，上端消费者服务也会挂掉，从而造成整个系统崩溃。</p>
<p>对高流量应用来说，单一的后端依赖可能会导致整个服务器上的所有资源在几秒内饱和，这些应用程序之间还可能导致服务之间延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多级联的故障，这些都需要对故障和延迟进行隔离处理，使单个服务挂掉不影响整个系统。</p>
<p>举个例子，如果一个应用依赖了 30 个服务，每个服务保证 99.99% 的时间是正常的，那可以计算出</p>
<blockquote>
<p>99.9930 = 99.7% uptime<br>
0.3% of 1 billion requests = 3,000,000 failures<br>
2+ hours downtime/month even if all dependencies have excellent uptime.</p>
</blockquote>
<p>用图说话：</p>
<p>正常情况下：</p>
<figure data-type="image" tabindex="1"><img src="https://riyugo.com/i/2021/04/24/10uroic.png" alt="" loading="lazy"></figure>
<p>当一个依赖的节点坏掉时，将阻塞整个的用户请求：</p>
<figure data-type="image" tabindex="2"><img src="https://riyugo.com/i/2021/04/24/10urvjg.png" alt="" loading="lazy"></figure>
<p>流量高峰时，一个单节点的宕机或延迟，会迅速导致所有服务负载达到饱和。应用中任何一个可能通过网络访问其他服务的节点，都有可能成为造成潜在故障的来源。更严重的是，还可能导致服务之间的延迟增加，占用队列、线程等系统资源，从而导致多系统之间的级联故障。</p>
<figure data-type="image" tabindex="3"><img src="https://riyugo.com/i/2021/04/24/10urnua.png" alt="" loading="lazy"></figure>
<h3 id="什么是hystrix">什么是Hystrix</h3>
<p>Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时，异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障以提高分布式系统的弹性。<br>
“断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控(类似熔断保险丝)，向调用方返回一个服务预期的，可处理的备选响应(FallBack)，而不是长时间的等待或者抛出调用方法无法处理的异常，这样就可以保证了服务调用方的线程不会被长时间，不必要的占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。</p>
<p>那么，hy能干嘛</p>
<ul>
<li>服务降级</li>
<li>服务熔断</li>
<li>服务限流</li>
</ul>
<h3 id="hystrix设计目标">Hystrix设计目标：</h3>
<ul>
<li>对来自依赖的延迟和故障进行防护和控制，防止单个依赖耗尽资源——这些依赖通常都是通过网络访问的</li>
<li>阻止故障的连锁反应</li>
<li>快速失败并迅速恢复</li>
<li>回退并优雅降级</li>
<li>提供近实时的监控与告警</li>
</ul>
<h3 id="hystrix遵循的设计原则">Hystrix遵循的设计原则：</h3>
<ul>
<li>防止任何单独的依赖耗尽资源（线程）</li>
<li>过载立即切断并快速失败，防止排队</li>
<li>尽可能提供回退以保护用户免受故障</li>
<li>使用隔离技术（例如隔板，泳道和断路器模式）来限制任何一个依赖的影响</li>
<li>通过近实时的指标，监控和告警，确保故障被及时发现</li>
<li>通过动态修改配置属性，确保故障及时恢复</li>
<li>防止整个依赖客户端执行失败，而不仅仅是网络通信</li>
</ul>
<h3 id="hystrix如何实现这些设计目标">Hystrix如何实现这些设计目标？</h3>
<ul>
<li>使用命令模式将所有对外部服务（或依赖关系）的调用包装在HystrixCommand或HystrixObservableCommand对象中，并将该对象放在单独的线程中执行；</li>
<li>每个依赖都维护着一个线程池（或信号量），线程池被耗尽则拒绝请求（而不是让请求排队）。</li>
<li>记录请求成功，失败，超时和线程拒绝。</li>
<li>服务错误百分比超过了阈值，熔断器开关自动打开，一段时间内停止对该服务的所有请求。</li>
<li>请求失败，被拒绝，超时或熔断时执行降级逻辑。</li>
<li>近实时地监控指标和配置的修改。</li>
</ul>
<p>用图来说就是</p>
<figure data-type="image" tabindex="4"><img src="https://riyugo.com/i/2021/04/24/10urxz5.png" alt="" loading="lazy"></figure>
<h1 id="怎么用我觉得这个不太重要随便写了">怎么用（我觉得这个不太重要，随便写了）</h1>
<p>工作原理：</p>
<figure data-type="image" tabindex="5"><img src="https://img2020.cnblogs.com/blog/1096103/202003/1096103-20200328181431827-1970391529.png" alt="img" loading="lazy"></figure>
<h3 id="服务熔断降级">服务熔断降级</h3>
<p>在服务提供端中因为访问不到数据库中的数据或者为了保证高并发服务的健康，在系统资源不够时，有时会需要暂时关闭部分冷门服务为服务降级。</p>
<p>hystrix可以在这时，返回一个自定义的通知给调用这个服务的所有消费者来应对降级。</p>
<p>先直接在配置文件配置好feign.hystrix.enable属性为true</p>
<pre><code class="language-java">@EnableCircuitBreaker//开启中断器
</code></pre>
<p>断路逻辑：hystrix最重要的一个注解@HystrixCommand，配置fallback属性为该方法挂掉之后的替补方法就好。</p>
<p>该注解还有commandProperties属性，该属性里面用hystrixProperty可以配置超时、错误率等信息。</p>
<p>比如</p>
<pre><code class="language-java"> @HystrixCommand(fallbackMethod = &quot;替补方法&quot;)
    @GetMapping(&quot;/{id}&quot;)
    public CommonResult&lt;Payment&gt; payment(@PathVariable(&quot;id&quot;) long id)
    {
        Payment payment = paymentService.selectPaymentById(id);
        if(payment==null) throw new RuntimeException(&quot;传入为空&quot;);
        return CommonResult.success(payment);
    }
</code></pre>
<p>如果想直接<code>配置一个类的降级策略</code>，直接在feign注解配置fallbackFactory属性为自写工厂类，该工厂类（必须在spring容器中）实现“FallbackFactory”接口，重写create方法，返回一个feign注解配置的接口的实现类，该实现类里每一个方法对应服务降级之后的处理信息。</p>
<hr>
<p>上面所说的都是单个服务熔断降级，会导致代码量膨胀，我们还可以配置<code>全局降级</code> 。</p>
<p><code>写到此时，打开朋友圈，见证朋友美好生活心态崩溃，我懒得写了。</code></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ribbon]]></title>
        <id>https://jayhablog.vercel.app/ribbon/</id>
        <link href="https://jayhablog.vercel.app/ribbon/">
        </link>
        <updated>2021-04-19T12:33:27.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-xml"> &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
<pre><code class="language-java">@Bean
@LoadBalanced  //开启restTemplate负载均衡
public RestTemplate restTemplate(){
    return new RestTemplate();
}
</code></pre>
<p>Spring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡的工具。</p>
<p>简单的说，Ribbon是Netflix发布的开源项目，主要功能是提供客户端的软件负载均衡算法和服务调用。Ribbon客户端组件提供一系列完善的配置项如连接超时，重试等。</p>
<p>简单的说，就是在配置文件中列出Load Balancer(简称LB)后面所有的机器，Ribbon会自动的帮助你基于某种规则(如简单轮询，随机连接等）去连接这些机器。我们很容易使用Ribbon实现自定义的负载均衡算法。</p>
<p><strong>Ribbon未来可能被Spring Cloud LoadBalacer替代。</strong></p>
<hr>
<h4 id="ribbon本地负载均衡客户端vs-nginx服务端负载均衡区别">Ribbon本地负载均衡客户端VS Nginx服务端负载均衡区别</h4>
<p>Nginx是服务器负载均衡，客户端所有请求都会交给nginx，然后由nginx实现转发请求。即负载均衡是由服务端实现的。<br>
Ribbon本地负载均衡，在调用微服务接口时候，会在注册中心上获取注册信息服务列表之后缓存到JVM本地，从而在本地实现RPC远程服务调用技术。</p>
<p>集中式LB</p>
<p>即在服务的消费方和提供方之间使用独立的LB设施(可以是硬件，如F5, 也可以是软件，如nginx)，由该设施负责把访问请求通过某种策略转发至服务的提供方;</p>
<p>进程内LB</p>
<p>将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选择出一个合适的服务器。</p>
<p>Ribbon就属于进程内LB，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址。</p>
<p>一句话</p>
<p><strong>负载均衡 + RestTemplate调用</strong></p>
<hr>
<h3 id="ribbon默认自带的负载规则">Ribbon默认自带的负载规则</h3>
<p>lRule：根据特定算法中从服务列表中选取一个要访问的服务</p>
<figure data-type="image" tabindex="1"><img src="https://jayhablog.vercel.app/post-images/1618835677071.png" alt="" loading="lazy"></figure>
<pre><code>RoundRobinRule 轮询
RandomRule 随机
RetryRule 先按照RoundRobinRule的策略获取服务，如果获取服务失败则在指定时间内会进行重
WeightedResponseTimeRule 对RoundRobinRule的扩展，响应速度越快的实例选择权重越大，越容易被选择
BestAvailableRule 会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务
AvailabilityFilteringRule 先过滤掉故障实例，再选择并发较小的实例
ZoneAvoidanceRule 默认规则,复合判断server所在区域的性能和server的可用性选择服务器</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker part1]]></title>
        <id>https://jayhablog.vercel.app/docker-part1-ji-chu-pian/</id>
        <link href="https://jayhablog.vercel.app/docker-part1-ji-chu-pian/">
        </link>
        <updated>2021-04-01T05:08:27.000Z</updated>
        <content type="html"><![CDATA[<p>Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中,然后发布到任何流行的Linux机器或Windows 机器上,也可以实现虚拟化,容器是完全使用沙箱机制,相互之间不会有任何接口。<br>
官网为：https://www.docker.com/<br>
本博客旨在本人整理笔记，顺带介绍docker的基础知识。</p>
<p><img src="https://jayhablog.vercel.app/post-images/1617254006024.png" alt="" loading="lazy"><img src="D:%5C%E5%9B%BE%E5%BA%8A%5C576507-docker1.png" alt="" loading="lazy"></p>
<table>
<thead>
<tr>
<th>概念</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Docker 镜像(Images)</td>
<td>Docker 镜像是用于创建 Docker 容器的模板，比如 Ubuntu 系统。</td>
</tr>
<tr>
<td>Docker 容器(Container)</td>
<td>容器是独立运行的一个或一组应用，是镜像运行时的实体。</td>
</tr>
<tr>
<td>Docker 客户端(Client)</td>
<td>Docker 客户端通过命令行或者其他工具使用 Docker SDK (https://docs.docker.com/develop/sdk/) 与 Docker 的守护进程通信。</td>
</tr>
<tr>
<td>Docker 主机(Host)</td>
<td>一个物理或者虚拟的机器用于执行 Docker  守护进程和容器。</td>
</tr>
<tr>
<td>Docker Registry</td>
<td>Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。 Docker Hub(https://hub.docker.com) 提供了庞大的镜像集合供使用。  一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 <strong>latest</strong> 作为默认标签。</td>
</tr>
<tr>
<td>Docker Machine</td>
<td>Docker Machine是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，比如VirtualBox、 Digital Ocean、Microsoft Azure。</td>
</tr>
</tbody>
</table>
<p><strong>Docker是什么工作的?</strong><br>
Docker是一个Client-Server结构的系统，Docker的守护进程运行在主机上。通过<code>Socket</code>从客户端访问! DockerServer接收到 Docker-Client的指令，就会执行这个命令!</p>
<p>docker支持$() 的标记语法 如</p>
<pre><code class="language-shell">docker rm $(docker ps -aq)
</code></pre>
<p>ctrl+p+q 容器不停止退出交互模式</p>
<p>常用命令 查询 https://mp.weixin.qq.com/s/vBsTkAGmwInbLT18qOUZBw</p>
<h2 id="docker镜像加载原理"><strong>Docker镜像加载原理</strong></h2>
<p>docker的镜像实际上由一层一层的文件系统组成，这种展级的文件系统UnionFS.<br>
bootfs(boot file system)主要包含bootloader和kernel,bootloader主要是引导加载kernel,Linux刚启动时会加载bootfs文件系统，在Docker镜像的最底层是bootfs。这一层与我们典型的Linux/Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs,<br>
rootfs (root fle system)，在bootfs之上。包含的就是典型Linux系统中的/dev/proc/bin,/etc 等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。</p>
<blockquote>
<p>平时我们安装进虚拟机的CentOS都是好几个G，为什么Docker这里才200M?</p>
</blockquote>
<p>对于一个精简的Os，rootfs可以很小，只需要包含最基本的命令，工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供rootfs就可以了。由此可见对于不同的linux发行版bootfs基本是一致的rootfs会有差别,因此不同的发行版可以公用 bootfs.</p>
<p><img src="https://jayhablog.vercel.app/post-images/1617253972074.png" alt="" loading="lazy"><img src="D:%5C%E5%9B%BE%E5%BA%8A%5C20200320105107961.png" alt="" loading="lazy"></p>
<h4 id="换一个方法来说"><strong>换一个方法来说</strong></h4>
<p>Docker 镜像由一些松耦合的只读镜像层组成。</p>
<p>Docker 负责堆叠这些镜像层，并且将它们表示为单个统一的对象。</p>
<p>查看镜像分层的方式可以通过 docker image inspect 命令。下面同样以 ubuntu:latest 镜像为例。</p>
<p>所有的 Docker 镜像都起始于一个基础镜像层，当进行修改或增加新的内容时，就会在当前镜像层之上，创建新的镜像层。</p>
<p>举一个简单的例子，假如基于 Ubuntu Linux 16.04 创建一个新的镜像，这就是新镜像的第一层；如果在该镜像中添加python 包，就会在基础镜像层之上创建第二个镜像层；如果继续添加一个安全补丁，就会创建第三个镜像层。</p>
<p>该镜像当前已经包含 3 个镜像层，如下图所示（这只是一个用于演示的很简单的例子）。</p>
<p><img src="https://jayhablog.vercel.app/post-images/1617253896321.gif" alt="" loading="lazy"><img src="D:%5C%E5%9B%BE%E5%BA%8A%5C4-1Z416164115364.gif" alt="" loading="lazy"></p>
<p><strong><code>多个镜像之间可以并且确实会共享镜像层。这样可以有效节省空间并提升性能</code></strong>。</p>
<p>在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合，理解这一点非常重要。下图中举了一个简单的例子，每个镜像层包含 3 个文件，而镜像包含了来自两个镜像层的 6 个文件。</p>
<p><img src="https://jayhablog.vercel.app/post-images/1617253822923.gif" alt="" loading="lazy"><img src="D:%5C%E5%9B%BE%E5%BA%8A%5C4-1Z41616413R94.gif" alt="" loading="lazy"></p>
<p>上图中的镜像层跟之前图中的略有区别，主要目的是便于展示文件。</p>
<p>下图中展示了一个稍微复杂的三层镜像，在外部看来整个镜像只有 6 个文件，这是因为最上层中的文件 7 是文件 5 的一个更新版本。</p>
<p><img src="https://jayhablog.vercel.app/post-images/1617253858775.gif" alt="" loading="lazy"><img src="D:%5C%E5%9B%BE%E5%BA%8A%5C4-1Z416164203H1.gif" alt="" loading="lazy"></p>
<p>这种情况下，上层镜像层中的文件覆盖了底层镜像层中的文件。这样就使得文件的更新版本作为一个新镜像层添加到镜像当中。</p>
<p>Docker 通过存储引擎（新版本采用快照机制）的方式来实现镜像层堆栈，并保证多镜像层对外展示为统一的文件系统。</p>
<p>Linux 上可用的存储引擎有 AUFS、Overlay2、Device Mapper、Btrfs 以及 ZFS。顾名思义，每种存储引擎都基于 Linux 中对应的文件系统或者块设备技术，并且每种存储引擎都有其独有的性能特点。</p>
<p>Docker 在 Windows 上仅支持 windowsfilter 一种存储引擎，该引擎基于 NTFS 文件系统之上实现了分层和 CoW[1]。</p>
<p>下图展示了与系统显示相同的三层镜像。所有镜像层堆叠并合并，对外提供统一的视图。</p>
<figure data-type="image" tabindex="1"><img src="http://c.biancheng.net/uploads/allimg/190416/4-1Z4161642301E.gif" alt="从系统角度看三层镜像" loading="lazy"></figure>
<p>回顾一下之前用于拉取 nigelpoulton/tu-demo 仓库下全部包含标签的 docker image pull 命令（包含 -a 参数）。</p>
<pre><code class="language-bash">$ docker image pull -a nigelpoulton/tu-demo
 
 latest: Pulling from nigelpoulton/tu-demo
 237d5fcd25cf: Pull complete
 a3ed95caeb02: Pull complete
 &lt;Snip&gt;
 Digest: sha256:42e34e546cee61adb100...a0c5b53f324a9e1c1aae451e9
 
 v1: Pulling from nigelpoulton/tu-demo
 237d5fcd25cf: Already exists
 a3ed95caeb02: Already exists
 &lt;Snip&gt;
 Digest: sha256:9ccc0c67e5c5eaae4beb...24c1d5c80f2c9623cbcc9b59a
 
 v2: Pulling from nigelpoulton/tu-demo
 237d5fcd25cf: Already exists
 a3ed95caeb02: Already exists
 &lt;Snip&gt;
 eab5aaac65de: Pull complete
 Digest: sha256:d3c0d8c9d5719d31b79c...fef58a7e038cf0ef2ba5eb74c
 
 Status: Downloaded newer image for nigelpoulton/tu-demo
 
 $ docker image ls
 REPOSITORY TAG IMAGE ID CREATED SIZE
 nigelpoulton/tu-demo v2 6ac...ead 4 months ago 211.6 MB
 nigelpoulton/tu-demo latest 9b9...e29 4 months ago 211.6 MB
 nigelpoulton/tu-demo v1 9b9...e29 4 months ago 211.6 MB
</code></pre>
<p>注意那些以 Already exists 结尾的行。</p>
<p>由这几行可见，Docker 很聪明，可以识别出要拉取的镜像中，哪几层已经在本地存在。</p>
<p>在本例中，Docker 首先尝试拉取标签为 latest 的镜像。然后，当拉取标签为 v1 和 v2 的镜像时，Docker 注意到组成这两个镜像的镜像层，有一部分已经存在了。出现这种情况的原因是前面 3 个镜像相似度很高，所以共享了很多镜像层。</p>
<p>如前所述，Docker 在 Linux 上支持很多存储引擎（Snapshotter）。每个存储引擎都有自己的镜像分层、镜像层共享以及写时复制（CoW）技术的具体实现。</p>
<h1 id="容器和虚拟机">容器和虚拟机</h1>
<p>容器和虚拟机都依赖于宿主机才能运行。宿主机可以是笔记本，是数据中心的物理服务器，也可以是公有云的某个实例。</p>
<p>在下面的示例中，假设宿主机是一台需要运行 4 个业务应用的物理服务器。</p>
<p>在虚拟机模型中，首先要开启物理机并启动 Hypervisor 引导程序。一旦 Hypervisor 启动，就会占有机器上的全部物理资源，如 CPU、RAM、存储和 NIC。</p>
<p>Hypervisor 接下来就会将这些物理资源划分为虚拟资源，并且看起来与真实物理资源完全一致。</p>
<p>然后 Hypervisor 会将这些资源打包进一个叫作虚拟机（VM）的软件结构当中。这样用户就可以使用这些虚拟机，并在其中安装操作系统和应用。</p>
<p>前面提到需要在物理机上运行 4 个应用，所以在 Hypervisor 之上需要创建 4 个虚拟机并安装 4 个操作系统，然后安装 4 个应用。当操作完成后，结构如下图所示。</p>
<figure data-type="image" tabindex="2"><img src="http://c.biancheng.net/uploads/allimg/190417/4-1Z41G01336346.gif" alt="运行4个业务应用的物理服务器" loading="lazy"></figure>
<p>而容器模型则略有不同。</p>
<p>服务器启动之后，所选择的操作系统会启动。在 Docker 世界中可以选择 Linux，或者内核支持内核中的容器原语的新版本 Windows。</p>
<p>与虚拟机模型相同，OS 也占用了全部硬件资源。在 OS 层之上，需要安装容器引擎（如 Docker）。</p>
<p>容器引擎可以获取系统资源，比如进程树、文件系统以及网络栈，接着将资源分割为安全的互相隔离的资源结构，称之为容器。</p>
<p>每个容器看起来就像一个真实的操作系统，在其内部可以运行应用。按照前面的假设，需要在物理机上运行 4 个应用。</p>
<p>因此，需要划分出 4 个容器并在每个容器中运行一个应用，如下图所示。</p>
<figure data-type="image" tabindex="3"><img src="http://c.biancheng.net/uploads/allimg/190417/4-1Z41G01424234.gif" alt="划分4个容器" loading="lazy"></figure>
<p>从更高层面上来讲，Hypervisor 是硬件虚拟化（Hardware Virtualization）——Hypervisor 将硬件物理资源划分为虚拟资源。</p>
<p>容器是操作系统虚拟化（OS Virtualization）——容器将系统资源划分为虚拟资源。</p>
<h1 id="虚拟机的额外开销">虚拟机的额外开销</h1>
<p>基于前文所述内容，接下来会着重探讨 Hypervisor 模型的一个主要问题。</p>
<p>首先我们的目标是在一台物理机上运行 4 个业务相关应用。每种模型示例中都安装了一个操作系统或者 Hypervisor（一种针对虚拟机高度优化后的操作系统）。</p>
<p>虚拟机模型将底层硬件资源划分到虚拟机当中。每个虚拟机都是包含了虚拟 CPU、虚拟 RAM、虚拟磁盘等资源的一种软件结构。</p>
<p>因此，每个虚拟机都需要有自己的操作系统来声明、初始化并管理这些虚拟资源。</p>
<p>但是，操作系统本身是有其额外开销的。例如，每个操作系统都消耗一点 CPU、一点 RAM、一点存储空间等。</p>
<p>每个操作系统都需要独立的许可证，并且都需要打补丁升级，每个操作系统也都面临被攻击的风险。</p>
<p>通常将这种现象称作 OS Tax 或者 VM Tax，每个操作系统都占用一定的资源。</p>
<p>容器模型具有在宿主机操作系统中运行的单个内核。在一台主机上运行数十个甚至数百个容器都是可能的——容器共享一个操作系统/内核。</p>
<p>这意味着只有一个操作系统消耗 CPU、RAM 和存储资源，只有一个操作系统需要授权，只有一个操作系统需要升级和打补丁。同时，只有一个操作系统面临被攻击的风险。简言之，就是只有一份 OS 损耗。</p>
<p>在上述单台机器上只需要运行 4 个业务应用的场景中，也许问题尚不明显。但当需要运行成百上千应用的时候，就会引起质的变化。</p>
<p>另一个值得考虑的事情是启动时间。因为容器并不是完整的操作系统，所以其启动要远比虚拟机快。</p>
<p>切记，在容器内部并不需要内核，也就没有定位、解压以及初始化的过程——更不用提在内核启动过程中对硬件的遍历和初始化了。</p>
<p>这些在容器启动的过程中统统都不需要！唯一需要的是位于下层操作系统的共享内核是启动了的！最终结果就是，容器可以在 1s 内启动。唯一对容器启动时间有影响的就是容器内应用启动所花费的时间。</p>
<p>这就是容器模型要比虚拟机模型简洁并且高效的原因了。使用容器可以在更少的资源上运行更多的应用，启动更快，并且支付更少的授权和管理费用，同时面对未知攻击的风险也更小。</p>
<h1 id="docker数据卷数据挂载">docker数据卷（数据挂载）</h1>
<p>docker的镜像是由多个只读的文件系统叠加在一起形成的。当我们在我启动一个容器的时候，docker会加载这些只读层并在这些只读层的上面(栈顶)增加一个读写层。这时如果修改正在运行的容器中已有的文件，那么这个文件将会从只读层复制到读写层。该文件的只读版本还在，只是被上面读写层的该文件的副本隐藏。当删除docker,或者重新启动时，之前的更改将会消失。在Docker中，只读层及在顶部的读写层的组合被称为Union File System（联合文件系统）。<code>简单来说，没有数据卷的时候，删除容器=删除容器内所有数据。</code></p>
<p>为了很好的实现数据保存和数据共享，Docker提出了Volume这个概念，简单的说就是绕过默认的联合文件系统，而以正常的文件或者目录的形式存在于宿主机上。又被称作数据卷。是<code>软连接，数据只有一份，双向同步</code>。</p>
<p>好处就是，<code>比如把本机nginx配置和docker内配置相互挂载，以后修改本机nginx配置后</code>，再打开docker nginx就方便很多了</p>
<h3 id="使用数据卷">使用数据卷</h3>
<blockquote>
<p>方式一：使用命令挂载 -v</p>
</blockquote>
<pre><code class="language-bash">docker run -it -v 宿主机目录:容器内目录
</code></pre>
<p>可以在docker inspect中的monts属性查看挂载情况</p>
<blockquote>
<p>方式二： 使用--mount</p>
</blockquote>
<pre><code class="language-text">docker run --name xxxx -p 8888:8888 --mount   
type:volume,source=/src/xxx,target=/xxx /my:/docker -it imagename /bin/bash 
</code></pre>
<p>type选项，其可以是bind，volume，或 tmpfs。本主题讨论卷，因此类型始终是 volume</p>
<p>注意：使用-v参数时如果本地目录不存在Docker会自动为你创建一个文件夹。使用<code>--mount</code>参数时如果本地目录不存在，Docker会报错。Docker挂载主机目录的默认权限是读写，用户也可以通过增加readonly指定为只读。</p>
<ul>
<li>如果挂载一个空的数据卷到容器中的一个非空目录中，那么这个目录下的文件会被复制到数据卷中。(我的测试：使用 -v 参数并没有这个效果，需要使<code>--mount</code>参数，如果不符请指正)</li>
<li>如果挂载一个非空的数据卷到容器中的一个目录中，那么容器中的目录中会显示数据卷中的数据。如果原来容器中目录非空，那么这些原始数据会被隐藏掉。</li>
</ul>
<p>匿名挂载：docker volume ls命令后 是无序字符串的就是匿名挂载。</p>
<p>具名挂载：配置的时候 变成-v 名字:容器目录 之后本机挂载位置可以通过inspect命令查看  <code>推荐</code></p>
<blockquote>
<p>拓展：在-v 卷名（或者宿主机路径）:容器路径:rw(这个是权限 可以选ro[read only]或者rw[read＆write])</p>
<p>ro即是只能从容器外部改变（即容器内部不可写）</p>
</blockquote>
<hr>
<h1 id="docker网络">docker网络</h1>
<p>没有计网只是的 可以跳过本章节了</p>
<h3 id="docker0">docker0</h3>
<p>输入ip addr 查看网络状况时 很容易找到docker0的描述</p>
<pre><code class="language-bash">3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP 
    link/ether 02:42:ee:b5:9d:73 brd ff:ff:ff:ff:ff:ff
    inet 172.18.0.1/16 brd 172.18.255.255 scope global docker0
       valid_lft forever preferred_lft forever
</code></pre>
<p>docker0即是物理网卡直连NAT为docker生成的虚拟网卡</p>
<p>进入容器内部（我选择进入了centos8的容器） 用ip addr查看</p>
<pre><code class="language-bash">16: eth0@if17: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group 
#16: eth0@if17 是docker0分配的
default 
    link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.18.0.2/16 brd 172.18.255.255 scope global eth0
       valid_lft forever preferred_lft forever
#宿主机一定能ping通内部容器因为172.18.0.2可以发现他就是宿主机docker0给容器分配的网段，是同一网段内的
</code></pre>
<blockquote>
<p>原理</p>
</blockquote>
<p>docker0相当于docker生成的网卡</p>
<p>上面的情况使用的是桥接模式，使用的是evth-pair技术。当启动容器后，在宿主机内ip addr</p>
<p>就会发现出现了</p>
<pre><code class="language-shell">17: veth2844acd@if16: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP 
    link/ether f2:45:bc:90:59:53 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</code></pre>
<p>一个容器 多<code>一对</code>网卡，即容器内的网卡对容器外的网卡。</p>
<p>evth-pair就是一对虚拟设备接口，一段连接协议。</p>
<p>所以evth-pair充当桥梁桥接宿主机和容器机，链接各种虚拟网络设备</p>
<p><mark>---容器间虽然相互隔离，但可以通过docker0转发，所以互相之间ping ip 可以ping通<code>docker0就相当于路由器</code>，docker0给容器分配默认的可用ip---</mark></p>
<p>这个特性有其缺陷，编写微服务的时候常常需要写ip地址调用，当docker遇到不可预测的问题宕机重启后，ip地址变了，写的服务层代码往往会失效。到后面会讲怎么解决。</p>
<h5 id="link">link</h5>
<p>启动容器时，设置 --link属性 后面+被接受容器名，即可实现两个容器间互通(当然 用)，比如</p>
<pre><code class="language-bash">docker run -it -P --name jayha_centos --link jayha_ubuntu7070 centos
</code></pre>
<p>输入docker network 命令 可查看docker的网络id号 通过id号即可用inspect查询目前网络各种情况。我们就会发现</p>
<p><code>link实现原理其实就是把link链接的容器，写死ip在本容器的host文件中，添加了一个映射。</code></p>
<p>所以，link已经是个被不看好的技术，也是个不实用的技术，了解即可。</p>
<hr>
<p><code>由此，我们为了拓展网络自由度，可以自己做网络。</code></p>
<h3 id="扩展docker网络">扩展docker网络</h3>
<p>💛docker网络模式有：bridge（默认），none（不配置网络），host（与宿主机共享网络），container（容器网络连通，局限极大，基本不用）</p>
<p>而拓展docker用的就是bridge</p>
<p>创建网络方式为：</p>
<pre><code class="language-bash">docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet
#                     连接方式设置为桥接    设置子网                网关                网络名
</code></pre>
<p>之后在启动容器时， 设置--net属性时候， 即可用自己创建的网络，这样的话 直接ping容器名字都可以ping通了。</p>
<p>好处就是，<code>不同的集群使用不同的网络，可以保证集群的安全健康。</code></p>
<p>容器与不同的网络之间也是可以打通的 可以使用</p>
<pre><code class="language-bash">docker network connect [参数] [网络] [容器]
</code></pre>
<p>来打通</p>
<hr>
<h1 id="dockerfile">dockerFile</h1>
<p>即是<code>用来构建docker image</code>的构建文件或者可以说是命令脚本，相当于编写docker images的源代码。</p>
<figure data-type="image" tabindex="4"><img src="D:%5C%E5%9B%BE%E5%BA%8A%5CdockerFile%E7%9A%84%E6%8C%87%E4%BB%A4%E5%9C%A8%E5%B9%B2%E4%BB%80%E4%B9%88.png" alt="" loading="lazy"></figure>
<p><strong>FROM：指定基础镜像，必须为第一个命令</strong> ：docker hub上九成九都是从scratch开始的（了解即可 我们不用从这个开始写</p>
<pre><code>格式：
　　FROM &lt;image&gt;
　　FROM &lt;image&gt;:&lt;tag&gt;
　　FROM &lt;image&gt;@&lt;digest&gt;示例：　　FROM mysql:5.6注：　　tag或digest是可选的，如果不使用这两个值时，会使用latest版本的基础镜像
</code></pre>
<p><strong>MAINTAINER: 维护者信息</strong></p>
<pre><code>格式：
    MAINTAINER &lt;name&gt;
示例：
    MAINTAINER Jasper Xu
    MAINTAINER sorex@163.com
    MAINTAINER Jasper Xu &lt;sorex@163.com&gt;
</code></pre>
<p><strong>RUN：构建镜像时执行的命令</strong></p>
<pre><code>RUN用于在镜像容器中执行命令，其有以下两种命令执行方式：
shell执行
格式：
    RUN &lt;command&gt;
exec执行
格式：
    RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]
示例：
    RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]
    RUN apk update
    RUN [&quot;/etc/execfile&quot;, &quot;arg1&quot;, &quot;arg1&quot;]
注：　　RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定--no-cache参数，如：docker build --no-cache
</code></pre>
<p><strong>ADD：将本地文件添加到容器中，tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，类似wget</strong></p>
<pre><code>格式：
    ADD &lt;src&gt;... &lt;dest&gt;
    ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] 用于支持包含空格的路径
示例：
    ADD hom* /mydir/          # 添加所有以&quot;hom&quot;开头的文件
    ADD hom?.txt /mydir/      # ? 替代一个单字符,例如：&quot;home.txt&quot;
    ADD test relativeDir/     # 添加 &quot;test&quot; 到 `WORKDIR`/relativeDir/
    ADD test /absoluteDir/    # 添加 &quot;test&quot; 到 /absoluteDir/
</code></pre>
<p><strong>COPY：功能类似ADD，但是是不会自动解压文件，也不能访问网络资源</strong></p>
<p><strong>CMD：构建容器后调用，也就是在容器启动时才进行调用。</strong></p>
<pre><code>格式：
    CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (执行可执行文件，优先)
    CMD [&quot;param1&quot;,&quot;param2&quot;] (设置了ENTRYPOINT，则直接调用ENTRYPOINT添加参数)
    CMD command param1 param2 (执行shell内部命令)
示例：
    CMD echo &quot;This is a test.&quot; | wc -
    CMD [&quot;/usr/bin/wc&quot;,&quot;--help&quot;]注： 　　CMD不同于RUN，CMD用于指定在容器启动时所要执行的命令，而RUN用于指定镜像构建时所要执行的命令。
</code></pre>
<p><strong>ENTRYPOINT：配置容器，使其可执行化。配合CMD可省去&quot;application&quot;，只使用参数。</strong></p>
<pre><code>格式：
    ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (可执行文件, 优先)
    ENTRYPOINT command param1 param2 (shell内部命令)
示例：
    FROM ubuntu
    ENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]
    CMD [&quot;-c&quot;]注：　　　ENTRYPOINT与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT，而docker run命令中指定的任何参数，都会被当做参数再次传递给ENTRYPOINT。Dockerfile中只允许有一个ENTRYPOINT命令，多指定时会覆盖前面的设置，而只执行最后的ENTRYPOINT指令。
</code></pre>
<p><strong>LABEL：用于为镜像添加元数据</strong></p>
<pre><code>格式：
    LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...
示例：
　　LABEL version=&quot;1.0&quot; description=&quot;这是一个Web服务器&quot; by=&quot;IT笔录&quot;
注：
　　使用LABEL指定元数据时，一条LABEL指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔。推荐将所有的元数据通过一条LABEL指令指定，以免生成过多的中间镜像。
</code></pre>
<p><strong>ENV：设置环境变量</strong></p>
<pre><code>格式：
    ENV &lt;key&gt; &lt;value&gt;  #&lt;key&gt;之后的所有内容均会被视为其&lt;value&gt;的组成部分，因此，一次只能设置一个变量
    ENV &lt;key&gt;=&lt;value&gt; ...  #可以设置多个变量，每个变量为一个&quot;&lt;key&gt;=&lt;value&gt;&quot;的键值对，如果&lt;key&gt;中包含空格，可以使用\来进行转义，也可以通过&quot;&quot;来进行标示；另外，反斜线也可以用于续行
示例：
    ENV myName John Doe
    ENV myDog Rex The Dog
    ENV myCat=fluffy
</code></pre>
<p><strong>EXPOSE：指定于外界交互的端口</strong></p>
<pre><code>格式：
    EXPOSE &lt;port&gt; [&lt;port&gt;...]
示例：
    EXPOSE 80 443
    EXPOSE 8080    EXPOSE 11211/tcp 11211/udp注：　　EXPOSE并不会让容器的端口访问到主机。要使其可访问，需要在docker run运行容器时通过-p来发布这些端口，或通过-P参数来发布EXPOSE导出的所有端口
</code></pre>
<p><strong>VOLUME：用于指定持久化目录</strong></p>
<pre><code>格式：
    VOLUME [&quot;/path/to/dir&quot;]
示例：
    VOLUME [&quot;/data&quot;]
    VOLUME [&quot;/var/www&quot;, &quot;/var/log/apache2&quot;, &quot;/etc/apache2&quot;注：　　一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能：
1 卷可以容器间共享和重用
2 容器并不一定要和其它容器共享卷
3 修改卷后会立即生效
4 对卷的修改不会对镜像产生影响
5 卷会一直存在，直到没有任何容器在使用它
</code></pre>
<p><strong>WORKDIR：工作目录，类似于cd命令</strong></p>
<pre><code>格式：
    WORKDIR /path/to/workdir
示例：
    WORKDIR /a  (这时工作目录为/a)
    WORKDIR b  (这时工作目录为/a/b)
    WORKDIR c  (这时工作目录为/a/b/c)注：　　通过WORKDIR设置工作目录后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT、ADD、COPY等命令都会在该目录下执行。在使用docker run运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。
</code></pre>
<p>**USER:**<strong>指定运行容器时的用户名或 UID，后续的 RUN 也会使用指定用户。使用USER指定用户时，可以使用用户名、UID或GID，或是两者的组合。当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户</strong></p>
<pre><code class="language-bash">格式:
　　USER user
　　USER user:group
　　USER uid
　　USER uid:gid
　　USER user:gid
　　USER uid:group

 示例：
    　　USER www
</code></pre>
<p>注：</p>
<p>使用USER指定用户后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT都将使用该用户。镜像构建完成后，通过<code>docker run</code>运行容器时，可以通过-u参数来覆盖所指定的用户。</p>
<p><strong>ARG：用于指定传递给构建运行时的变量</strong></p>
<pre><code>格式：
    ARG &lt;name&gt;[=&lt;default value&gt;]
示例：
    ARG site
    ARG build_user=www
</code></pre>
<p><strong>ONBUILD：用于设置镜像触发器</strong></p>
<pre><code>格式：　　ONBUILD [INSTRUCTION]
示例：
　　ONBUILD ADD . /app/src
　　ONBUILD RUN /usr/local/bin/python-build --dir /app/src
注：　　当所构建的镜像被用做其它镜像的基础镜像，该镜像中的触发器将会被钥触发
</code></pre>
<p><strong>以下是一个小例子：</strong></p>
<pre><code># This my first nginx Dockerfile
# Version 1.0

# Base images 基础镜像
FROM centos

#MAINTAINER 维护者信息
MAINTAINER tianfeiyu 

#ENV 设置环境变量
ENV PATH /usr/local/nginx/sbin:$PATH

#ADD  文件放在当前目录下，拷过去会自动解压
ADD nginx-1.8.0.tar.gz /usr/local/  
ADD epel-release-latest-7.noarch.rpm /usr/local/  

#RUN 执行以下命令 
RUN rpm -ivh /usr/local/epel-release-latest-7.noarch.rpm
RUN yum install -y wget lftp gcc gcc-c++ make openssl-devel pcre-devel pcre &amp;&amp; yum clean all
RUN useradd -s /sbin/nologin -M www

#WORKDIR 相当于cd
WORKDIR /usr/local/nginx-1.8.0 

RUN ./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-pcre &amp;&amp; make &amp;&amp; make install

RUN echo &quot;daemon off;&quot; &gt;&gt; /etc/nginx.conf

#EXPOSE 映射端口
EXPOSE 80

#CMD 运行以下命令
CMD [&quot;nginx&quot;]
</code></pre>
<p><strong><code>可以！推送到阿里云的镜像仓库！</code></strong></p>
<p><s>吐槽：极其类似github 我怀疑不管docker官方还是阿里云代码都借鉴了很多linus写的东西，至少是思想</s></p>
<figure data-type="image" tabindex="5"><img src="https://jayhablog.vercel.app/post-images/1617773530086.png" alt="Jayha的，别乱用" loading="lazy"></figure>
<hr>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[更优雅的写接口（转）]]></title>
        <id>https://jayhablog.vercel.app/geng-you-ya-de-xie-jie-kou-zhuan/</id>
        <link href="https://jayhablog.vercel.app/geng-you-ya-de-xie-jie-kou-zhuan/">
        </link>
        <updated>2020-11-20T08:27:04.000Z</updated>
        <content type="html"><![CDATA[<p>作者：RudeCrab<br>
来源：juejin.im/post/6844904101940117511<br>
前言</p>
<p>一个后端接口大致分为四个部分组成：接口地址（url）、接口请求方式（get、post等）、请求数据（request）、响应数据（response）。如何构建这几个部分每个公司要求都不同，没有什么“一定是最好的”标准，但一个优秀的后端接口和一个糟糕的后端接口对比起来差异还是蛮大的，其中最重要的关键点就是看是否规范! 本文就一步一步演示如何构建起一个优秀的后端接口体系，体系构建好了自然就有了规范，同时再构建新的后端接口也会十分轻松。<br>
所需依赖包</p>
<p>这里用的是SpringBoot配置项目，本文讲解的重点是后端接口，所以只需要导入一个spring-boot-starter-web包就可以了：</p>
<!--web依赖包，web应用必备-->
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-web</artifactId>
</dependency>
本文还用了swagger来生成API文档，lombok来简化类，不过这两者不是必须的，可用可不用。
参数校验
<p>一个接口一般对参数（请求数据）都会进行安全校验，参数校验的重要性自然不必多说，那么如何对参数进行校验就有讲究了。<br>
业务层校验<br>
首先我们来看一下最常见的做法，就是在业务层进行参数校验：<br>
public String addUser(User user) {<br>
if (user == null || user.getId() == null || user.getAccount() == null || user.getPassword() == null || user.getEmail() == null) {<br>
return &quot;对象或者对象字段不能为空&quot;;<br>
}<br>
if (StringUtils.isEmpty(user.getAccount()) || StringUtils.isEmpty(user.getPassword()) || StringUtils.isEmpty(user.getEmail())) {<br>
return &quot;不能输入空字符串&quot;;<br>
}<br>
if (user.getAccount().length() &lt; 6 || user.getAccount().length() &gt; 11) {<br>
return &quot;账号长度必须是6-11个字符&quot;;<br>
}<br>
if (user.getPassword().length() &lt; 6 || user.getPassword().length() &gt; 16) {<br>
return &quot;密码长度必须是6-16个字符&quot;;<br>
}<br>
if (!Pattern.matches(&quot;<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>+@[a-zA-Z0-9_-]+(\.[a-zA-Z0-9_-]+)+$&quot;, user.getEmail())) {<br>
return &quot;邮箱格式不正确&quot;;<br>
}<br>
// 参数校验完毕后这里就写上业务逻辑<br>
return &quot;success&quot;;<br>
}<br>
这样做当然是没有什么错的，而且格式排版整齐也一目了然，不过这样太繁琐了，这还没有进行业务操作呢光是一个参数校验就已经这么多行代码，实在不够优雅。我们来改进一下，使用Spring Validator和Hibernate Validator这两套Validator来进行方便的参数校验！这两套Validator依赖包已经包含在前面所说的web依赖包里了，所以可以直接使用。<br>
Validator + BindResult进行校验<br>
Validator可以非常方便的制定校验规则，并自动帮你完成校验。首先在入参里需要校验的字段加上注解,每个注解对应不同的校验规则，并可制定校验失败后的信息：<br>
@Data<br>
public class User {<br>
@NotNull(message = &quot;用户id不能为空&quot;)<br>
private Long id;</p>
<pre><code>@NotNull(message = &quot;用户账号不能为空&quot;)
@Size(min = 6, max = 11, message = &quot;账号长度必须是6-11个字符&quot;)
private String account;

@NotNull(message = &quot;用户密码不能为空&quot;)
@Size(min = 6, max = 11, message = &quot;密码长度必须是6-16个字符&quot;)
private String password;

@NotNull(message = &quot;用户邮箱不能为空&quot;)
@Email(message = &quot;邮箱格式不正确&quot;)
private String email;
</code></pre>
<p>}<br>
校验规则和错误提示信息配置完毕后，接下来只需要在接口需要校验的参数上加上@Valid注解，并添加BindResult参数即可方便完成验证：<br>
@RestController<br>
@RequestMapping(&quot;user&quot;)<br>
public class UserController {<br>
@Autowired<br>
private UserService userService;</p>
<pre><code>@PostMapping(&quot;/addUser&quot;)
public String addUser(@RequestBody @Valid User user, BindingResult bindingResult) {
    // 如果有参数校验失败，会将错误信息封装成对象组装在BindingResult里
    for (ObjectError error : bindingResult.getAllErrors()) {
        return error.getDefaultMessage();
    }
    return userService.addUser(user);
}
</code></pre>
<p>}<br>
这样当请求数据传递到接口的时候Validator就自动完成校验了，校验的结果就会封装到BindingResult中去，如果有错误信息我们就直接返回给前端，业务逻辑代码也根本没有执行下去。此时，业务层里的校验代码就已经不需要了：<br>
public String addUser(User user) {<br>
// 直接编写业务逻辑<br>
return &quot;success&quot;;<br>
}<br>
现在可以看一下参数校验效果。我们故意给这个接口传递一个不符合校验规则的参数，先传递一个错误数据给接口，故意将password这个字段不满足校验条件：<br>
{<br>
&quot;account&quot;: &quot;12345678&quot;,<br>
&quot;email&quot;: &quot;123@qq.com&quot;,<br>
&quot;id&quot;: 0,<br>
&quot;password&quot;: &quot;123&quot;<br>
}<br>
再来看一下接口的响应数据：</p>
<p>img<br>
这样是不是方便很多？不难看出使用Validator校验有如下几个好处：<br>
简化代码，之前业务层那么一大段校验代码都被省略掉了。<br>
使用方便，那么多校验规则可以轻而易举的实现，比如邮箱格式验证，之前自己手写正则表达式要写那么一长串，还容易出错，用Validator直接一个注解搞定。（还有更多校验规则注解，可以自行去了解哦）<br>
减少耦合度，使用Validator能够让业务层只关注业务逻辑，从基本的参数校验逻辑中脱离出来。<br>
使用Validator+ BindingResult已经是非常方便实用的参数校验方式了，在实际开发中也有很多项目就是这么做的，不过这样还是不太方便，因为你每写一个接口都要添加一个BindingResult参数，然后再提取错误信息返回给前端。这样有点麻烦，并且重复代码很多（尽管可以将这个重复代码封装成方法）。我们能否去掉BindingResult这一步呢？当然是可以的！<br>
Validator + 自动抛出异常<br>
我们完全可以将BindingResult这一步给去掉：<br>
@PostMapping(&quot;/addUser&quot;)<br>
public String addUser(@RequestBody @Valid User user) {<br>
return userService.addUser(user);<br>
}<br>
去掉之后会发生什么事情呢？直接来试验一下，还是按照之前一样故意传递一个不符合校验规则的参数给接口。此时我们观察控制台可以发现接口已经引发MethodArgumentNotValidException异常了：</p>
<p>img<br>
其实这样就已经达到我们想要的效果了，参数校验不通过自然就不执行接下来的业务逻辑，去掉BindingResult后会自动引发异常，异常发生了自然而然就不会执行业务逻辑。也就是说，我们完全没必要添加相关BindingResult相关操作嘛。不过事情还没有完，异常是引发了，可我们并没有编写返回错误信息的代码呀，那参数校验失败了会响应什么数据给前端呢？我们来看一下刚才异常发生后接口响应的数据：</p>
<p>img<br>
没错，是直接将整个错误对象相关信息都响应给前端了！这样就很难受，不过解决这个问题也很简单，就是我们接下来要讲的全局异常处理！<br>
全局异常处理</p>
<p>参数校验失败会自动引发异常，我们当然不可能再去手动捕捉异常进行处理，不然还不如用之前BindingResult方式呢。又不想手动捕捉这个异常，又要对这个异常进行处理，那正好使用SpringBoot全局异常处理来达到一劳永逸的效果！<br>
基本使用<br>
首先，我们需要新建一个类，在这个类上加上@ControllerAdvice或@RestControllerAdvice注解，这个类就配置成全局处理类了。（这个根据你的Controller层用的是@Controller还是@RestController来决定） 然后在类中新建方法，在方法上加上@ExceptionHandler注解并指定你想处理的异常类型，接着在方法内编写对该异常的操作逻辑，就完成了对该异常的全局处理！我们现在就来演示一下对参数校验失败抛出的MethodArgumentNotValidException全局处理：<br>
@RestControllerAdvice<br>
public class ExceptionControllerAdvice {</p>
<pre><code>@ExceptionHandler(MethodArgumentNotValidException.class)
public String MethodArgumentNotValidExceptionHandler(MethodArgumentNotValidException e) {
 // 从异常对象中拿到ObjectError对象
    ObjectError objectError = e.getBindingResult().getAllErrors().get(0);
    // 然后提取错误提示信息进行返回
    return objectError.getDefaultMessage();
}
</code></pre>
<p>}<br>
我们再来看下这次校验失败后的响应数据：</p>
<p>img<br>
没错，这次返回的就是我们制定的错误提示信息！我们通过全局异常处理优雅的实现了我们想要的功能！以后我们再想写接口参数校验，就只需要在入参的成员变量上加上Validator校验规则注解，然后在参数上加上@Valid注解即可完成校验，校验失败会自动返回错误提示信息，无需任何其他代码！<br>
自定义异常<br>
全局处理当然不会只能处理一种异常，用途也不仅仅是对一个参数校验方式进行优化。在实际开发中，如何对异常处理其实是一个很麻烦的事情。传统处理异常一般有以下烦恼：<br>
是捕获异常(try...catch)还是抛出异常(throws)<br>
是在controller层做处理还是在service层处理又或是在dao层做处理<br>
处理异常的方式是啥也不做，还是返回特定数据，如果返回又返回什么数据<br>
不是所有异常我们都能预先进行捕捉，如果发生了没有捕捉到的异常该怎么办？<br>
以上这些问题都可以用全局异常处理来解决，全局异常处理也叫统一异常处理，全局和统一处理代表什么？代表规范！ 规范有了，很多问题就会迎刃而解！全局异常处理的基本使用方式大家都已经知道了，我们接下来更进一步的规范项目中的异常处理方式：自定义异常。在很多情况下，我们需要手动抛出异常，比如在业务层当有些条件并不符合业务逻辑，我这时候就可以手动抛出异常从而触发事务回滚。那手动抛出异常最简单的方式就是throw new RuntimeException(&quot;异常信息&quot;)了，不过使用自定义会更好一些：<br>
自定义异常可以携带更多的信息，不像这样只能携带一个字符串。<br>
项目开发中经常是很多人负责不同的模块，使用自定义异常可以统一了对外异常展示的方式。<br>
自定义异常语义更加清晰明了，一看就知道是项目中手动抛出的异常。<br>
我们现在就来开始写一个自定义异常：<br>
@Getter //只要getter方法，无需setter<br>
public class APIException extends RuntimeException {<br>
private int code;<br>
private String msg;</p>
<pre><code>public APIException() {
    this(1001, &quot;接口错误&quot;);
}

public APIException(String msg) {
    this(1001, msg);
}

public APIException(int code, String msg) {
    super(msg);
    this.code = code;
    this.msg = msg;
}
</code></pre>
<p>}<br>
在刚才的全局异常处理类中记得添加对我们自定义异常的处理：<br>
@ExceptionHandler(APIException.class)<br>
public String APIExceptionHandler(APIException e) {<br>
return e.getMsg();<br>
}<br>
这样就对异常的处理就比较规范了，当然还可以添加对Exception的处理，这样无论发生什么异常我们都能屏蔽掉然后响应数据给前端，不过建议最后项目上线时这样做，能够屏蔽掉错误信息暴露给前端，在开发中为了方便调试还是不要这样做。现在全局异常处理和自定义异常已经弄好了，不知道大家有没有发现一个问题，就是当我们抛出自定义异常的时候全局异常处理只响应了异常中的错误信息msg给前端，并没有将错误代码code返回。这就要引申出我们接下来要讲的东西了：数据统一响应<br>
数据统一响应</p>
<p>现在我们规范好了参数校验方式和异常处理方式，然而还没有规范响应数据！比如我要获取一个分页信息数据，获取成功了呢自然就返回的数据列表，获取失败了后台就会响应异常信息，即一个字符串，就是说前端开发者压根就不知道后端响应过来的数据会是啥样的！所以，统一响应数据是前后端规范中必须要做的！<br>
自定义统一响应体<br>
统一数据响应第一步肯定要做的就是我们自己自定义一个响应体类，无论后台是运行正常还是发生异常，响应给前端的数据格式是不变的！那么如何定义响应体呢？可以参考我们自定义异常类，也来一个响应信息代码code和响应信息说明msg：<br>
@Getter<br>
public class ResultVO<T> {<br>
/**<br>
* 状态码，比如1000代表响应成功<br>
<em>/<br>
private int code;<br>
/</em>*<br>
* 响应信息，用来说明响应情况<br>
<em>/<br>
private String msg;<br>
/</em>*<br>
* 响应的具体数据<br>
*/<br>
private T data;</p>
<pre><code>public ResultVO(T data) {
    this(1000, &quot;success&quot;, data);
}

public ResultVO(int code, String msg, T data) {
    this.code = code;
    this.msg = msg;
    this.data = data;
}
</code></pre>
<p>}<br>
然后我们修改一下全局异常处理那的返回值：<br>
@ExceptionHandler(APIException.class)<br>
public ResultVO<String> APIExceptionHandler(APIException e) {<br>
// 注意哦，这里返回类型是自定义响应体<br>
return new ResultVO&lt;&gt;(e.getCode(), &quot;响应失败&quot;, e.getMsg());<br>
}</p>
<p>@ExceptionHandler(MethodArgumentNotValidException.class)<br>
public ResultVO<String> MethodArgumentNotValidExceptionHandler(MethodArgumentNotValidException e) {<br>
ObjectError objectError = e.getBindingResult().getAllErrors().get(0);<br>
// 注意哦，这里返回类型是自定义响应体<br>
return new ResultVO&lt;&gt;(1001, &quot;参数校验失败&quot;, objectError.getDefaultMessage());<br>
}<br>
我们再来看一下此时如果发生异常了会响应什么数据给前端：</p>
<p>img<br>
OK，这个异常信息响应就非常好了，状态码和响应说明还有错误提示数据都返给了前端，并且是所有异常都会返回相同的格式！异常这里搞定了，别忘了我们到接口那也要修改返回类型，我们新增一个接口好来看看效果：<br>
@GetMapping(&quot;/getUser&quot;)<br>
public ResultVO<User> getUser() {<br>
User user = new User();<br>
user.setId(1L);<br>
user.setAccount(&quot;12345678&quot;);<br>
user.setPassword(&quot;12345678&quot;);<br>
user.setEmail(&quot;123@qq.com&quot;);</p>
<pre><code>return new ResultVO&lt;&gt;(user);
</code></pre>
<p>}<br>
看一下如果响应正确返回的是什么效果：</p>
<p>img<br>
这样无论是正确响应还是发生异常，响应数据的格式都是统一的，十分规范！<br>
数据格式是规范了，不过响应码code和响应信息msg还没有规范呀！大家发现没有，无论是正确响应，还是异常响应，响应码和响应信息是想怎么设置就怎么设置，要是10个开发人员对同一个类型的响应写10个不同的响应码，那这个统一响应体的格式规范就毫无意义！所以，必须要将响应码和响应信息给规范起来。<br>
响应码枚举<br>
要规范响应体中的响应码和响应信息用枚举简直再恰当不过了，我们现在就来创建一个响应码枚举类：<br>
@Getter<br>
public enum ResultCode {</p>
<pre><code>SUCCESS(1000, &quot;操作成功&quot;),

FAILED(1001, &quot;响应失败&quot;),

VALIDATE_FAILED(1002, &quot;参数校验失败&quot;),

ERROR(5000, &quot;未知错误&quot;);

private int code;
private String msg;

ResultCode(int code, String msg) {
    this.code = code;
    this.msg = msg;
}
</code></pre>
<p>}<br>
然后修改响应体的构造方法，让其只准接受响应码枚举来设置响应码和响应信息：<br>
public ResultVO(T data) {<br>
this(ResultCode.SUCCESS, data);<br>
}</p>
<p>public ResultVO(ResultCode resultCode, T data) {<br>
this.code = resultCode.getCode();<br>
this.msg = resultCode.getMsg();<br>
this.data = data;<br>
}<br>
然后同时修改全局异常处理的响应码设置方式：<br>
@ExceptionHandler(APIException.class)<br>
public ResultVO<String> APIExceptionHandler(APIException e) {<br>
// 注意哦，这里传递的响应码枚举<br>
return new ResultVO&lt;&gt;(ResultCode.FAILED, e.getMsg());<br>
}</p>
<p>@ExceptionHandler(MethodArgumentNotValidException.class)<br>
public ResultVO<String> MethodArgumentNotValidExceptionHandler(MethodArgumentNotValidException e) {<br>
ObjectError objectError = e.getBindingResult().getAllErrors().get(0);<br>
// 注意哦，这里传递的响应码枚举<br>
return new ResultVO&lt;&gt;(ResultCode.VALIDATE_FAILED, objectError.getDefaultMessage());<br>
}<br>
这样响应码和响应信息只能是枚举规定的那几个，就真正做到了响应数据格式、响应码和响应信息规范化、统一化！<br>
全局处理响应数据<br>
接口返回统一响应体 + 异常也返回统一响应体，其实这样已经很好了，但还是有可以优化的地方。要知道一个项目下来定义的接口搞个几百个太正常不过了，要是每一个接口返回数据时都要用响应体来包装一下好像有点麻烦，有没有办法省去这个包装过程呢？当然是有滴，还是要用到全局处理。<br>
首先，先创建一个类加上注解使其成为全局处理类。然后继承ResponseBodyAdvice接口重写其中的方法，即可对我们的controller进行增强操作，具体看代码和注释：<br>
@RestControllerAdvice(basePackages = {&quot;com.rudecrab.demo.controller&quot;}) // 注意哦，这里要加上需要扫描的包<br>
public class ResponseControllerAdvice implements ResponseBodyAdvice<Object> {<br>
@Override<br>
public boolean supports(MethodParameter returnType, Class<? extends HttpMessageConverter<?>&gt; aClass) {<br>
// 如果接口返回的类型本身就是ResultVO那就没有必要进行额外的操作，返回false<br>
return !returnType.getParameterType().equals(ResultVO.class);<br>
}</p>
<pre><code>@Override
public Object beforeBodyWrite(Object data, MethodParameter returnType, MediaType mediaType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; aClass, ServerHttpRequest request, ServerHttpResponse response) {
    // String类型不能直接包装，所以要进行些特别的处理
    if (returnType.getGenericParameterType().equals(String.class)) {
        ObjectMapper objectMapper = new ObjectMapper();
        try {
            // 将数据包装在ResultVO里后，再转换为json字符串响应给前端
            return objectMapper.writeValueAsString(new ResultVO&lt;&gt;(data));
        } catch (JsonProcessingException e) {
            throw new APIException(&quot;返回String类型错误&quot;);
        }
    }
    // 将原本的数据包装在ResultVO里
    return new ResultVO&lt;&gt;(data);
}
</code></pre>
<p>}<br>
重写的这两个方法是用来在controller将数据进行返回前进行增强操作，supports方法要返回为true才会执行beforeBodyWrite方法，所以如果有些情况不需要进行增强操作可以在supports方法里进行判断。对返回数据进行真正的操作还是在beforeBodyWrite方法中，我们可以直接在该方法里包装数据，这样就不需要每个接口都进行数据包装了，省去了很多麻烦。<br>
我们可以现在去掉接口的数据包装来看下效果：<br>
@GetMapping(&quot;/getUser&quot;)<br>
public User getUser() {<br>
User user = new User();<br>
user.setId(1L);<br>
user.setAccount(&quot;12345678&quot;);<br>
user.setPassword(&quot;12345678&quot;);<br>
user.setEmail(&quot;123@qq.com&quot;);<br>
// 注意哦，这里是直接返回的User类型，并没有用ResultVO进行包装<br>
return user;<br>
}<br>
然后我们来看下响应数据：</p>
<p>img<br>
成功对数据进行了包装！<br>
注意：beforeBodyWrite方法里包装数据无法对String类型的数据直接进行强转，所以要进行特殊处理，这里不讲过多的细节，有兴趣可以自行深入了解。<br>
总结</p>
<p>自此整个后端接口基本体系就构建完毕了<br>
通过Validator + 自动抛出异常来完成了方便的参数校验<br>
通过全局异常处理 + 自定义异常完成了异常操作的规范<br>
通过数据统一响应完成了响应数据的规范<br>
多个方面组装非常优雅的完成了后端接口的协调，让开发人员有更多的经历注重业务逻辑代码，轻松构建后端接口<br>
再次强调，项目体系该怎么构建、后端接口该怎么写都没有一个绝对统一的标准，不是说一定要按照本文的来才是最好的，你怎样都可以，本文每一个环节你都可以按照自己的想法来进行编码，我只是提供了一个思路！<br>
项目源码地址</p>
<p>https://github.com/RudeCrab/rude-java/tree/master/project-practice/validation-and-exception-handler</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>a-zA-Z0-9_- <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springboot整合apchepoi 实现excel的导入导出]]></title>
        <id>https://jayhablog.vercel.app/springboot-zheng-he-apchepoi-shi-xian-excel-de-dao-ru-dao-chu/</id>
        <link href="https://jayhablog.vercel.app/springboot-zheng-he-apchepoi-shi-xian-excel-de-dao-ru-dao-chu/">
        </link>
        <updated>2020-11-20T08:17:31.000Z</updated>
        <content type="html"><![CDATA[<p>转自ruoyi开发文档</p>
<h2 id="导入导出">导入导出</h2>
<p>在实际开发中经常需要使用导入导出功能来加快数据的操作。在项目中可以使用注解来完成此项功能。 在需要被导入导出的实体类属性添加<code>@Excel</code>注解  该注解编写在转载者在桌面的utils包内（以改良ruoyi包下的excelUtil 支持date、localdate、localdatetime转换。如有需要可以联系本网站管理员）</p>
<p>目前支持参数如下：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>sort</td>
<td>int</td>
<td>Integer.MAX_VALUE</td>
<td>导出时在excel中排序</td>
</tr>
<tr>
<td>name</td>
<td>String</td>
<td>空</td>
<td>导出到Excel中的名字</td>
</tr>
<tr>
<td>dateFormat</td>
<td>String</td>
<td>空</td>
<td>日期格式, 如: yyyy-MM-dd</td>
</tr>
<tr>
<td>dictType</td>
<td>String</td>
<td>空</td>
<td>如果是字典类型，请设置字典的type值 (如: sys_user_sex)</td>
</tr>
<tr>
<td>readConverterExp</td>
<td>String</td>
<td>空</td>
<td>读取内容转表达式 (如: 0=男,1=女,2=未知)</td>
</tr>
<tr>
<td>separator</td>
<td>String</td>
<td>,</td>
<td>分隔符，读取字符串组内容</td>
</tr>
<tr>
<td>scale</td>
<td>int</td>
<td>-1</td>
<td>BigDecimal 精度 默认:-1(默认不开启BigDecimal格式化)</td>
</tr>
<tr>
<td>roundingMode</td>
<td>int</td>
<td>BigDecimal.ROUND_HALF_EVEN</td>
<td>BigDecimal 舍入规则 默认:BigDecimal.ROUND_HALF_EVEN</td>
</tr>
<tr>
<td>columnType</td>
<td>Enum</td>
<td>Type.STRING</td>
<td>导出类型（0数字 1字符串）</td>
</tr>
<tr>
<td>height</td>
<td>String</td>
<td>14</td>
<td>导出时在excel中每个列的高度 单位为字符</td>
</tr>
<tr>
<td>width</td>
<td>String</td>
<td>16</td>
<td>导出时在excel中每个列的宽 单位为字符</td>
</tr>
<tr>
<td>suffix</td>
<td>String</td>
<td>空</td>
<td>文字后缀,如% 90 变成90%</td>
</tr>
<tr>
<td>defaultValue</td>
<td>String</td>
<td>空</td>
<td>当值为空时,字段的默认值</td>
</tr>
<tr>
<td>prompt</td>
<td>String</td>
<td>空</td>
<td>提示信息</td>
</tr>
<tr>
<td>combo</td>
<td>String</td>
<td>Null</td>
<td>设置只能选择不能输入的列内容</td>
</tr>
<tr>
<td>targetAttr</td>
<td>String</td>
<td>空</td>
<td>另一个类中的属性名称,支持多级获取,以小数点隔开</td>
</tr>
<tr>
<td>isStatistics</td>
<td>boolean</td>
<td>false</td>
<td>是否自动统计数据,在最后追加一行统计数据总和</td>
</tr>
<tr>
<td>type</td>
<td>Enum</td>
<td>Type.ALL</td>
<td>字段类型（0：导出导入；1：仅导出；2：仅导入）</td>
</tr>
</tbody>
</table>
<h3 id="导出实现流程">导出实现流程</h3>
<p>1、前端调用封装好的方法$.table.init，传入后台<code>exportUrl</code></p>
<pre><code class="language-javascript">var options = {
	exportUrl: prefix + &quot;/export&quot;,
	columns: [{
		field: 'id',
		title: '主键'
	},
	{
		field: 'name',
		title: '名称'
	}]
};
$.table.init(options);
</code></pre>
<p>2、添加导出按钮事件</p>
<pre><code class="language-html">&lt;a class=&quot;btn btn-warning&quot; onclick=&quot;$.table.exportExcel()&quot;&gt;
	&lt;i class=&quot;fa fa-download&quot;&gt;&lt;/i&gt; 导出
&lt;/a&gt;
</code></pre>
<p>3、在实体变量上添加@Excel注解</p>
<pre><code class="language-java">@Excel(name = &quot;用户序号&quot;, prompt = &quot;用户编号&quot;)
private Long userId;

@Excel(name = &quot;用户名称&quot;)
private String userName;
	
@Excel(name = &quot;用户性别&quot;, readConverterExp = &quot;0=男,1=女,2=未知&quot;)
private String sex;

@Excel(name = &quot;最后登陆时间&quot;, width = 30, dateFormat = &quot;yyyy-MM-dd HH:mm:ss&quot;)
private Date loginDate;
</code></pre>
<p>4、在Controller添加导出方法</p>
<pre><code class="language-java">@PostMapping(&quot;/export&quot;)
@ResponseBody
public AjaxResult export(User user)
{
	List&lt;User&gt; list = userService.selectUserList(user);
	ExcelUtil&lt;User&gt; util = new ExcelUtil&lt;User&gt;(User.class);
	return util.exportExcel(list, &quot;用户数据&quot;);
}
</code></pre>
<h3 id="导入实现流程">导入实现流程</h3>
<p>1、前端调用封装好的方法$.table.init，传入后台importUrl。</p>
<pre><code class="language-javascript">var options = {
	importUrl: prefix + &quot;/importData&quot;,
	columns: [{
		field: 'id',
		title: '主键'
	},
	{
		field: 'name',
		title: '名称'
	}]
};
$.table.init(options);
</code></pre>
<p>2、添加导入按钮事件</p>
<pre><code class="language-html">&lt;a class=&quot;btn btn-info&quot; onclick=&quot;$.table.importExcel()&quot;&gt;
	&lt;i class=&quot;fa fa-upload&quot;&gt;&lt;/i&gt; 导入
&lt;/a&gt;
</code></pre>
<p>3、添加导入前端代码，form默认id为importForm，也可指定importExcel(id)</p>
<pre><code class="language-html">&lt;!-- 导入区域 --&gt;
&lt;script id=&quot;importTpl&quot; type=&quot;text/template&quot;&gt;
&lt;form enctype=&quot;multipart/form-data&quot; class=&quot;mt20 mb10&quot;&gt;
	&lt;div class=&quot;col-xs-offset-1&quot;&gt;
		&lt;input type=&quot;file&quot; id=&quot;file&quot; name=&quot;file&quot;/&gt;
		&lt;div class=&quot;mt10 pt5&quot;&gt;
			&lt;input type=&quot;checkbox&quot; id=&quot;updateSupport&quot; name=&quot;updateSupport&quot; title=&quot;如果登录账户已经存在，更新这条数据。&quot;&gt; 是否更新已经存在的用户数据
			 &amp;nbsp;	&lt;a onclick=&quot;$.table.importTemplate()&quot; class=&quot;btn btn-default btn-xs&quot;&gt;&lt;i class=&quot;fa fa-file-excel-o&quot;&gt;&lt;/i&gt; 下载模板&lt;/a&gt;
		&lt;/div&gt;
		&lt;font color=&quot;red&quot; class=&quot;pull-left mt10&quot;&gt;
			提示：仅允许导入“xls”或“xlsx”格式文件！
		&lt;/font&gt;
	&lt;/div&gt;
&lt;/form&gt;
&lt;/script&gt;
</code></pre>
<p>4、在实体变量上添加@Excel注解，默认为导出导入，也可以单独设置仅导入Type.IMPORT</p>
<pre><code class="language-java">@Excel(name = &quot;用户序号&quot;)
private Long id;

@Excel(name = &quot;部门编号&quot;, type = Type.IMPORT)
private Long deptId;

@Excel(name = &quot;用户名称&quot;)
private String userName;

/** 导出部门多个对象 */
@Excels({
	@Excel(name = &quot;部门名称&quot;, targetAttr = &quot;deptName&quot;, type = Type.EXPORT),
	@Excel(name = &quot;部门负责人&quot;, targetAttr = &quot;leader&quot;, type = Type.EXPORT)
})
private SysDept dept;

/** 导出部门单个对象 */
@Excel(name = &quot;部门名称&quot;, targetAttr = &quot;deptName&quot;, type = Type.EXPORT)
private SysDept dept;
</code></pre>
<p>5、在Controller添加导入方法，updateSupport属性为是否存在则覆盖（可选）</p>
<pre><code class="language-java">@PostMapping(&quot;/importData&quot;)
@ResponseBody
public AjaxResult importData(MultipartFile file, boolean updateSupport) throws Exception
{
	ExcelUtil&lt;SysUser&gt; util = new ExcelUtil&lt;SysUser&gt;(SysUser.class);
	List&lt;SysUser&gt; userList = util.importExcel(file.getInputStream());
	String operName = ShiroUtils.getSysUser().getLoginName();
	String message = userService.importUser(userList, updateSupport, operName);
	return AjaxResult.success(message);
}
</code></pre>
<p>提示</p>
<p>也可以直接到main运行此方法测试。</p>
<pre><code class="language-java">InputStream is = new FileInputStream(new File(&quot;D:\\test.xlsx&quot;));
ExcelUtil&lt;Entity&gt; util = new ExcelUtil&lt;Entity&gt;(Entity.class);
List&lt;Entity&gt; userList = util.importExcel(is);
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springboot全局异常处理]]></title>
        <id>https://jayhablog.vercel.app/springboot-quan-ju-yi-chang-chu-li/</id>
        <link href="https://jayhablog.vercel.app/springboot-quan-ju-yi-chang-chu-li/">
        </link>
        <updated>2020-11-20T08:16:53.000Z</updated>
        <content type="html"><![CDATA[<p>转自ruoyi开发文档</p>
<h2 id="异常处理">异常处理</h2>
<p>通常一个web框架中，有大量需要处理的异常。比如业务异常，权限不足等等。前端通过弹出提示信息的方式告诉用户出了什么错误。 通常情况下我们用try.....catch.... 对异常进行捕捉处理，但是在实际项目中对业务模块进行异常捕捉，会造成代码重复和繁杂， 我们希望代码中只有业务相关的操作，所有的异常我们单独设立一个类来处理它。全局异常就是对框架所有异常进行统一管理。 我们在可能发生异常的方法里throw抛给控制器。然后由全局异常处理器对异常进行统一处理。 如此，我们的<code>Controller</code>中的方法就可以很简洁了。</p>
<p>所谓全局异常处理器就是使用<code>@ControllerAdvice</code>注解。示例如下：</p>
<p>1、统一返回实体定义</p>
<pre><code class="language-java">package com.ruoyi.common.core.domain;

import java.util.HashMap;

/**
 * 操作消息提醒
 * 
 * @author ruoyi
 */
public class AjaxResult extends HashMap&lt;String, Object&gt;
{
    private static final long serialVersionUID = 1L;

    /**
     * 返回错误消息
     * 
     * @param code 错误码
     * @param msg 内容
     * @return 错误消息
     */
    public static AjaxResult error(String msg)
    {
        AjaxResult json = new AjaxResult();
        json.put(&quot;msg&quot;, msg);
        json.put(&quot;code&quot;, 500);
        return json;
    }

    /**
     * 返回成功消息
     * 
     * @param msg 内容
     * @return 成功消息
     */
    public static AjaxResult success(String msg)
    {
        AjaxResult json = new AjaxResult();
        json.put(&quot;msg&quot;, msg);
        json.put(&quot;code&quot;, 0);
        return json;
    }
}
</code></pre>
<p>2、定义登录异常定义</p>
<pre><code class="language-java">package com.ruoyi.common.exception;

/**
 * 登录异常
 * 
 * @author ruoyi
 */
public class LoginException extends RuntimeException
{
    private static final long serialVersionUID = 1L;

    protected final String message;

    public LoginException(String message)
    {
        this.message = message;
    }

    @Override
    public String getMessage()
    {
        return message;
    }
}
</code></pre>
<p>3、基于@ControllerAdvice注解的Controller层的全局异常统一处理</p>
<pre><code class="language-java">package com.ruoyi.framework.web.exception;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.web.bind.annotation.ExceptionHandler;
import org.springframework.web.bind.annotation.RestControllerAdvice;
import com.ruoyi.common.core.domain.AjaxResult;
import com.ruoyi.common.exception.LoginException;

/**
 * 全局异常处理器
 * 
 * @author ruoyi
 */
@RestControllerAdvice
public class GlobalExceptionHandler
{
    private static final Logger log = LoggerFactory.getLogger(GlobalExceptionHandler.class);
	
	/**
     * 登录异常
     */
    @ExceptionHandler(LoginException.class)
    public AjaxResult loginException(LoginException e)
    {
        log.error(e.getMessage(), e);
        return AjaxResult.error(e.getMessage());
    }
}
</code></pre>
<p>4、测试访问请求</p>
<pre><code class="language-java">@Controller
public class SysIndexController 
{
    /**
     * 首页方法
     */
    @GetMapping(&quot;/index&quot;)
    public String index(ModelMap mmap)
    {
        /**
         * 模拟用户未登录，抛出业务逻辑异常
         */
        SysUser user = ShiroUtils.getSysUser();
        if (StringUtils.isNull(user))
		{
            throw new LoginException(&quot;用户未登录，无法访问请求。&quot;);
        }
		mmap.put(&quot;user&quot;, user);
        return &quot;index&quot;;
    }
}
</code></pre>
<p>根据上面代码含义，当我们未登录访问/index时就会发生LoginException业务逻辑异常，按照我们之前的全局异常配置以及统一返回实体实例化，访问后会出现AjaxResult格式JSON数据， 下面我们运行项目访问查看效果。<br>
界面输出内容如下所示：</p>
<pre><code class="language-json">{
    &quot;msg&quot;: &quot;用户未登录，无法访问请求。&quot;,
    &quot;code&quot;: 500
}
</code></pre>
<p><code>对于一些特殊情况，如接口需要返回json，页面请求返回html可以使用如下方法</code>：</p>
<pre><code class="language-java">@ExceptionHandler(LoginException.class)
public Object loginException(HttpServletRequest request, LoginException e)
{
	log.error(e.getMessage(), e);

	if (ServletUtils.isAjaxRequest(request))
	{
		return AjaxResult.error(e.getMessage());
	}
	else
	{
		return new ModelAndView(&quot;/error/500&quot;);
	}
}
</code></pre>
<p>若依系统的全局异常处理器<code>GlobalExceptionHandler</code><br>
注意：如果全部异常处理返回<code>json</code>，那么可以使用<code>@RestControllerAdvice</code>代替<code>@ControllerAdvice</code>，这样在方法上就可以不需要添加<code>@ResponseBody</code>。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[算法归纳]]></title>
        <id>https://jayhablog.vercel.app/kuai-man-zhi-zhen/</id>
        <link href="https://jayhablog.vercel.app/kuai-man-zhi-zhen/">
        </link>
        <updated>2020-10-22T12:29:04.000Z</updated>
        <content type="html"><![CDATA[<h2 id="快慢指针">快慢指针</h2>
<h4 id="floyd判圈算法龟兔赛跑算法">floyd判圈算法（龟兔赛跑算法）</h4>
<blockquote>
<p>遇到场合：判断链表是否循环</p>
</blockquote>
<h6 id="算法描述">算法描述：</h6>
<p>假想「乌龟」和「兔子」在链表上移动，「兔子」跑得快，「乌龟」跑得慢。当「乌龟」和「兔子」从链表上的同一个节点开始移动时，如果该链表中没有环，那么「兔子」将一直处于「乌龟」的前方；如果该链表中有环，那么「兔子」会先于「乌龟」进入环，并且一直在环内移动。等到「乌龟」进入环时，由于「兔子」的速度快，它一定会在某个时刻与乌龟相遇，即套了「乌龟」若干圈。</p>
<p>即有两个指针，他们速度不同 如 A指针=A指针.next B指针=B指针.next.next 那么他们肯定会相遇</p>
<pre><code class="language-java">public boolean hasCycle(ListNode head){
        if (head == null || head.next == null) {
            return false;//只有两个时候不用判断
        }
        ListNode A= head;//慢指针（乌龟指针）
        ListNode B =head.next;//快指针（兔子指针）
        while(A != B){
        if (B == null|| B.next==null){
            return  false;
        }
            A= A.next;
            B=B.next.next;
        }
        return  true;
</code></pre>
<p>时间复杂度O（N）</p>
<p>空间复杂度O（1）</p>
<hr>
<h2 id="贪心算法">贪心算法</h2>
<p>划分字母区间</p>
<p>题目</p>
<blockquote>
<blockquote>
<p>字符串 S 由小写字母组成。我们要把这个字符串划分为尽可能多的片段，同一个字母只会出现在其中的一个片段。返回一个表示每个字符串片段的长度的列表。</p>
<p>示例 1：</p>
<p>输入：S = &quot;ababcbacadefegdehijhklij&quot;<br>
输出：[9,7,8]<br>
解释：<br>
划分结果为 &quot;ababcbaca&quot;, &quot;defegde&quot;, &quot;hijhklij&quot;。<br>
每个字母最多出现在一个片段中。<br>
像 &quot;ababcbacadefegde&quot;, &quot;hijhklij&quot; 的划分是错误的，因为划分的片段数较少。</p>
<p>来源：力扣（LeetCode）<br>
链接：https://leetcode-cn.com/problems/partition-labels<br>
著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p>
</blockquote>
</blockquote>
<p>该题使用贪心算法，具体思路为，先把字符串中出现的char，将他们最后出现的下标保存在一个长度为26（因为有26个字母）的数组内</p>
<pre><code class="language-java">for (int i = 0; i &lt; 所给定字符串.length; i++) {
            last[S.charAt(i) - 'a'] = i;
        }
</code></pre>
<p>然后设置两个指针start和end，初始时为0，然后</p>
<pre><code class="language-java">end = Math.max(end, last[S.charAt(i) - 'a']);
</code></pre>
<p>end不断更新为i字符在该字符串的最后位置，如果在i！=end时候有字符还有更后的最后位置，那么end就会更新为该字符的最后位置。</p>
<p>如果i==end时候，就代表获取了这个字符区间长度（因为前面的字符都不会在剩余的字符串中出现，可以切的尽量多）。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis作为nosql的使用（详细）与集成到springboot缓存]]></title>
        <id>https://jayhablog.vercel.app/redis-zuo-wei-nosql-de-shi-yong-xiang-xi-yu-ji-cheng-dao-springboot-huan-cun/</id>
        <link href="https://jayhablog.vercel.app/redis-zuo-wei-nosql-de-shi-yong-xiang-xi-yu-ji-cheng-dao-springboot-huan-cun/">
        </link>
        <updated>2020-10-22T12:27:01.000Z</updated>
        <content type="html"><![CDATA[<p>声明 由于本文部分借鉴菜鸟教程redis教程 https://www.runoob.com/redis/redis-geo.html</p>
<p>侵删。</p>
<h2 id="redis概述">redis概述</h2>
<p>redis是典型的noSQL数据库，以 <mark>key-value键值对</mark> 的方式存储数据，默认端口为6379</p>
<p>可以用来作<strong>数据库、缓存、消息中间件</strong></p>
<p>特点-&gt;</p>
<ul>
<li>基于内存实现</li>
<li>以单线程方式实现</li>
<li>默认有16个数据库</li>
</ul>
<p>redis可以设置成常开状态</p>
<p>首先 在shell界面启动进入redis命令为</p>
<pre><code class="language-bash">redis-cli
</code></pre>
<p>在redis界面可以使用</p>
<pre><code class="language-bash">dbsize #查看数据库大小
select [value] #使用第几个数据库
keys * #查看所有的key
FLUSHDB #清空此数据库
exist [key] #该key是否存在
move [key] #把这个键值对移到另一个库
EXPIRE [KEY] [TIME] #设置key过期的时间
ttl [key] #查看key剩余时间
type [key] #查看该key的value是什么类型
del [key] #删除某个键值对
</code></pre>
<hr>
<p>…………………………………………………………………………………………………………………………………………………</p>
<hr>
<h2 id="redis五大类型">redis五大类型</h2>
<blockquote>
<p>String类型</p>
</blockquote>
<pre><code class="language-bash">incr [key] #让他自增1
decr [key] #让他自减1
INCRBY [KEY] [NUM] #自增NUM个值 DECRBY同理
GETRANGE [KEY] [从哪开始] [从哪结束] #相当于substr
append [key] [string] #相当于java的append
SETRANGE [KEY] [STRING] #相当于substr＆replace
setex #设置过期时间
setnx #如果该key不存在才赋值
mset #一次设置多个键值对
mget #一次获取多个值
msetnx #看上面就知道什么意思了 只是这是个原子性操作（即只有成功或失败 没有一部分成功一部分失败）
getset #获取完这个值后再set这个值
set key value #存放键值对
</code></pre>
<p>因为json字符串也是String 存对象常用json字符串</p>
<p>或者以 <mark><em>[实体类]:[对象名]:[属性] [值]</em></mark> 多个属性 一个对象名 这种方式存储一个对象</p>
<hr>
<blockquote>
<p>List类型</p>
</blockquote>
<p>把list看作一个链表</p>
<p>L代表从左边 R代表从右边</p>
<p>有-》</p>
<pre><code class="language-bash">LPUSH [key] [value...] #创建链表/从左边插入数据 Rpush即从右边
Lrange [key] [start] [end] #序号开始 从左边开始遍历 Rrange即从右边
LPOP [key] [n] #从左边移出去n个值
Lindex #通过下标获取值 （从0开始 上面的从1开始）
Lrem #移除
#这些命令也可以组合
Lset #替换某个下标的值
Linsert #在某一个具体的值前面或者后面插入一个新的值
</code></pre>
<hr>
<blockquote>
<p>Set 类型</p>
</blockquote>
<table>
<thead>
<tr>
<th>1</th>
<th style="text-align:center">SADD key member1 [member2]向集合添加一个或多个成员</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/sets-scard.html">SCARD key</a>  获取集合的成员数</td>
</tr>
<tr>
<td>3</td>
<td style="text-align:center">[SDIFF key1 <a href="https://www.runoob.com/redis/sets-sdiff.html">key2]</a>  返回第一个集合与其他集合之间的差异。</td>
</tr>
<tr>
<td>4</td>
<td style="text-align:center">[SDIFFSTORE destination key1 <a href="https://www.runoob.com/redis/sets-sdiffstore.html">key2]</a>  返回给定所有集合的差集并存储在 destination 中</td>
</tr>
<tr>
<td>5</td>
<td style="text-align:center">[SINTER key1 <a href="https://www.runoob.com/redis/sets-sinter.html">key2]</a>  返回给定所有集合的交集</td>
</tr>
<tr>
<td>6</td>
<td style="text-align:center">[SINTERSTORE destination key1 <a href="https://www.runoob.com/redis/sets-sinterstore.html">key2]</a>  返回给定所有集合的交集并存储在 destination 中</td>
</tr>
<tr>
<td>7</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/sets-sismember.html">SISMEMBER key member</a>  判断 member 元素是否是集合 key 的成员</td>
</tr>
<tr>
<td>8</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/sets-smembers.html">SMEMBERS key</a>  返回集合中的所有成员</td>
</tr>
<tr>
<td>9</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/sets-smove.html">SMOVE source destination member</a>  将 member 元素从 source 集合移动到 destination 集合</td>
</tr>
<tr>
<td>10</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/sets-spop.html">SPOP key</a>  移除并返回集合中的一个随机元素</td>
</tr>
<tr>
<td>11</td>
<td style="text-align:center">[SRANDMEMBER key <a href="https://www.runoob.com/redis/sets-srandmember.html">count]</a>  返回集合中一个或多个随机数</td>
</tr>
<tr>
<td>12</td>
<td style="text-align:center">[SREM key member1 <a href="https://www.runoob.com/redis/sets-srem.html">member2]</a>  移除集合中一个或多个成员</td>
</tr>
<tr>
<td>13</td>
<td style="text-align:center">[SUNION key1 <a href="https://www.runoob.com/redis/sets-sunion.html">key2]</a>  返回所有给定集合的并集</td>
</tr>
<tr>
<td>14</td>
<td style="text-align:center">[SUNIONSTORE destination key1 <a href="https://www.runoob.com/redis/sets-sunionstore.html">key2]</a>  所有给定集合的并集存储在 destination 集合中</td>
</tr>
<tr>
<td>15</td>
<td style="text-align:center">[SSCAN key cursor <a href="https://www.runoob.com/redis/sets-sscan.html">MATCH pattern] [COUNT count]</a>  迭代集合中的元素</td>
</tr>
</tbody>
</table>
<hr>
<blockquote>
<p>Hash类型</p>
</blockquote>
<p>Redis hash 是一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。</p>
<table>
<thead>
<tr>
<th>1</th>
<th style="text-align:center">[HDEL key field1 <a href="https://www.runoob.com/redis/hashes-hdel.html">field2]</a>  删除一个或多个哈希表字段</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td style="text-align:center">hset key [filed value...] 创建hash</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hexists.html">HEXISTS key field</a>  查看哈希表 key 中，指定的字段是否存在。</td>
</tr>
<tr>
<td>3</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hget.html">HGET key field</a>  获取存储在哈希表中指定字段的值。</td>
</tr>
<tr>
<td>4</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hgetall.html">HGETALL key</a>  获取在哈希表中指定 key 的所有字段和值</td>
</tr>
<tr>
<td>5</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hincrby.html">HINCRBY key field increment</a>  为哈希表 key 中的指定字段的整数值加上增量 increment 。</td>
</tr>
<tr>
<td>6</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hincrbyfloat.html">HINCRBYFLOAT key field increment</a>  为哈希表 key 中的指定字段的浮点数值加上增量 increment 。</td>
</tr>
<tr>
<td>7</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hkeys.html">HKEYS key</a>  获取所有哈希表中的字段</td>
</tr>
<tr>
<td>8</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hlen.html">HLEN key</a>  获取哈希表中字段的数量</td>
</tr>
<tr>
<td>9</td>
<td style="text-align:center">[HMGET key field1 <a href="https://www.runoob.com/redis/hashes-hmget.html">field2]</a>  获取所有给定字段的值</td>
</tr>
<tr>
<td>10</td>
<td style="text-align:center">[HMSET key field1 value1 <a href="https://www.runoob.com/redis/hashes-hmset.html">field2 value2 ]</a>  同时将多个 field-value (域-值)对设置到哈希表 key 中。</td>
</tr>
<tr>
<td>11</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hset.html">HSET key field value</a>  将哈希表 key 中的字段 field 的值设为 value 。</td>
</tr>
<tr>
<td>12</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hsetnx.html">HSETNX key field value</a>  只有在字段 field 不存在时，设置哈希表字段的值。</td>
</tr>
<tr>
<td>13</td>
<td style="text-align:center"><a href="https://www.runoob.com/redis/hashes-hvals.html">HVALS key</a>  获取哈希表中所有值。</td>
</tr>
<tr>
<td>14</td>
<td style="text-align:center">[HSCAN key cursor <a href="https://www.runoob.com/redis/hashes-hscan.html">MATCH pattern] [COUNT count]</a>  迭代哈希表中的键值</td>
</tr>
</tbody>
</table>
<blockquote>
<p>有序集合zset</p>
</blockquote>
<p>Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员。</p>
<p>不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。</p>
<p>有序集合的成员是唯一的,但分数(score)却可以重复。</p>
<p>集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。</p>
<table>
<thead>
<tr>
<th>1</th>
<th>[ZADD key score1 member1 <a href="https://www.runoob.com/redis/sorted-sets-zadd.html">score2 member2]</a>  向有序集合添加一个或多个成员，或者更新已存在成员的分数</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zcard.html">ZCARD key</a>  获取有序集合的成员数</td>
</tr>
<tr>
<td>3</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zcount.html">ZCOUNT key min max</a>  计算在有序集合中指定区间分数的成员数</td>
</tr>
<tr>
<td>4</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zincrby.html">ZINCRBY key increment member</a>  有序集合中对指定成员的分数加上增量 increment</td>
</tr>
<tr>
<td>5</td>
<td>[ZINTERSTORE destination numkeys key <a href="https://www.runoob.com/redis/sorted-sets-zinterstore.html">key ...]</a>  计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 destination 中</td>
</tr>
<tr>
<td>6</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zlexcount.html">ZLEXCOUNT key min max</a>  在有序集合中计算指定字典区间内成员数量</td>
</tr>
<tr>
<td>7</td>
<td>[ZRANGE key start stop <a href="https://www.runoob.com/redis/sorted-sets-zrange.html">WITHSCORES]</a>  通过索引区间返回有序集合指定区间内的成员</td>
</tr>
<tr>
<td>8</td>
<td>[ZRANGEBYLEX key min max <a href="https://www.runoob.com/redis/sorted-sets-zrangebylex.html">LIMIT offset count]</a>  通过字典区间返回有序集合的成员</td>
</tr>
<tr>
<td>9</td>
<td>[ZRANGEBYSCORE key min max <a href="https://www.runoob.com/redis/sorted-sets-zrangebyscore.html">WITHSCORES] [LIMIT]</a>  通过分数返回有序集合指定区间内的成员</td>
</tr>
<tr>
<td>10</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zrank.html">ZRANK key member</a>  返回有序集合中指定成员的索引</td>
</tr>
<tr>
<td>11</td>
<td>[ZREM key member <a href="https://www.runoob.com/redis/sorted-sets-zrem.html">member ...]</a>  移除有序集合中的一个或多个成员</td>
</tr>
<tr>
<td>12</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zremrangebylex.html">ZREMRANGEBYLEX key min max</a>  移除有序集合中给定的字典区间的所有成员</td>
</tr>
<tr>
<td>13</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zremrangebyrank.html">ZREMRANGEBYRANK key start stop</a>  移除有序集合中给定的排名区间的所有成员</td>
</tr>
<tr>
<td>14</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zremrangebyscore.html">ZREMRANGEBYSCORE key min max</a>  移除有序集合中给定的分数区间的所有成员</td>
</tr>
<tr>
<td>15</td>
<td>[ZREVRANGE key start stop <a href="https://www.runoob.com/redis/sorted-sets-zrevrange.html">WITHSCORES]</a>  返回有序集中指定区间内的成员，通过索引，分数从高到低</td>
</tr>
<tr>
<td>16</td>
<td>[ZREVRANGEBYSCORE key max min <a href="https://www.runoob.com/redis/sorted-sets-zrevrangebyscore.html">WITHSCORES]</a>  返回有序集中指定分数区间内的成员，分数从高到低排序</td>
</tr>
<tr>
<td>17</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zrevrank.html">ZREVRANK key member</a>  返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序</td>
</tr>
<tr>
<td>18</td>
<td><a href="https://www.runoob.com/redis/sorted-sets-zscore.html">ZSCORE key member</a>  返回有序集中，成员的分数值</td>
</tr>
<tr>
<td>19</td>
<td>[ZUNIONSTORE destination numkeys key <a href="https://www.runoob.com/redis/sorted-sets-zunionstore.html">key ...]</a>  计算给定的一个或多个有序集的并集，并存储在新的 key 中</td>
</tr>
<tr>
<td>20</td>
<td>[ZSCAN key cursor <a href="https://www.runoob.com/redis/sorted-sets-zscan.html">MATCH pattern] [COUNT count]</a>  迭代有序集合中的元素（包括元素成员和元素分值）</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="另外的类型">另外的类型</h2>
<blockquote>
<p>geospatial 地理位置</p>
</blockquote>
<pre><code class="language-bash">geoadd [国家]:city/town/... [区域名] [经纬度坐标] #添加一个城市/镇/街信息 [国家]:[什么区域]是key [区域名]是member 
</code></pre>
<p>但一般不用自己添加 使用java程序下载数据集一次性导入</p>
<pre><code class="language-bash">geopos [key] [member] #获取指定的经纬度
 GEODIST key member1 member2 [unit] #获取两者之间的距离 [unit]可以是km m dm ft（英尺） mi（英里）
 georadius #已给定经纬度为中心，找出某一个半径内的元素
 geohash #将经纬度坐标转换成hash字符串
 
</code></pre>
<p>其底层是zset 可以使用zset指令操作geospatial</p>
<hr>
<blockquote>
<p>HyperLogLog基数</p>
</blockquote>
<p>该元素是基数统计的算法</p>
<p>网页的UV（即一个人访问一个网站多次，还是算作一个人访问）</p>
<p>传统方式，set方式保存用户id，统计set元素数量作为判断。</p>
<p>HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。(12kb)</p>
<p>但有错误率(0.81％)</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>命令及描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>[PFADD key element <a href="https://www.runoob.com/redis/hyperloglog-pfadd.html">element ...]</a>  添加指定元素到 HyperLogLog 中。</td>
</tr>
<tr>
<td>2</td>
<td>[PFCOUNT key <a href="https://www.runoob.com/redis/hyperloglog-pfcount.html">key ...]</a>  返回给定 HyperLogLog 的基数估算值。</td>
</tr>
<tr>
<td>3</td>
<td>[PFMERGE destkey sourcekey <a href="https://www.runoob.com/redis/hyperloglog-pfmerge.html">sourcekey ...]</a>  将多个 HyperLogLog 合并为一个 HyperLogLog</td>
</tr>
</tbody>
</table>
<hr>
<p>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</p>
<hr>
<blockquote>
<p>事务</p>
</blockquote>
<p>redis事务不能保证原子性 使用multi命令开启 exec执行，一条语句错误不影响其他语句的执行</p>
<h2 id="springboot集成redis">springboot集成redis</h2>
<p>springboot2.x后 对redis的 底层放弃了jedis改采用lettuce</p>
<p>jedis：采用的是直连的server，多个线程操作的情况下，没有锁会不安全。</p>
<p>lettuce：底层采用netty，是NIO，实例可在多线程共享，多线程情况下也安全。</p>
<p>spring使用redisTemplate的方式操作redis，需要注意的是redisTemplate没有过多的设置，所以redis<strong>对象需要序列化</strong>，implements Serializable的方式固然可以存取值。但这只是在jdk中序列化，直接在redis仓库中查看会乱码，所以我们采用部分转化成String，部分转化成json的方式进行储存对象。（下面代码为固定模板，直接套用即可）</p>
<pre><code class="language-java">import com.fasterxml.jackson.annotation.JsonAutoDetect;
import com.fasterxml.jackson.annotation.PropertyAccessor;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.StringRedisSerializer;

import javax.xml.transform.Templates;
@Configuration
public class redisConfig {
    /**
     * 自定义redisTemplate 使之序列化到redis仓库不乱码
     * @param redisConnectionFactory
     * @return
     */
    @Bean
    @SuppressWarnings(&quot;all&quot;)
    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;String, Object&gt;();
        template.setConnectionFactory(factory);
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
        ObjectMapper om = new ObjectMapper();
        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
        jackson2JsonRedisSerializer.setObjectMapper(om);
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();

        // key采用String的序列化方式
        template.setKeySerializer(stringRedisSerializer);
        // hash的key也采用String的序列化方式
        template.setHashKeySerializer(stringRedisSerializer);
        // value序列化方式采用jackson
        template.setValueSerializer(jackson2JsonRedisSerializer);
        // hash的value序列化方式采用jackson
        template.setHashValueSerializer(jackson2JsonRedisSerializer);
        template.afterPropertiesSet();

        return template;

    }
}
</code></pre>
<p>之后</p>
<p>在application.yaml里配置有关redis的属性</p>
<pre><code class="language-yaml">spring:
  redis:
    host: 8.129.58.219
    password: djiowandijd
    client-name: redisClient
    lettuce:
      pool:
        max-active: 8
</code></pre>
<p>再之后，就可以用redistemplate封装的各种方法，操作各种类型的数据了，例如</p>
<pre><code class="language-java">Customer testCustomer = new Customer(1, &quot;imgLocaltion&quot;, 1, &quot;testAccount&quot;, &quot;testPassword&quot;, 200d, &quot;testName&quot;, &quot;testPhone&quot;, 2);
        redisTemplate.opsForValue().set(&quot;jayhaKey1&quot;,testCustomer);
        System.out.println(redisTemplate.opsForValue().get(&quot;jayhaKey1&quot;));
</code></pre>
<h2 id="springboot缓存抽象重点">springboot缓存抽象<mark>重点</mark></h2>
<p>spring定义了cache和cachemanager接口来统一不同的注解技术，并支持使用Jcache（JSR107</p>
<p>)注解简化开发</p>
<pre><code class="language-java">@Cacheable //主要针对方法配置，将结果进行缓存 主要用于查询的方法上
@CacheEvict //清空缓存 主要用于delete
@CachePut //保证方法被调用，又缓存 主要用于update
@EnableCaching //开启缓存注解支持
</code></pre>
<p>三个注解都有”value“属性， value属性相同时即是同一个缓存</p>
<h3 id="cacheable">Cacheable</h3>
<p>将方法的运行结果进行缓存;以后再要相同的数据,直接从缓存中获取,不用调用方法:<br>
CacheManager管理多个Cache组件的,对缓存的真正CRUD操作在Cache组件中,每一个缓存组件有自己唯一一个名字;</p>
<p>cacheable几个属性:<br>
cacheNames/value:指定缓存组件的名字;可以是多个</p>
<p>key:缓存数据使用的key;可以用它来指定。默认是使用方法参数的值 1-方法的返回值</p>
<p>编写SPEL; #id;参数id的值<br>
例如#root.method.name获取方法名  #root.args[0]获取参数 #result 结果 #result.id 结果对象的id<br>
keyGenerator: key的生成器;可以自己指定key的生成器的组件id key/keyGenerator: 二选一</p>
<p>cacheManager:指定缓存管理器;或者cacheResol ver指定获取解析器<br>
condition:指定符合条件的情况下才缓存:<br>
unless:否定缓存;当unless指定的条件为true,方法的返回值就不会被缓存;可以获取到结果进行判断<br>
unless = &quot;#result == null&quot;<br>
sync:是否使用异步模式</p>
<h3 id="cacheput">CachePut</h3>
<p>主要放在更新的方法上</p>
<p>在cachePut注解中，可以key指定为“#result.id(主键)”达到更新数据库同时更新缓存的目的</p>
<h3 id="cacheevict">CacheEvict</h3>
<p>主要用于删除的方法上，直接删除这个数据的缓存。</p>
<h3 id="caching">Caching</h3>
<p>上面三个注解的组合注解，适用于较为复杂的缓存</p>
<h3 id="cacheconfig">CacheConfig</h3>
<p>放在service类上 抽取缓存公共配置</p>
<p>比如cacheName等于其他注解的value 该类下所有cache的value都会变成这个</p>
]]></content>
    </entry>
</feed>